\documentclass[11pt, a4paper]{report}

% --- PREÁMBULO PYTHON ---
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}

\usepackage[spanish, provide=*]{babel}
\babelprovide[import, onchar=ids fonts]{spanish}

% Definición de fuente principal
% \babelfont{rm}{Noto Sans}

% Configuración de listings para Python
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{\textbf{Guía de Implementación en Python \\ de Predictores Estocásticos Universales}}
\author{Consorcio de Desarrollo de Meta-Predicción Adaptativa}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter{Entorno y Stack Tecnológico}

Esta guía traduce las especificaciones algorítmicas del tratado universal a un ecosistema de producción en Python de alto rendimiento.

\section{Selección de Librerías}
Para equilibrar expresividad matemática y eficiencia computacional (C++/CUDA backend), se prescribe el siguiente stack:

\begin{itemize}
    \item \textbf{JAX}: Para computación numérica acelerada (XLA), vectorización automática (\texttt{vmap}) y diferenciación automática (\texttt{grad}, \texttt{jacfwd}) requerida por Malliavin y JKO.
    \item \textbf{Equinox / Diffrax}: Frameworks sobre JAX para redes neuronales y solvers de ecuaciones diferenciales estocásticas (SDEs), respectivamente.
    \item \textbf{Signax}: (Nativo en JAX) para el cálculo diferencial y ultra-rápido de Signatures y Log-Signatures en GPU, manteniendo el grafo computacional intacto.
    \item \textbf{PyWavelets}: Para la Transformada Wavelet Continua (en CPU, con callback asíncrono) en el módulo SIA.
    \item \textbf{OTT-JAX (Optimal Transport Tools)}: Implementación robusta y diferenciable de Sinkhorn-Knopp.
\end{itemize}

\section{Gestión de Precisión Numérica Global}
Las operaciones en Rama D (Signatures) y el cálculo de derivadas de Malliavin son altamente sensibles al error de redondeo. JAX usa por defecto \texttt{float32}, lo que puede inducir derivas numéricas acumulativas en series temporales largas ($N > 10000$). Se recomienda activar globalmente:

\begin{lstlisting}[language=Python]
import jax
jax.config.update('jax_enable_x64', True)
\end{lstlisting}

Esta activación duplica la precisión a \texttt{float64}, preservando:
\begin{itemize}
    \item Estabilidad numérica en exponentes de Hölder (derivadas de $\tau(q)$)
    \item Precisión en integrales de Skorokhod (sensibles a cuantización)
    \item Convergencia del algoritmo de Sinkhorn bajo condiciones extremas ($\epsilon \to 0$)
\end{itemize}

\textbf{Costo y Compensación:} El overhead es $\sim 2\times$ en tiempo de compilación XLA y VRAM consumida, pero es esencial para la confiabilidad en producción cuando se procesan trayectorias de assets volátiles.

\chapter{Módulo 1: Motor de Identificación (SIA)}

\section{Estimación WTMM con Callback Asíncrono}
Uso de \texttt{jax.pure\_callback} para invocar código CPU (PyWavelets) sin romper el grafo JIT ni la diferenciabilidad del resto del pipeline.

\begin{lstlisting}[language=Python]
import pywt
import jax
import jax.numpy as jnp
from jax import jit, vmap
import numpy as np

class WTMM_Estimator:
    def __init__(self, n_scales=40, j_min=1.0, j_max=6.0):
        # Implementacion Fiel: Escalas Diadicas Densas
        # a_j = 2^{j/v} para analisis multifractal preciso
        # Usamos 10 voces por octava (densidad estandar en WTMM)
        
        powers = jnp.linspace(j_min, j_max, num=n_scales)
        self.scales = jnp.power(2.0, powers)
        self.wavelet = 'gaus1'

    def compute_cwt_safe(self, signal):
        """
        Wrapper seguro para llamar a PyWavelets desde una funcion JIT.
        """
        result_shape = (len(self.scales), signal.shape[0])
        
        def _cwt_cpu(s, sc):
            # Esta funcion corre en CPU puro con arrays de Numpy
            coefs, _ = pywt.cwt(np.array(s), np.array(sc), 'gaus1')
            return coefs.astype(np.float32)

        # pure_callback permite inyectar valores externos en el grafo
        coefs = jax.pure_callback(_cwt_cpu, 
                                  jax.ShapeDtypeStruct(result_shape, jnp.float32), 
                                  signal, self.scales)
        return coefs

    @staticmethod
    @jit
    def find_modulus_maxima(cwt_coeffs):
        # ... (Idem implementacion anterior) ...
        c = jnp.abs(cwt_coeffs)
        left = jnp.roll(c, 1, axis=1)
        right = jnp.roll(c, -1, axis=1)
        is_local_max = (c > left) & (c > right)
        return c * is_local_max

    @staticmethod
    @jit
    def trace_skeletons_and_compute_tau(maxima_coeffs, scales, q_moments=jnp.array([-2.0, -1.0, 1.0, 2.0]), C_influence=1.5):
        """
        Implementacion Fiel del Algoritmo 2 (Guia Universal): Enlace de Maximos y Funcion de Particion.
        """
        # maxima_coeffs: Array [n_scales, time_steps] con los modulos en los maximos (0 en el resto).
        
        # PASO 2: Enlace de Maximos (Tracking Vectorizado)
        # Inicializamos las lineas activas en la escala mas gruesa (J)
        active_lines = jnp.where(maxima_coeffs[-1] > 0, maxima_coeffs[-1], 0.0)
        
        def link_scale(prev_active_lines, current_scale_data):
            curr_maxima, curr_a = current_scale_data
            
            # Solucion Estructural para XLA: Broadcasting en lugar de reduce_window dinamico
            # reduce_window requiere tamaños estaticos, pero el radio depende de curr_a (Tracer).
            # Usamos una mascara de distancia global.
            
            # 1. Crear matriz de distancias relativas
            n_time = prev_active_lines.shape[0]
            indices = jnp.arange(n_time)
            # Matriz (N, N): dist_matrix[i, j] = |i - j|
            dist_matrix = jnp.abs(indices[:, None] - indices[None, :])
            
            # 2. Definir el radio dinamico de influencia
            radius = jnp.ceil(C_influence * curr_a)
            
            # 3. Mascara de influencia (N, N)
            # mask[i, j] es True si j influye en i (esta dentro del radio)
            influence_mask = dist_matrix <= radius
            
            # 4. Dilatacion segura con XLA (Max-Pool via Masked Reduction)
            # Para cada punto i, calculamos el maximo de prev_active_lines[j] donde mask[i,j] es True.
            # Rellenamos con -inf donde no hay influencia para que el maximo funcione
            masked_values = jnp.where(influence_mask, prev_active_lines[None, :], -jnp.inf)
            dilated_prev = jnp.max(masked_values, axis=1)
            
            # Interseccion Logica (AND suave):
            # Un maximo actual sobrevive SOLO si cae dentro del cono dilatado de un ancestro
            # Y ademas es un maximo local valido
            linked_maxima = jnp.where((curr_maxima > 0) & (dilated_prev > 0), curr_maxima, 0.0)
            
            # Actualizamos lineas activas: propagamos la magnitud
            return linked_maxima, linked_maxima


        # Escaneo hacia arriba (escalas mas finas) usando jax.lax.scan
        _, skeletons = jax.lax.scan(
            link_scale, 
            active_lines, 
            (maxima_coeffs[:-1][::-1], scales[:-1][::-1])
        )
        
        # Reordenamos las escalas a su orden original
        skeletons = jnp.vstack([skeletons[::-1], active_lines])

        # PASO 3: Funcion de Particion Z(q, a)
        def compute_zq(q):
            # Filtrar ceros para evitar NaNs en potencias negativas
            safe_skeletons = jnp.where(skeletons > 1e-8, skeletons, jnp.nan)
            return jnp.nansum(safe_skeletons ** q, axis=1)

        Z_q_a = vmap(compute_zq)(q_moments) # Forma: [n_q, n_scales]
        
        # PASO 4: Exponentes tau(q) mediante regresion lineal (log Z vs log a)
        log_a = jnp.log(scales)
        log_Z = jnp.log(Z_q_a + 1e-8)
        
        a_mean = jnp.mean(log_a)
        def compute_slope(lz):
            return jnp.sum((log_a - a_mean) * (lz - jnp.mean(lz))) / jnp.sum((log_a - a_mean)**2)
            
        tau_q = vmap(compute_slope)(log_Z)
        
        # Espectro de Legendre: D(h) = min_q (q*h - tau(q))
        # El Holder local 'h' se extrae de las derivadas de tau(q)
        h_estimates = jnp.gradient(tau_q, q_moments)
        
        # Retornamos el Holder minimo (la singularidad mas fuerte) para el Circuit Breaker
        return jnp.min(h_estimates)

    def estimate_holder_exponent(self, signal, besov_c=1.5):
        # Pipeline completo fiel a la Guia Universal
        coefs = self.compute_cwt_safe(signal)
        maxima = self.find_modulus_maxima(coefs)
        # Inyectar el parametro de influencia de Besov calibrable
        h_min = self.trace_skeletons_and_compute_tau(maxima, self.scales, C_influence=besov_c)
        
        # Retornar array escalar para consistencia
        return jnp.array([h_min])
    
    def compute_cwt_windowed(self, signal, window_size=1024):
        """
        Variante optimizada en memoria para buffers grandes (N_buf > 1024).
        Usa jax.lax.reduce_window para max-pooling en lugar de construir
        una matriz de distancias de tamaño O(N^2).
        
        Aplicable cuando el buffer excede GPU VRAM disponible y la precision
        multifractal puede relajarse ligeramente en favor de la estabilidad.
        """
        if signal.shape[0] <= window_size:
            # Para buffers pequenos, usar com implantacao normal
            return self.compute_cwt_safe(signal)
        
        # Dividir en ventanas con overlap para mantener continuidad
        stride = window_size // 2  # 50% overlap
        coefs_chunks = []
        
        for i in range(0, signal.shape[0] - window_size, stride):
            chunk = signal[i:i + window_size]
            coef_chunk = self.compute_cwt_safe(chunk)
            
            # Tomar solo la parte 'nueva' para evitar duplicados
            if i > 0:
                coef_chunk = coef_chunk[:, stride:]
            coefs_chunks.append(coef_chunk)
        
        # Concatenar: forma [n_scales, n_time_processado]
        coefs_full = jnp.concatenate(coefs_chunks, axis=1)
        return coefs_full
\end{lstlisting}

\section{Cálculo de Peso de Malliavin (Integral de Skorokhod)}
Aumentamos el estado de la SDE para computar simultáneamente la integral estocástica requerida para las Griegas en payoffs discontinuos.

\begin{lstlisting}[language=Python]
import jax
import jax.numpy as jnp
import diffrax

class MalliavinCalculator:
    def __init__(self, drift, diffusion, inv_diffusion_fn):
        self.drift = drift
        self.diffusion = diffusion
        self.inv_diffusion = inv_diffusion_fn
        
    def solve_malliavin_system(self, x0, t_span, key):
        """
        Resuelve:
        1. Estado: dX_t = b(X)dt + sigma(X)dW_t
        2. Tangente: dY_t = b'(X)Y dt + sigma'(X)Y dW_t
        3. Peso (Integral): dP_t = (sigma^-1(X) Y)^T dW_t
        """
        y0 = jnp.eye(x0.shape[0])
        p0 = jnp.zeros(x0.shape[0]) # Malliavin weight accumulator
        
        def vector_field(t, state, args):
            x, y, p = state
            
            # 1. Drift terminos
            bx = self.drift(t, x)
            db_dx = jax.jacfwd(lambda _x: self.drift(t, _x))(x)
            by = db_dx @ y
            bp = jnp.zeros_like(p) # Integral estocastica no tiene drift en Ito estandar
            
            # 2. Diffusion terminos
            sx = self.diffusion(t, x)
            ds_dx = jax.jacfwd(lambda _x: self.diffusion(t, _x))(x)
            sy = ds_dx @ y
            
            # Termino del peso de Malliavin (Bismut-Elworthy-Li): 
            # dP_t = (sigma^-1(X) Y \nabla b(X))^T dW_t
            # sp = (sigma_inv @ Y @ drift_jacobian).T 
            
            s_inv = self.inv_diffusion(t, x)
            # Correccion Teorica: Incluir Jacobiano del Drift en el integrando
            # db_dx @ y es la deformacion local del flujo determinista
            # Multiplicamos por sigma inversa para convertirlo en ruido
            
            # Nota: La formula exacta puede variar segun si buscamos Delta o Vega.
            # Aqui asumimos la variacion estandar respecto a x0 via flujo tangente Y_t.
            # Para Delta puro: weight ~ int (sigma^-1 Y_t)^T dW_t es la formula estandar simplificada
            # Pero el tratado exige la formulacion completa que acopla drift y difusion.
            
            # sp = (s_inv @ y).T # Anterior (Incompleto)
            sp = (s_inv @ (db_dx @ y)).T # Corregido (Con Drift Sensitivity)
            
            return (bx, by, bp), (sx, sy, sp)

        # Terminos para SDE Solver
        # Malliavin requiere esquema fuerte 1.0 (Milstein) si difusion no es constante.
        # Diffrax no tiene Milstein directo simple para ruido multidimensional general sin conmutatividad.
        # Pero podemos usar un esquema Runge-Kutta estocastico de orden fuerte 1.0 o 1.5.
        
        # Usamos Heun estocastico (Trapezoidal) que converge mas fuerte que Euler
        # O idealmente diffrax.ItoMilstein() si el ruido es escalar o conmutativo.
        # Para maxima precision general: SRK1 (Strong Order 1.0)
        
class CoupledMalliavinTerm(diffrax.AbstractTerm):
    """
    Termino personalizado para Ecuaciones Diferenciales Estocasticas Acopladas (Malliavin).
    Maneja el producto tensorial explicito entre el estado PyTree ((D), (D,D), (D))
    y el ruido browniano vectorial (D).
    """
    def __init__(self, diffusion_fn, brownian_path):
        self.diffusion = diffusion_fn
        self.control = brownian_path
        
    def vf(self, t, y, args):
        return self.diffusion(t, y, args)
        
    def contr(self, t0, t1):
        return self.control.evaluate(t0, t1)
        
    def prod(self, vf, control):
        # Esta es la logica critica que fallaba en ControlTerm estandar.
        # vf es el output de diffusion_fn: (sx, sy, sp)
        # control es el incremento browniano: dW (vector D)
        
        sx, sy, sp = vf
        
        # 1. Estado Primal (X_t): sx @ dW
        dx_diff = jnp.dot(sx, control)
        
        # 2. Estado Tangente (Y_t): Contraction (D,D,D) * (D) -> (D,D)
        # sy_ijk * dW_k
        dy_diff = jnp.einsum('ijk,k->ij', sy, control)
        
        # 3. Peso Malliavin (P_t): Dot product (D) * (D) -> Scalar
        dp_diff = jnp.dot(sp, control)
        
        return (dx_diff, dy_diff, dp_diff)

    def is_in_place(self, *args, **kwargs):
        return False
        
        # --- FIN DE LA CLASE ANIDADA ---
        
        # Retomamos el flujo de solve_malliavin_system CON LA INDENTACION CORRECTA
        # VirtualBrownianTree requiere 'shape' para definir la dimension del ruido W_t
        # Asumimos ruido de misma dimension que el estado (Difusion Cuadrada)
    brownian = diffrax.VirtualBrownianTree(t_span[0], t_span[1], tol=1e-3, shape=x0.shape, key=key)
        
    # Definimos MultiTerm con nuestro termino personalizado
    drift = diffrax.ODETerm(lambda t, s, a: vector_field(t, s, a)[0])
    
    def diffusion_fn_wrapper(t, state, args):
        return vector_field(t, state, args)[1]
       
    diffusion = CoupledMalliavinTerm(diffusion_fn_wrapper, brownian)
    
    terms = diffrax.MultiTerm(drift, diffusion)
        
    # Solver seguro para ruido multidimensional general (Strong Order 0.5)
    # Para Malliavin, Euler es suficiente si el paso es pequeño (dt=0.01)
    solver = diffrax.Euler()
    sol = diffrax.diffeqsolve(terms, solver, t0=t_span[0], t1=t_span[1], 
                              dt0=0.01, y0=(x0, y0, p0))
    
    x_T = sol.ys[0][-1]
    weight_integral = sol.ys[2][-1]
    
    return x_T, weight_integral

    def compute_delta(self, x0, t_span, key, payoff_fn):
        # E[f(X_T) * Weight * (1/T)]
        x_T, integral = self.solve_malliavin_system(x0, t_span, key)
        T = t_span[1] - t_span[0]
        malliavin_weight = integral / T
        
        return payoff_fn(x_T) * malliavin_weight
\end{lstlisting}

\chapter{Módulo 2: Núcleos de Predicción}

\section{Rama A: Procesos de Lévy y Monte Carlo Vectorizado}
Implementación del algoritmo de Chambers-Mallows-Stuck para simulación estable.

\begin{lstlisting}[language=Python]
import jax.numpy as jnp
from jax import random, vmap

def simulate_stable_levy(key, alpha, beta, gamma, delta, n_samples):
    """
    Generador Vectorizado de Variables Alpha-Estables
    Algoritmo: Chambers-Mallows-Stuck (1976)
    """
    k1, k2 = random.split(key)
    
    # Variables auxiliares uniformes y exponenciales
    phi = random.uniform(k1, shape=(n_samples,), minval=-jnp.pi/2, maxval=jnp.pi/2)
    w = random.exponential(k2, shape=(n_samples,))
    
    # Terminos S1, S2 segun parametrizacion (alpha != 1)
    # Ver Predictor_Estocastico_Implementacion.tex Eq (3.4)
    
    s_alpha_beta = (1 + (beta * jnp.tan(jnp.pi * alpha / 2))**2)**(1 / (2 * alpha))
    b_alpha_beta = jnp.arctan(beta * jnp.tan(jnp.pi * alpha / 2)) / alpha
    
    term1 = s_alpha_beta * (jnp.sin(alpha * (phi + b_alpha_beta))) / ((jnp.cos(phi))**(1/alpha))
    term2 = ((jnp.cos(phi - alpha * (phi + b_alpha_beta))) / w)**((1 - alpha) / alpha)
    
    z = term1 * term2
    
    return gamma * z + delta
\end{lstlisting}

\section{Rama B: Solvers DGM-PDE con Equinox}
Uso de Deep Galerkin Method para resolver la ecuación HJB en alta dimensión.

\begin{lstlisting}[language=Python]
import equinox as eqx
import diffrax

class DGM_HJB_Solver(eqx.Module):
    # Red simple para V(t,x)
    mlp: eqx.nn.MLP
    
    def __init__(self, in_size, key):
        self.mlp = eqx.nn.MLP(in_size, 1, width_size=64, depth=4, key=key, activation=jax.nn.tanh)

    def __call__(self, t, x):
        # Concatenar tiempo y espacio
        t = jnp.array([t]) if jnp.ndim(t) == 0 else t
        tx = jnp.concatenate([t, x])
        return self.mlp(tx)[0]

def loss_hjb(model, t_batch, x_batch, hamiltonian_fn, terminal_cond_fn, boundary_cond_fn, T, x_term_batch=None, t_bound_batch=None, x_bound_batch=None):
    """
    Computa la Loss Total DGM: L = L_interior + L_terminal + L_boundary
    Algoritmo 5 (Guia Universal) - Version Vectorizada (vmap)
    """
    
    # 1. Loss Interior (Residual PDE)
    # Definimos el residual para UN solo punto (t, x) para que jax.grad funcione (retorno escalar)
    
    def compute_single_residual(t_val, x_val):
        # t_val: scalar, x_val: vector (dim espacial)
        
        # Derivadas automaticas respecto al tiempo
        v_t = jax.grad(lambda _t: model(_t, x_val))(t_val)
        
        # Derivadas automaticas respecto al espacio
        v_x = jax.grad(lambda _x: model(t_val, _x))(x_val)
        v_xx = jax.hessian(lambda _x: model(t_val, _x))(x_val)
        
        # Residual HJB
        return v_t + hamiltonian_fn(x_val, v_x, v_xx)

    # Vectorizamos sobre el batch de entrenamiento usando vmap
    # t_batch: [Batch], x_batch: [Batch, D]
    residuals = vmap(compute_single_residual)(t_batch, x_batch)
    loss_interior = jnp.mean(residuals**2)
    
    # 2. Loss Terminal (Condicion de Contorno Temporal)
    # V(T, x) = g(x)
    
    x_term = x_batch if x_term_batch is None else x_term_batch
    
    # Vectorizacion simple de la inferencia
    v_terminal_pred = vmap(lambda x: model(T, x))(x_term)
    v_terminal_target = vmap(terminal_cond_fn)(x_term)
    
    loss_terminal = jnp.mean((v_terminal_pred - v_terminal_target)**2)
    
    # 3. Loss Frontera (Condicion de Contorno Espacial)
    # V(t, x_b) = h(t, x_b)
    
    if x_bound_batch is not None and t_bound_batch is not None:
         v_bound_pred = vmap(lambda t, x: model(t, x))(t_bound_batch, x_bound_batch)
         v_bound_target = vmap(boundary_cond_fn)(t_bound_batch, x_bound_batch)
         loss_boundary = jnp.mean((v_bound_pred - v_bound_target)**2)
    else:
         loss_boundary = 0.0
    
    return loss_interior + loss_terminal + loss_boundary

\end{lstlisting}

\subsection{Monitoreo de Entropía DGM (Detección de Mode Collapse)}

Durante el entrenamiento de la red neuronal DGM, existe el riesgo de que la red colapse a soluciones triviales (constantes) que satisfacen formalmente la PDE pero carecen de contenido informativo. Esta subsección implementa el \textbf{Principio de Conservación de Entropía de Solución} del documento de Teoría.

\begin{lstlisting}[language=Python]
def compute_entropy_dgm(model, t, x_samples, num_bins=50):
    """
    Calcula la entropia diferencial de la solucion DGM en tiempo t
    sobre una distribucion de puntos espaciales x_samples.
    
    H[V_theta] = -∫ p(v) log p(v) dv
    
    Args:
        model: Red DGM (V_theta)
        t: Tiempo de evaluacion (scalar)
        x_samples: Puntos de muestreo espacial [N, D]
        num_bins: Numero de bins para estimacion de densidad
    
    Returns:
        entropy: Entropia diferencial estimada (scalar)
    """
    # Evaluar la red en los puntos de muestreo
    v_values = vmap(lambda x: model(t, x))(x_samples)  # [N]
    
    # Estimar densidad mediante histograma normalizado
    # Para estimacion mas precisa, usar KDE (Kernel Density Estimation)
    # pero histograma es mas eficiente para monitoreo en linea
    
    hist, bin_edges = jnp.histogram(v_values, bins=num_bins, density=True)
    
    # Ancho de bins para normalizacion
    bin_width = bin_edges[1] - bin_edges[0]
    
    # Probabilidades normalizadas
    # p_i = hist_i * bin_width (para que sum(p_i) ≈ 1)
    probs = hist * bin_width
    
    # Entropia: H = -Σ p_i log(p_i)
    # Evitar log(0) agregando epsilon
    log_probs = jnp.log(probs + 1e-10)
    entropy = -jnp.sum(probs * log_probs)
    
    return entropy

def check_mode_collapse(model, t_eval, x_samples, 
                       terminal_entropy, gamma=0.5):
    """
    Verifica si la red DGM ha colapsado a solucion trivial.
    
    Criterio del Teorema de Conservacion de Entropia:
    H[V_theta](t) >= gamma * H[g]
    
    Args:
        model: Red DGM
        t_eval: Tiempos de evaluacion [T_eval]
        x_samples: Puntos espaciales [N, D]
        terminal_entropy: H[g] - entropia de condicion terminal
        gamma: Factor de retencion [0.5, 1.0]
    
    Returns:
        collapsed: bool - True si mode collapse detectado
        avg_entropy: Entropia promedio temporal
    """
    # Calcular entropia en cada tiempo
    entropies = jnp.array([
        compute_entropy_dgm(model, t, x_samples) 
        for t in t_eval
    ])
    
    # Entropia promedio temporal
    avg_entropy = jnp.mean(entropies)
    
    # Criterio de colapso
    threshold = gamma * terminal_entropy
    collapsed = avg_entropy < threshold
    
    return collapsed, avg_entropy

# Ejemplo de uso en loop de entrenamiento
def train_dgm_with_entropy_monitoring(model, optimizer, 
                                     train_data, gamma=0.5):
    """
    Entrenamiento DGM con monitoreo de entropia para prevenir
    mode collapse.
    """
    # Calcular entropia terminal (baseline)
    # g(x) es la condicion terminal (payoff function)
    x_terminal_samples = train_data['x_terminal']
    g_values = vmap(terminal_cond_fn)(x_terminal_samples)
    
    hist_term, edges_term = jnp.histogram(g_values, bins=50, density=True)
    bin_w = edges_term[1] - edges_term[0]
    probs_term = hist_term * bin_w
    H_terminal = -jnp.sum(probs_term * jnp.log(probs_term + 1e-10))
    
    opt_state = optimizer.init(model)
    
    for epoch in range(num_epochs):
        # Loss estandar DGM
        loss, grads = jax.value_and_grad(loss_hjb)(
            model, t_batch, x_batch, 
            hamiltonian_fn, terminal_cond_fn, 
            boundary_cond_fn, T
        )
        
        # Actualizar parametros
        updates, opt_state = optimizer.update(grads, opt_state)
        model = optax.apply_updates(model, updates)
        
        # Monitoreo de entropia cada K epochs
        if epoch % 10 == 0:
            t_eval = jnp.linspace(0, 0.9*T, 20)  # Evaluar hasta 90% del tiempo
            x_eval = x_batch  # Reusar batch de entrenamiento
            
            collapsed, avg_H = check_mode_collapse(
                model, t_eval, x_eval, H_terminal, gamma
            )
            
            if collapsed:
                print(f"WARNING: Mode collapse detected at epoch {epoch}")
                print(f"  Avg entropy: {avg_H:.4f}")
                print(f"  Threshold: {gamma*H_terminal:.4f}")
                
                # Accion correctiva: reinicializar red o ajustar hiperparametros
                # En produccion: reducir peso rho_B -> 0 en orquestador
                break
    
    return model

\end{lstlisting}

\textbf{Nota Teórica:} Este monitoreo implementa el Teorema de Conservación de Entropía (Sección 3.2 del documento de Teoría). Una solución colapsada tiene $H[V_\theta] \to -\infty$ (distribución delta), violando el criterio $H_{avg} \geq \gamma \cdot H[g]$. En el orquestador JKO, si se detecta colapso persistente ($> 10$ pasos consecutivos), se debe reducir $\rho_B \to 0$ hasta re-entrenar la red DGM.

\chapter{Módulo 3: Orquestador JKO (Jordan-Kinderlehrer-Otto)}

\section{Sinkhorn Estabilizado en Log-Domain con OTT-JAX}
Implementación numéricamente robusta del algoritmo de transporte óptimo entrópico.

\begin{lstlisting}[language=Python]
import jax.numpy as jnp
from ott.geometry import geometry
from ott.problems.linear import linear_problem
from ott.solvers.linear import sinkhorn

class JKO_Discreto:
    def __init__(self, epsilon=1e-2):
        self.epsilon = epsilon # Regularizacion entropica

    def solve_ot_step(self, weights_prev, gradients_energy, tau=0.1):
        """
        Resuelve un paso del esquema JKO:
        rho_{k+1} = argmin_rho { Energy(rho) + (1/2tau)*W2^2(rho, rho_k) }
        
        Usamos la formulacion proximal:
        rho_{k+1} = P #_epsilon (rho_k * exp(-tau * grad_E))
        Donde P es el mapa de transporte entropico.
        """
        
        # 1. Paso explicito (Gradient Descent en espacio de probabilidad)
        # log(rho_target) = log(rho_prev) - tau * grad_E
        log_weights_target = jnp.log(weights_prev + 1e-8) - tau * gradients_energy
        weights_target = jax.nn.softmax(log_weights_target)
        
        # 2. Proyeccion Wasserstein (Sinkhorn)
        # En JKO puro, minimizamos W2^2. Aqui usamos Sinkhorn para encontrar
        # la proyeccion mas cercana en geometria de transporte si hay restricciones.
        # Si no hay restricciones espaciales complejas, el paso softmax es suficiente
        # para la version "Mean Field".
        # Para rigor completo, definimos una geometria entre los "modelos" (nucleos)
        
        # Asumimos que la "distancia" entre modelos es uniforme (todos equidistantes)
        # O definimos una matriz de covarianza entre predictores
        # Costo: penaliza moverse lejos de la diagonal. Costo 0 en diagonal.
        C = 1.0 - jnp.eye(len(weights_prev)) 
        geom = geometry.Geometry(cost_matrix=C, epsilon=self.epsilon)
        
        prob = linear_problem.LinearProblem(geom, a=weights_prev, b=weights_target)
        solver = sinkhorn.Sinkhorn(lse_mode=True)
        out = solver(prob)
        
        # El plan de transporte optimo P (out.matrix) es el acoplamiento pi(x, y).
        # Por definicion de Transporte Optimo (Kantorovich), las marginales de P son 'a' y 'b'.
        # En el esquema JKO, buscamos la proyeccion de la distribucion actual en la direccion del gradiente.
        # La nueva distribucion rho_{k+1} es efectivamente la marginal 'b' (weights_target) ajustada 
        # por la regularizacion de Sinkhorn si no convergio perfectamente, 
        # o mas precisamente, la marginal proyeccion de la masa transportada.
        
        # Correccion Matematica:
        # out.matrix es la matriz de acoplamiento pi_{ij}.
        # La masa total que llega al destino j es la suma sobre i de pi_{ij}.
        # No debemos multiplicar por weights_prev nuevamente, pues pi_{ij} ya contiene la masa.
        
        transported_weights = jnp.sum(out.matrix, axis=0)
        
        # Asegurar normalizacion (por si hay pequenas fugas numericas)
        transported_weights = transported_weights / jnp.sum(transported_weights)
        
        return transported_weights
    
    def solve_ot_step_with_entropy_annealing(self, weights_prev, gradients_energy, tau=0.1, max_iter_sinkhorn=100):
        """
        Variante robusta del algoritmo JKO con Recocido Entrópico (Entropy Annealing).
        
        Bajo condiciones de mercado extremas (ej. gaps de precio, vol explota), el algoritmo
        de Sinkhorn puede divergir si epsilon es muy pequeno. Este metodo implementa:
        
        1. Intenta convergencia con epsilon nominal
        2. Si falla (iteraciones alcanzadas sin tolerancia), duplica epsilon
        3. Retorna solucion suavizada pero garantizada (mejor que error)
        
        Teoria: El recocido entropico intercambia precision por robustez. La solucion
        con epsilon mayor es una proyeccion Wasserstein menos precisa pero numericamente
        estable. Aceptable para "circuit breaker" o modos degradados.
        """
        
        # 1. Paso exponencial (Gradient Descent en espacio de probabilidad)
        log_weights_target = jnp.log(weights_prev + 1e-8) - tau * gradients_energy
        weights_target = jax.nn.softmax(log_weights_target)
        
        C = 1.0 - jnp.eye(len(weights_prev))
        
        # Intento 1: epsilon nominal
        geom = geometry.Geometry(cost_matrix=C, epsilon=self.epsilon)
        prob = linear_problem.LinearProblem(geom, a=weights_prev, b=weights_target)
        solver = sinkhorn.Sinkhorn(lse_mode=True, max_iterations=max_iter_sinkhorn)
        out = solver(prob)
        
        # Diagnosticar convergencia: Si n_iterations >= max_iter_sinkhorn, reintentar
        converged = out.n_iterations < max_iter_sinkhorn
        
        def fallback_annealed():
            """Plan B: Epsilon annealing para convergencia robusta."""
            epsilon_annealed = self.epsilon * 2.0
            geom_anneal = geometry.Geometry(cost_matrix=C, epsilon=epsilon_annealed)
            prob_anneal = linear_problem.LinearProblem(geom_anneal, a=weights_prev, b=weights_target)
            solver_anneal = sinkhorn.Sinkhorn(lse_mode=True, max_iterations=max_iter_sinkhorn)
            out_anneal = solver_anneal(prob_anneal)
            return out_anneal
        
        # Seleccionar solucion basada en convergencia
        out = jax.lax.cond(converged, lambda: out, lambda: fallback_annealed())
        
        transported_weights = jnp.sum(out.matrix, axis=0)
        transported_weights = transported_weights / jnp.sum(transported_weights)
        
        return transported_weights, converged
\end{lstlisting}

\section{Integración con Optax para Aprendizaje de Metaparametros}
Optimización de los hiperparámetros del orquestador (tasas de aprendizaje, regularización).

\begin{lstlisting}[language=Python]
import optax

def make_optimizer(learning_rate):
    # Optimizador AdamW con weight decay para regularizacion
    optimizer = optax.adamw(learning_rate, weight_decay=1e-4)
    return optimizer

def update_metaparameters(params, grads, opt_state, optimizer):
    """
    Actualiza los parametros del orquestador (ej. pesos de atencion, tasas)
    usando gradientes calculados via backprop kroz del tiempo.
    """
    updates, new_opt_state = optimizer.update(grads, opt_state, params)
    new_params = optax.apply_updates(params, updates)
    return new_params, new_opt_state
\end{lstlisting}

\section{Rama C: Esquema IMEX con Solver de Punto Fijo Robusto}
Splitting Implícito-Explícito utilizando \texttt{jaxopt} para garantizar convergencia en la parte rígida.

\begin{lstlisting}[language=Python]
import jaxopt
import jax.numpy as jnp
from jax.scipy.signal import convolve

def compute_jump_fft(u, kernel_fft):
    """
    Evalua la integral de salto (convolucion compensada) usando el Teorema de Convolucion via FFT.
    Operador no-local: L u(x) = int (u(x+y) - u(x)) nu(dy) 
    = (u * nu)(x) - u(x) * lambda
    """
    # 1. Transformada al dominio de la frecuencia
    u_fft = jnp.fft.fft(u)
    
    # 2. Producto punto a punto (convolucion circular)
    # kernel_fft debe ser pre-calculado para eficiencia
    conv_fft = u_fft * kernel_fft
    
    # 3. Transformada inversa (retornar parte real)
    convolution_term = jnp.real(jnp.fft.ifft(conv_fft))
    
    # 4. Compensacion de Levy (Conservacion de Masa)
    # El termino -(lambda * u) es necesario porque la masa salta FUERA de x.
    # lambda (intensidad total) es la suma del kernel = kernel_fft[0] (Componente DC)
    
    lambda_intensity = jnp.real(kernel_fft[0])
    jump_integral = convolution_term - lambda_intensity * u
    
    return jump_integral

def imex_step(x_curr, dt, drift_stiff, jump_kernel_fft, diffusion, key):
    """
    Esquema IMEX de 1er orden para PIDE con Saltos (Levy).
    Parte Implicita: Difusion + Drift Local Stiff
    Parte Explicita: Integral de Saltos (No-Local) via FFT
    """
    noise = random.normal(key, x_curr.shape) * jnp.sqrt(dt)
    
    # 1. Evaluar termino no-local (integral de salto) explicitamente
    # drift_nonstiff (Jumps) = lambda * int (u(y) - u(x)) nu(dy) ~ Convolucion
    jump_term = compute_jump_fft(x_curr, jump_kernel_fft)
    
    # Parte explicita total
    explicit_part = x_curr + dt * jump_term + diffusion(x_curr) * noise
    
    # 2. Solver Implicito para Drift Stiff (Reaccion/Difusion Local)
    # y - dt*f_I(y) = explicit_part
    def fixed_point_op(y, _):
        return explicit_part + dt * drift_stiff(y)
        
    # Solver robusto (Anderson Acceleration converge mas rapido que Picard simple)
    solver = jaxopt.AndersonAcceleration(fixed_point_op, maxiter=10, tol=1e-5)
    
    # Iniciar con x_curr como guess
    x_new, state = solver.run(x_curr, None)
    
    return x_new
\end{lstlisting}

\section{Rama D: Log-Signatures con Signax}
Cálculo de características topológicas de rutas rugosas.

\begin{lstlisting}[language=Python]
import signax # Libreria JAX para signatures

def compute_features(path, depth=3):
    # path: [Batch, Time, Channels]
    # Usamos signax nativo de JAX para calcular log-signatures
    # Esto permite backprop a traves de la signature si fuera necesario
    
    signature = signax.signature(path, depth)
    log_sig = signax.logsignature(path, depth)
    
    return log_sig
\end{lstlisting}

\chapter{Integración y Pipeline}

\section{Clase Maestra PredictionEngine}
Coordinación asíncrona de los módulos.

\begin{lstlisting}[language=Python]
class UniversalPredictor:
    def __init__(self, epsilon=1e-2, tau=0.1, holder_threshold=0.1, 
                 signature_depth=3, signal_buffer_size=128, 
                 cusum_k=0.5, cusum_h=5.0, error_alpha=0.05,
                 besov_c=1.5): # Parametro de influencia de Besov
        self.sia = WTMM_Estimator()
        
        # Guardar parametro Besov para inyectarlo en cada step
        self.besov_c = besov_c
        
        # Buffer circular Estatico (Performance Hack XLA)
        # Usamos JAX arrays estaticos para evitar recompilacion en cada paso
        # Inicializamos con ceros; CWT ignorara el inicio si usamos padding correcto o controlamos el indice.
        self.max_buffer_size = signal_buffer_size
        self.signal_buffer = jnp.zeros(signal_buffer_size) 
        self.buffer_idx = 0
        
        self.min_buffer_size = 32 # Minimo necesario para una wavelet de escala media
        
        # Inyectar profundidad de signatura en Kernel D (Topologico)
        # Asumimos que KernelD acepta 'depth' en su constructor
        self.kernels = [
            KernelA(), 
            KernelB(), 
            KernelC(), 
            KernelD(depth=signature_depth)
        ]
        
        self.orchestrator = JKO_Discreto(epsilon=epsilon)
        self.prev_weights = jnp.ones(4) / 4.0
        self.tau = tau
        self.holder_threshold = holder_threshold
        
        # Estado CUSUM para deteccion de cambio de regimen
        # Incluimos rastreo de varianza (EMA) para estandarizacion dinamica
        self.cusum_state = {
            'g_plus': 0.0, 
            'g_minus': 0.0, 
            'threshold': cusum_h,
            'slack_k': cusum_k, # Parametro de deriva calibrable
            'alpha_var': error_alpha, # Memoria de volatilidad calibrable
            'error_sq_ema': 0.1, # Varianza inicial estimada
            'n_obs': 0
        }

    def fit(self, historical_data):
        """
        Calibracion o Warm-up del modelo online usando datos historicos.
        Procesa la serie temporal para estabilizar pesos JKO y estados internos.
        """
        # 0. Calibrar Nucleos Individuales (Ramas A, B, C, D)
        # Cada kernel ajusta sus parametros internos (ej. redes neuronales DGM, parametros Levy)
        # Esto es critico para que las predicciones base no sean ruido aleatorio.
        for kernel in self.kernels:
             # Asumimos contrato de interfaz: kernel.fit(data)
             if hasattr(kernel, 'fit'):
                 kernel.fit(historical_data)
        
        # Simulamos el paso del tiempo para actualizar pesos y CUSUM
        # Asumimos que historical_data es un array [Time, Features]
        # Y que la target es la propia serie (autoregresivo) o parte de ella
        
        # Reset de estados por seguridad
        self.prev_weights = jnp.ones(4) / 4.0
        self.cusum_state['g_plus'] = 0.0
        self.cusum_state['g_minus'] = 0.0
        
        # Bucle de warm-up (sin guardar predicciones)
        # En JAX puro, esto deberia ser un scan, pero mantenemos loop python 
        # por legibilidad en esta guia, dado que fit() se llama pocas veces.
        
        for t in range(len(historical_data)):
            current_obs = historical_data[t]
            
            # Correction Causal (Time-Shift Bug):
            # En validacion One-Step-Ahead, la observacion que ACABA de llegar (current_obs)
            # es el target real para evaluar la prediccion que hicimos en el paso anterior (t-1).
            # Por tanto, previous_target = current_obs.
            
            # Step actualiza pesos y CUSUM internamente evaluando error = current_obs - last_pred
            _, _ = self.step(current_obs, previous_target=current_obs)

    def predict(self, test_data):
        """
        Generacion de pronosticos secuenciales fuera de muestra.
        """
        predictions = []
        
        for t in range(len(test_data)):
            current_obs = test_data[t]
            
            # Predecir paso t (usando error del paso t-1 evaluado contra current_obs)
            # El argumento previous_target se usa dentro de step() para calcular el error 
            # de la prediccion anterior. Ese target es la observacion actual.
            
            pred, _ = self.step(current_obs, previous_target=current_obs)
            predictions.append(pred)
            
        return jnp.array(predictions)

    def _check_regime_change(self, prediction_error):
        # Implementacion del Algoritmo 3 (CUSUM Secuencial) con Residuos Estandarizados
        # Correccion Dimensionalidad: Reducir error vectorial a escalar (Norma L2)
        # para evitar ValueError en decisiones booleanas.
        
        # Calculamos la magnitud del error (escalar) conservando el signo si es 1D,
        # o usando la norma si es multivariado.
        # Para deteccion general de "falta de ajuste", usamos el error cuadratico medio instantaneo.
        
        error_sq = jnp.sum(prediction_error**2)
        error_norm = jnp.sqrt(error_sq)
        
        # 1. Actualizar estimacion de volatilidad del error (EMA escalar)
        alpha_ema = self.cusum_state['alpha_var'] # Memoria calibrada por Optuna
        current_var = self.cusum_state['error_sq_ema']
        new_var = (1 - alpha_ema) * current_var + alpha_ema * error_sq
        
        # Estandarizacion: s_t ~ (e^2 / sigma^2) - 1 (Chi-squared check)
        # O mas simple para CUSUM de media en magnitud: s_t = (|e| - mu_e) / sigma_e
        # Asumimos que bajo regimen normal, error_norm tiene media correlacionada con sqrt(var).
        
        sigma_t = jnp.sqrt(new_var + 1e-8)
        
        # Score estandarizado: Cuantas desviaciones estandar nos alejamos
        s_standardized = (error_norm / sigma_t) 
        # Restamos el bias esperado (1.0 bajo asuncion normal aprox) para centrar en 0
        s_centered = s_standardized - 1.0
        
        # Guardar estado actualizado
        self.cusum_state['error_sq_ema'] = new_var
        self.cusum_state['n_obs'] += 1

        # 2. Logica CUSUM Unilateral (solo nos importa si el error crece)
        k = self.cusum_state['slack_k'] # Slack calibrado por Optuna
        h = self.cusum_state['threshold']
        
        # Solo monitoreamos g_plus (aumento de error) para detectar ruptura de modelo
        self.cusum_state['g_plus'] = jnp.maximum(0.0, self.cusum_state['g_plus'] + s_centered - k)
        # g_minus no es relevante para deteccion de error (error disminuyendo es bueno)
        self.cusum_state['g_minus'] = 0.0 
        
        alarm = self.cusum_state['g_plus'] > h
        return alarm

    def _check_regime_change_with_kurtosis(self, prediction_error, window_size=252):
        """
        Version mejorada de CUSUM con ajuste adaptativo del umbral basado en curtosis.
        
        Implementa el Lema de Umbral Adaptativo del documento de Teoria:
        h_t = k * sigma_t * (1 + ln(kappa_t / 3))
        
        Args:
            prediction_error: Error de prediccion (scalar o vector)
            window_size: Tamano de ventana para calculo de curtosis (default 252 ~ 1 ano)
        
        Returns:
            alarm: bool - True si cambio de regimen detectado
            kurtosis: float - Curtosis empirica actual
        """
        # Conversion a escalar
        error_sq = jnp.sum(prediction_error**2)
        error_norm = jnp.sqrt(error_sq)
        
        # 1. Actualizar buffer de errores para curtosis
        # Inicializar buffer si no existe
        if not hasattr(self, 'error_buffer'):
            self.error_buffer = jnp.zeros(window_size)
            self.error_buffer_idx = 0
        
        # Actualizar buffer circular
        self.error_buffer = self.error_buffer.at[self.error_buffer_idx].set(error_norm)
        self.error_buffer_idx = (self.error_buffer_idx + 1) % window_size
        
        # 2. Calcular curtosis empirica (cuarto momento estandarizado)
        # Solo calcular cuando tengamos suficientes observaciones
        valid_errors = jnp.where(
            jnp.arange(window_size) < min(self.cusum_state['n_obs'], window_size),
            self.error_buffer,
            jnp.nan
        )
        
        # Media y varianza del buffer (sin NaNs)
        mu_e = jnp.nanmean(valid_errors)
        sigma_e_sq = jnp.nanvar(valid_errors)
        sigma_e = jnp.sqrt(sigma_e_sq + 1e-8)
        
        # Cuarto momento
        m_4 = jnp.nanmean((valid_errors - mu_e)**4)
        
        # Curtosis: kappa = E[(e - mu)^4] / sigma^4
        kappa_t = m_4 / (sigma_e**4 + 1e-10)
        
        # Durante warm-up, asumir curtosis Gaussiana
        kappa_t = jnp.where(
            self.cusum_state['n_obs'] < window_size,
            3.0,  # Curtosis Gaussiana
            kappa_t
        )
        
        # 3. Calcular umbral adaptativo
        # h_t = k * sigma * (1 + ln(kappa/3))
        k = self.cusum_state['slack_k']
        
        # Actualizar varianza con EMA (para consistencia con version original)
        alpha_ema = self.cusum_state['alpha_var']
        current_var = self.cusum_state['error_sq_ema']
        new_var = (1 - alpha_ema) * current_var + alpha_ema * error_sq
        sigma_t = jnp.sqrt(new_var + 1e-8)
        
        # Umbral adaptativo con curtosis
        # ln(kappa/3) puede ser negativo si kappa < 3 (sub-Gaussiano, muy raro en finanzas)
        # Clampeamos para evitar umbrales negativos
        kurtosis_adjustment = jnp.log(jnp.maximum(kappa_t, 1.0) / 3.0)
        h_adaptive = k * sigma_t * (1.0 + kurtosis_adjustment)
        
        # 4. Estadistica CUSUM estandarizada
        s_standardized = error_norm / sigma_t
        s_centered = s_standardized - 1.0
        
        # 5. Actualizar acumulador CUSUM
        self.cusum_state['g_plus'] = jnp.maximum(
            0.0, 
            self.cusum_state['g_plus'] + s_centered - k
        )
        
        # Actualizar estado
        self.cusum_state['error_sq_ema'] = new_var
        self.cusum_state['n_obs'] += 1
        
        # 6. Deteccion con umbral adaptativo
        alarm = self.cusum_state['g_plus'] > h_adaptive
        
        return alarm, kappa_t, h_adaptive

\end{lstlisting}

\textbf{Ejemplo de Uso e Interpretacion de Curtosis:}

\begin{lstlisting}[language=Python]
# En el metodo step() del PredictionEngine, reemplazar:
# regime_changed = self._check_regime_change(last_error)
# por:
regime_changed, kurtosis, h_adaptive = self._check_regime_change_with_kurtosis(last_error)

# Logueo de telemetria
if kurtosis > 5.0:
    print(f"High volatility regime detected: kurtosis = {kurtosis:.2f}")
if kurtosis > 15.0:
    print(f"Crisis regime: kurtosis = {kurtosis:.2f}, adaptive threshold = {h_adaptive:.4f}")
if kurtosis > 20.0:
    print(f"WARNING: Extreme fat tails - residual model may be invalid")

# Interpretacion:
# - kappa ≈ 3: Regimen Gaussiano (mercado normal)
# - kappa ∈ [5, 10]: Volatilidad financiera estandar
# - kappa ∈ [10, 15]: Alta volatilidad (eventos outlier frecuentes)
# - kappa > 15: Regimen de crisis (colas extremadamente pesadas)
# - kappa > 20: Falla del modelo de residuos - considerar cambio de arquitectura

\end{lstlisting}

\textbf{Nota Teorica:} Esta implementacion refleja el \textbf{Lema de Umbral Adaptativo} (Seccion 2.3 del documento de Teoria). El ajuste logaritmico $\ln(\kappa_t/3)$ permite que el umbral CUSUM se expanda automaticamente en regimenes de colas pesadas, evitando falsos positivos mientras mantiene sensibilidad a cambios estructurales genuinos. La formulacion esta derivada de la Desigualdad de Markov de cuarto orden y tiene consistencia asintotica probada.

\begin{lstlisting}[language=Python]

    def step(self, new_data, previous_target=None):
        # 0. Actualizacion del Buffer Circular Estatico (Fix XLA Recompilation)
        # Convertimos new_data a escalar representativo
        scalar_obs = new_data[0] if hasattr(new_data, '__len__') and len(new_data) > 0 else new_data
        
        # Desplazamiento ciclico eficiente (Roll)
        # self.signal_buffer = [x_1, x_2, ..., x_N] -> [x_2, ..., x_N, new_x]
        
        # Ojo: jnp.roll devuelve un nuevo array (inmutable). Debemos reemplazar la referencia.
        # Si buffer_idx < max_size, estamos en llenado inicial.
        # Pero para XLA estatico, siempre mantenemos el array full size.
        
        self.signal_buffer = jnp.roll(self.signal_buffer, shift=-1)
        self.signal_buffer = self.signal_buffer.at[-1].set(float(scalar_obs))
        
        # Incremento contador de observaciones validas (hasta saturar)
        new_count = self.buffer_idx + 1
        self.buffer_idx = min(new_count, self.max_buffer_size) # Clamp al maximo int standard de python
        
        # 1. Identificacion (Singularidad Holderiana)
        # Siempre pasamos el buffer COMPLETO de tamano fijo a la funcion JIT.
        # WTMM calculara sobre todo el buffer con el parametro de Besov ajustado.
        
        meta_state_h = self.sia.estimate_holder_exponent(self.signal_buffer, besov_c=self.besov_c)
        
        # Logica condicional fuera de JAX puro (o con where) para el warm-up
        if self.buffer_idx < self.min_buffer_size:
             meta_state_h = jnp.array([0.5]) # Default browniano durante arranque
        
        # 1.1 Deteccion de Cambio de Regimen (CUSUM)
        # Calcular error de la prediccion anterior si existe target
        last_error = 0.0
        
        # Inicializar last_pred si no existe (startup)
        if not hasattr(self, 'last_pred'):
             self.last_pred = jnp.zeros_like(new_data)
             
        if previous_target is not None:
             # Necesitamos haber guardado la prediccion anterior (self.last_pred)
             # last_pred debe tener la misma forma que target
             last_error = previous_target - self.last_pred
        else:
             # Si no hay target previo (burn-in inicial), el error es cero vector
             last_error = jnp.zeros_like(new_data)
        
        # Validacion dimensional: CUSUM internamente reduce a escalar
        # Retorna un booleano unico (True/False)
        regime_changed = self._check_regime_change(last_error)
        
        # 2. Circuit Breaker (Robustez)
        loss_type = 'mse' # Default
        
        if jnp.min(meta_state_h) < self.holder_threshold: # Singularidad detectada (Crash/Salto) con Umbral Dinamico
             # Forzar peso a signatures (Kernel D) con epsilon de seguridad
             epsilon = 1e-8
             weights = jnp.array([epsilon, epsilon, epsilon, 1.0])
             weights = weights / jnp.sum(weights)
             
             loss_type = 'huber' # Activar robustez para el siguiente paso
             
        elif regime_changed:
             # Reinicio Entropico (Softmax Uniforme)
             # El cambio estructural invalida la historia de pesos
             weights = jnp.ones(len(self.kernels)) / len(self.kernels)
             
             # Reset CUSUM
             self.cusum_state['g_plus'] = 0.0
             self.cusum_state['g_minus'] = 0.0
             
        else:
             # Calcular gradientes reales basados en el error anterior
             energy_grads = jnp.zeros(len(self.kernels)) 
             
             if previous_target is not None and hasattr(self, 'last_kernel_preds'):
                 # Recuperar volatilidad reciente del error para escalar la robustez
                 # Esto hace que el parametro delta sea adapativo y universal (scale-invariant)
                 current_volatility = jnp.sqrt(self.cusum_state['error_sq_ema'] + 1e-8)
                 
                 # Definir funcion de perdida local para JAX autograd
                 def loss_objective(w):
                     pred = jnp.dot(w, self.last_kernel_preds)
                     diff = pred - previous_target
                     
                     if self.last_loss_type == 'huber':
                         # Huber Loss robusta: delta depende de la escala de volatilidad
                         # Usamos 1.35 * sigma para eficiencia del 95% en distribucion normal
                         delta = 1.35 * current_volatility
                         
                         abs_diff = jnp.abs(diff)
                         is_small = abs_diff <= delta
                         loss_elements = jnp.where(is_small, 0.5 * diff**2, delta * (abs_diff - 0.5 * delta))
                         return jnp.sum(loss_elements) # Retornar Energia Escalar Total
                     else:
                         return 0.5 * jnp.sum(diff**2) # MSE Escalar Total
                 
                 # Obtener gradiente de la Energia (Loss) respecto a los pesos (rho)
                 energy_grads = jax.grad(loss_objective)(self.prev_weights)
             
             # Resolver flujo JKO con gradientes reales
             # IMPORTANTE: Inyectar el parametro 'tau' optimizado por Optuna
             # De lo contrario, se usaria el default (0.1), ignorando el aprendizaje de metaparametros.
             weights = self.orchestrator.solve_ot_step(self.prev_weights, energy_grads, tau=self.tau)
             
        # 3. Prediccion Ponderada
        # Calcular predicciones individuales para usarlas en el siguiente gradiente
        current_kernel_preds = jnp.array([k.predict(new_data) for k in self.kernels])
        final_pred = jnp.dot(weights, current_kernel_preds)
        
        # Actualizar estado
        self.prev_weights = weights
        self.last_pred = final_pred 
        self.last_kernel_preds = current_kernel_preds # Guardar componentes para autograd
        self.last_loss_type = loss_type # Recordar si estabamos en modo robusto
        
        return final_pred, loss_type
\end{lstlisting}

\chapter{Meta-Optimización: Walk-Forward y Bayesian Tuning}
Implementación de los protocolos de gobernanza para hiperparámetros no diferenciables.

\section{Validación Rolling Walk-Forward}
Implementación vectorizada del esquema de validación causal con ventana deslizante.

\begin{lstlisting}[language=Python]
class WalkForwardValidator:
    def __init__(self, model_factory, metric_fn, window_size, horizon, max_memory=None):
        self.model_factory = model_factory # Funcion: params -> Model
        self.metric_fn = metric_fn
        self.window_size = window_size
        self.horizon = horizon
        self.max_memory = max_memory # W_max para Rolling Window

    def run(self, data, hyperparams):
        """
        Ejecuta el protocolo de validacion sin data leakage.
        data: serie temporal completa [T, Features]
        """
        t = self.window_size
        errors = []
        
        # Ajuste de Horizonte Estructural:
        # Para validar H pasos adelante, necesitamos H+1 datos reales.
        # El dato extra al final es el target real para la ultima prediccion.
        while t + self.horizon + 1 <= len(data):
            # 1. Definir ventanas (Rolling si max_memory esta definido)
            start_idx = 0
            if self.max_memory is not None:
                start_idx = max(0, t - self.max_memory)
                
            train_data = data[start_idx:t]
            
            # Extraemos una ventana de prueba extendida (H+1)
            # test_data incluye: [Obs_t, Obs_t+1, ..., Obs_t+H]
            # Esto nos permite:
            # - Alimentar [Obs_t, ..., Obs_t+H-1] al modelo para generar predicciones
            # - Usar [Obs_t+1, ..., Obs_t+H] como vector de verdad (Ground Truth)
            
            test_window_full = data[t : t + self.horizon + 1]
            input_data = test_window_full[:-1] # Lo que ve el modelo
            target_data = test_window_full[1:] # La realidad futura
            
            # 2. Instanciar y Entrenar (Reset del estado)
            model = self.model_factory(hyperparams)
            
            # Ejecucion del entrenamiento (Warm-up / Fitting)
            model.fit(train_data) 
            
            # 3. Inferencia Fuera de Muestra
            # El modelo recibe N inputs y genera N predicciones one-step-ahead
            preds = model.predict(input_data)
            
            # Correction Data Leakage (Off-by-One) SOLUCIONADA:
            # preds[i] es la prediccion hecha en t+i para t+i+1
            # target_data[i] es el valor real en t+i+1
            # Ahora ambos arrays tienen longitud exacta self.horizon (incluso si H=1)
            
            valid_preds = preds
            valid_targets = target_data
            
            if len(valid_preds) > 0:
                error = self.metric_fn(valid_preds, valid_targets)
                errors.append(error)
            
            # 4. Avanzar
            t += self.horizon
            
        return np.mean(errors)
\end{lstlisting}

\section{Optimización Bayesiana con Optuna}
Uso del estimador TPE (Tree-structured Parzen Estimator) para buscar heurísticas óptimas.

\begin{lstlisting}[language=Python]
import optuna

def objective(trial):
    # Definir espacio de busqueda (AHORA TOTALMENTE AUTO-APRENDIDO)
    hyperparams = {
        # Discretizacion
        'signature_depth': trial.suggest_int('depth', 3, 5),
        
        # Regularizacion
        'sinkhorn_epsilon': trial.suggest_float('epsilon', 1e-3, 1e-1, log=True),
        'jko_tau': trial.suggest_float('tau', 0.01, 1.0),
        
        # Umbrales y Heuristicas Estocasticas (Conectados al Constructor)
        'cusum_h': trial.suggest_float('cusum_h', 2.0, 5.0), # Umbral de disparo
        'cusum_slack': trial.suggest_float('cusum_slack', 0.1, 1.0), # Tolerancia a la deriva
        'error_alpha': trial.suggest_float('error_alpha', 0.01, 0.2, log=True), # Memoria de volatilidad
        'besov_c': trial.suggest_float('besov_c', 1.0, 3.0), # Cono de influencia WTMM
        'holder_threshold': trial.suggest_float('h_min', 0.3, 0.6)
    }
    
    # Validacion Causal
    # Definir factoria: hyperparams -> UniversalPredictor Wrapper
    def model_factory(hp):
        # Inyeccion TOTAL de Hiperparametros Evolutivos hacia el Constructor
        model = UniversalPredictor(
            epsilon=hp['sinkhorn_epsilon'], 
            tau=hp['jko_tau'],
            holder_threshold=hp['holder_threshold'],
            signature_depth=hp['signature_depth'],
            cusum_h=hp['cusum_h'],          # <- Conexion restaurada
            cusum_k=hp['cusum_slack'],      # <- Conexion restaurada (Deriva/Slack)
            error_alpha=hp['error_alpha'],  # <- Conexion restaurada (Memoria Volatilidad)
            besov_c=hp['besov_c']           # <- Conexion restaurada (Cono de Besov)
        )
        return model

    # Definir metrica robusta (MAE/MSE)
    def metric_fn(preds, targets):
        return np.mean(np.abs(preds - targets))

    # Instanciar validador con ventana de 252 dias (trading year) y horizonte 1 dia
    # Usamos la "fabrica" actualizada que inyecta todos los metaparametros
    validator = WalkForwardValidator(
        model_factory=model_factory, 
        metric_fn=metric_fn, 
        window_size=252, 
        horizon=1, 
        max_memory=504
    )
    
    # Ejecutar validacion (data debe ser visible en el scope o pasado como argumento global)
    mean_error = validator.run(historical_data, hyperparams)
    
    return mean_error

def run_meta_optimization(n_trials=50):
    study = optuna.create_study(direction='minimize')
    study.optimize(objective, n_trials=n_trials)
    
    print("Best Personality:", study.best_params)
    return study.best_params
\end{lstlisting}

\chapter{Sistema de Telemetría y Flags de Estado}

Para garantizar la observabilidad completa del sistema en producción, se requiere una estructura de telemetría que exponga métricas críticas y flags de operación. Esta sección implementa la especificación de $\mathbb{S}_{risk}$ del documento I/O.

\section{Estructura de Telemetría}

\begin{lstlisting}[language=Python]
from dataclasses import dataclass
from typing import Dict

@dataclass
class PredictorTelemetry:
    """
    Estructura de telemetria completa del predictor universal.
    Alineada con la especificacion $\mathbb{S}_{risk}$ del documento I/O.
    """
    # Metricas de singularidad
    holder_exponent: float          # H_t
    cusum_drift: float              # G^+
    distance_to_alarm: float        # h - G^+
    
    # Metricas avanzadas (nuevas)
    kurtosis: float                 # κ_t - Curtosis empirica
    dgm_entropy: float              # H_DGM - Entropia del predictor DGM
    adaptive_threshold: float       # h_t adaptativo
    
    # Pesos y energia
    kernel_weights: jnp.ndarray     # ρ (4 elementos)
    free_energy: float              # F[ρ]
    
    # Flags de operacion
    degraded_inference_mode: bool   # TTL violation
    emergency_mode: bool            # H_t < H_min (singularidad critica)
    regime_change_detected: bool    # CUSUM alarm
    mode_collapse_warning: bool     # H_DGM < γ·H[g]
    
    # Estado del solver
    sinkhorn_converged: bool
    loss_type: str                  # 'mse' | 'huber'

class TelemetryLogger:
    """
    Logger de telemetria para monitoreo en produccion.
    """
    def __init__(self, gamma_entropy=0.5, ttl_max_steps=100):
        self.gamma = gamma_entropy
        self.ttl_max = ttl_max_steps
        self.ttl_counter = 0
        self.mode_collapse_counter = 0
        self.terminal_entropy_baseline = None
    
    def log_state(self, 
                  holder: float,
                  cusum_g_plus: float,
                  cusum_h: float,
                  kurtosis: float,
                  dgm_entropy: float,
                  weights: jnp.ndarray,
                  free_energy: float,
                  regime_changed: bool,
                  sinkhorn_ok: bool,
                  loss_type: str) -> PredictorTelemetry:
        """
        Construye estructura de telemetria a partir del estado interno.
        """
        # Calcular flags
        emergency = holder < 0.4  # H_min threshold
        
        # TTL counter (simulado - en produccion usar timestamps reales)
        if regime_changed or emergency:
            self.ttl_counter = 0  # Reset en eventos criticos
        else:
            self.ttl_counter += 1
        
        degraded = self.ttl_counter > self.ttl_max
        
        # Mode collapse warning
        if self.terminal_entropy_baseline is not None:
            threshold = self.gamma * self.terminal_entropy_baseline
            mode_collapse = dgm_entropy < threshold
            
            if mode_collapse:
                self.mode_collapse_counter += 1
            else:
                self.mode_collapse_counter = 0
            
            # Alarma persistente (>10 pasos consecutivos)
            mode_collapse_warning = self.mode_collapse_counter > 10
        else:
            mode_collapse_warning = False
        
        # Construir telemetria
        telemetry = PredictorTelemetry(
            holder_exponent=holder,
            cusum_drift=cusum_g_plus,
            distance_to_alarm=cusum_h - cusum_g_plus,
            kurtosis=kurtosis,
            dgm_entropy=dgm_entropy,
            adaptive_threshold=cusum_h,
            kernel_weights=weights,
            free_energy=free_energy,
            degraded_inference_mode=degraded,
            emergency_mode=emergency,
            regime_change_detected=regime_changed,
            mode_collapse_warning=mode_collapse_warning,
            sinkhorn_converged=sinkhorn_ok,
            loss_type=loss_type
        )
        
        return telemetry
    
    def set_terminal_entropy_baseline(self, H_terminal: float):
        """
        Establece baseline de entropia para deteccion de mode collapse.
        Debe llamarse una vez durante inicializacion con H[g].
        """
        self.terminal_entropy_baseline = H_terminal

# Ejemplo de integracion en PredictionEngine
class UniversalPredictorWithTelemetry(UniversalPredictor):
    """
    Version extendida del predictor con telemetria completa.
    """
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self.telemetry_logger = TelemetryLogger()
    
    def step_with_telemetry(self, new_data, previous_target=None):
        """
        Version extendida de step() que retorna telemetria.
        """
        # Ejecutar prediccion normal
        pred, loss_type = self.step(new_data, previous_target)
        
        # Calcular metricas avanzadas
        # (Asumir que _check_regime_change_with_kurtosis fue usado)
        kurtosis = getattr(self, 'last_kurtosis', 3.0)
        
        # Calcular entropia DGM (solo si Rama B activa)
        if self.prev_weights[1] > 0.05:  # rho_B > 5%
            # En produccion, evaluar entropy sobre batch de puntos
            dgm_entropy = 1.0  # Placeholder - reemplazar con compute_entropy_dgm()
        else:
            dgm_entropy = float('nan')  # No aplicable
        
        # Calcular energia libre (funcional de Wasserstein)
        free_energy = -jnp.sum(self.prev_weights * jnp.log(self.prev_weights + 1e-10))
        
        # Loguear estado
        telemetry = self.telemetry_logger.log_state(
            holder=float(self.sia.estimate_holder_exponent(self.signal_buffer)[0]),
            cusum_g_plus=float(self.cusum_state['g_plus']),
            cusum_h=float(getattr(self, 'last_h_adaptive', self.cusum_state['threshold'])),
            kurtosis=kurtosis,
            dgm_entropy=dgm_entropy,
            weights=self.prev_weights,
            free_energy=free_energy,
            regime_changed=bool(self.cusum_state['g_plus'] > self.cusum_state['threshold']),
            sinkhorn_ok=True,  # Placeholder
            loss_type=loss_type
        )
        
        return pred, telemetry

\end{lstlisting}

\textbf{Ejemplo de Uso en Producción:}

\begin{lstlisting}[language=Python]
# Inicializar predictor con telemetria
predictor = UniversalPredictorWithTelemetry(
    epsilon=0.01, tau=0.1, holder_threshold=0.45
)

# Establecer baseline de entropia (calculado una vez al inicio)
predictor.telemetry_logger.set_terminal_entropy_baseline(H_terminal=2.5)

# Loop de inferencia
for obs in live_market_data:
    pred, telemetry = predictor.step_with_telemetry(
        obs.price, previous_target=obs.target
    )
    
    # Monitoreo de flags criticos
    if telemetry.degraded_inference_mode:
        logger.warning(f"DEGRADED MODE: TTL exceeded {predictor.telemetry_logger.ttl_max} steps")
        logger.warning("Consider reducing position size - weights are stale")
    
    if telemetry.emergency_mode:
        logger.critical(f"EMERGENCY: Singularity detected (H={telemetry.holder_exponent:.3f})")
        logger.critical("Forcing Kernel D (signatures) with Huber loss")
    
    if telemetry.mode_collapse_warning:
        logger.error("MODE COLLAPSE: DGM entropy below threshold")
        logger.error(f"  H_DGM = {telemetry.dgm_entropy:.3f}")
        logger.error(f"  Threshold = {predictor.telemetry_logger.gamma * predictor.telemetry_logger.terminal_entropy_baseline:.3f}")
        logger.error("Action: Reducing rho_B -> 0 until retraining")
    
    if telemetry.kurtosis > 15.0:
        logger.warning(f"Crisis regime: kurtosis = {telemetry.kurtosis:.2f}")
        logger.info(f"Adaptive CUSUM threshold = {telemetry.adaptive_threshold:.4f}")
    
    # Telemetria para dashboard
    metrics_buffer.append({
        'timestamp': obs.timestamp,
        'prediction': pred,
        'holder': telemetry.holder_exponent,
        'kurtosis': telemetry.kurtosis,
        'cusum_distance': telemetry.distance_to_alarm,
        'weights': telemetry.kernel_weights.tolist(),
        'emergency': telemetry.emergency_mode,
        'degraded': telemetry.degraded_inference_mode
    })

\end{lstlisting}

\section{Interpretación de Flags}

\begin{itemize}
    \item \textbf{degraded\_inference\_mode}: Se activa cuando el sistema no recibe señales frescas ($y_{target}$) dentro del límite TTL. Los pesos $\rho$ se congelan y las predicciones continúan pero con confianza degradada. Recuperación con histéresis: $\text{TTL} < 0.8 \cdot \Delta_{max}$.
    
    \item \textbf{emergency\_mode}: Singularidad crítica detectada ($H_t < H_{min}$). Fuerza $w_D \to 1.0$ (Kernel D de signatures) y activa pérdida de Huber robusta. Indica evento de mercado extremo (flash crash, circuit breaker).
    
    \item \textbf{regime\_change\_detected}: CUSUM detecta cambio estructural ($G^+ > h_t$). Reinicia entropía a distribución uniforme y resetea acumuladores. Indica cambio de paradigma de mercado.
    
    \item \textbf{mode\_collapse\_warning}: DGM ha colapsado a solución trivial ($H_{DGM} < \gamma \cdot H[g]$ durante $>10$ pasos). Requiere re-entrenamiento de la red. Mientras tanto, reducir $\rho_B \to 0$.
\end{itemize}

\end{document}
