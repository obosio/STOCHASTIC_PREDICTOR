\documentclass[11pt, a4paper]{report}

% --- PREÁMBULO PYTHON ---
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}

\usepackage[spanish, provide=*]{babel}
\babelprovide[import, onchar=ids fonts]{spanish}

% Definición de fuente principal
% \babelfont{rm}{Noto Sans}

% Configuración de listings para Python
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}

\lstset{style=mystyle}

\title{\textbf{Guía de Implementación en Python \\ de Predictores Estocásticos Universales}}
\author{Consorcio de Desarrollo de Meta-Predicción Adaptativa}
\date{\today}

\begin{document}

\maketitle

\tableofcontents

\chapter{Entorno y Stack Tecnológico}

Esta guía traduce las especificaciones algorítmicas del tratado universal a un ecosistema de producción en Python de alto rendimiento.

\section{Selección de Librerías}
Para equilibrar expresividad matemática y eficiencia computacional (C++/CUDA backend), se prescribe el siguiente stack:

\begin{itemize}
    \item \textbf{JAX}: Para computación numérica acelerada (XLA), vectorización automática (\texttt{vmap}) y diferenciación automática (\texttt{grad}, \texttt{jacfwd}) requerida por Malliavin y JKO.
    \item \textbf{Equinox / Diffrax}: Frameworks sobre JAX para redes neuronales y solvers de ecuaciones diferenciales estocásticas (SDEs), respectivamente.
    \item \textbf{Signax}: (Nativo en JAX) para el cálculo diferencial y ultra-rápido de Signatures y Log-Signatures en GPU, manteniendo el grafo computacional intacto.
    \item \textbf{PyWavelets}: Para la Transformada Wavelet Continua (en CPU, con callback asíncrono) en el módulo SIA.
    \item \textbf{OTT-JAX (Optimal Transport Tools)}: Implementación robusta y diferenciable de Sinkhorn-Knopp.
\end{itemize}

\chapter{Módulo 1: Motor de Identificación (SIA)}

\section{Estimación WTMM con Callback Asíncrono}
Uso de \texttt{jax.pure\_callback} para invocar código CPU (PyWavelets) sin romper el grafo JIT ni la diferenciabilidad del resto del pipeline.

\begin{lstlisting}[language=Python]
import pywt
import jax
import jax.numpy as jnp
from jax import jit, vmap
import numpy as np

class WTMM_Estimator:
    def __init__(self, n_scales=40, j_min=1.0, j_max=6.0):
        # Implementacion Fiel: Escalas Diadicas Densas
        # a_j = 2^{j/v} para analisis multifractal preciso
        # Usamos 10 voces por octava (densidad estandar en WTMM)
        
        powers = jnp.linspace(j_min, j_max, num=n_scales)
        self.scales = jnp.power(2.0, powers)
        self.wavelet = 'gaus1'

    def compute_cwt_safe(self, signal):
        """
        Wrapper seguro para llamar a PyWavelets desde una funcion JIT.
        """
        result_shape = (len(self.scales), signal.shape[0])
        
        def _cwt_cpu(s, sc):
            # Esta funcion corre en CPU puro con arrays de Numpy
            coefs, _ = pywt.cwt(np.array(s), np.array(sc), 'gaus1')
            return coefs.astype(np.float32)

        # pure_callback permite inyectar valores externos en el grafo
        coefs = jax.pure_callback(_cwt_cpu, 
                                  jax.ShapeDtypeStruct(result_shape, jnp.float32), 
                                  signal, self.scales)
        return coefs

    @staticmethod
    @jit
    def find_modulus_maxima(cwt_coeffs):
        # ... (Idem implementacion anterior) ...
        c = jnp.abs(cwt_coeffs)
        left = jnp.roll(c, 1, axis=1)
        right = jnp.roll(c, -1, axis=1)
        is_local_max = (c > left) & (c > right)
        return c * is_local_max

    @staticmethod
    @jit
    def trace_skeletons_and_compute_tau(maxima_coeffs, scales, q_moments=jnp.array([-2.0, -1.0, 1.0, 2.0]), C_influence=1.5):
        """
        Implementacion Fiel del Algoritmo 2 (Guia Universal): Enlace de Maximos y Funcion de Particion.
        """
        # maxima_coeffs: Array [n_scales, time_steps] con los modulos en los maximos (0 en el resto).
        
        # PASO 2: Enlace de Maximos (Tracking Vectorizado)
        # Inicializamos las lineas activas en la escala mas gruesa (J)
        active_lines = jnp.where(maxima_coeffs[-1] > 0, maxima_coeffs[-1], 0.0)
        
        def link_scale(prev_active_lines, current_scale_data):
            curr_maxima, curr_a = current_scale_data
            
            # Solucion Estructural para XLA: Broadcasting en lugar de reduce_window dinamico
            # reduce_window requiere tamaños estaticos, pero el radio depende de curr_a (Tracer).
            # Usamos una mascara de distancia global.
            
            # 1. Crear matriz de distancias relativas
            n_time = prev_active_lines.shape[0]
            indices = jnp.arange(n_time)
            # Matriz (N, N): dist_matrix[i, j] = |i - j|
            dist_matrix = jnp.abs(indices[:, None] - indices[None, :])
            
            # 2. Definir el radio dinamico de influencia
            radius = jnp.ceil(C_influence * curr_a)
            
            # 3. Mascara de influencia (N, N)
            # mask[i, j] es True si j influye en i (esta dentro del radio)
            influence_mask = dist_matrix <= radius
            
            # 4. Dilatacion segura con XLA (Max-Pool via Masked Reduction)
            # Para cada punto i, calculamos el maximo de prev_active_lines[j] donde mask[i,j] es True.
            # Rellenamos con -inf donde no hay influencia para que el maximo funcione
            masked_values = jnp.where(influence_mask, prev_active_lines[None, :], -jnp.inf)
            dilated_prev = jnp.max(masked_values, axis=1)
            
            # Interseccion Logica (AND suave):
            # Un maximo actual sobrevive SOLO si cae dentro del cono dilatado de un ancestro
            # Y ademas es un maximo local valido
            linked_maxima = jnp.where((curr_maxima > 0) & (dilated_prev > 0), curr_maxima, 0.0)
            
            # Actualizamos lineas activas: propagamos la magnitud
            return linked_maxima, linked_maxima


        # Escaneo hacia arriba (escalas mas finas) usando jax.lax.scan
        _, skeletons = jax.lax.scan(
            link_scale, 
            active_lines, 
            (maxima_coeffs[:-1][::-1], scales[:-1][::-1])
        )
        
        # Reordenamos las escalas a su orden original
        skeletons = jnp.vstack([skeletons[::-1], active_lines])

        # PASO 3: Funcion de Particion Z(q, a)
        def compute_zq(q):
            # Filtrar ceros para evitar NaNs en potencias negativas
            safe_skeletons = jnp.where(skeletons > 1e-8, skeletons, jnp.nan)
            return jnp.nansum(safe_skeletons ** q, axis=1)

        Z_q_a = vmap(compute_zq)(q_moments) # Forma: [n_q, n_scales]
        
        # PASO 4: Exponentes tau(q) mediante regresion lineal (log Z vs log a)
        log_a = jnp.log(scales)
        log_Z = jnp.log(Z_q_a + 1e-8)
        
        a_mean = jnp.mean(log_a)
        def compute_slope(lz):
            return jnp.sum((log_a - a_mean) * (lz - jnp.mean(lz))) / jnp.sum((log_a - a_mean)**2)
            
        tau_q = vmap(compute_slope)(log_Z)
        
        # Espectro de Legendre: D(h) = min_q (q*h - tau(q))
        # El Holder local 'h' se extrae de las derivadas de tau(q)
        h_estimates = jnp.gradient(tau_q, q_moments)
        
        # Retornamos el Holder minimo (la singularidad mas fuerte) para el Circuit Breaker
        return jnp.min(h_estimates)

    def estimate_holder_exponent(self, signal, besov_c=1.5):
        # Pipeline completo fiel a la Guia Universal
        coefs = self.compute_cwt_safe(signal)
        maxima = self.find_modulus_maxima(coefs)
        # Inyectar el parametro de influencia de Besov calibrable
        h_min = self.trace_skeletons_and_compute_tau(maxima, self.scales, C_influence=besov_c)
        
        # Retornar array escalar para consistencia
        return jnp.array([h_min]) 
\end{lstlisting}

\section{Cálculo de Peso de Malliavin (Integral de Skorokhod)}
Aumentamos el estado de la SDE para computar simultáneamente la integral estocástica requerida para las Griegas en payoffs discontinuos.

\begin{lstlisting}[language=Python]
import jax
import jax.numpy as jnp
import diffrax

class MalliavinCalculator:
    def __init__(self, drift, diffusion, inv_diffusion_fn):
        self.drift = drift
        self.diffusion = diffusion
        self.inv_diffusion = inv_diffusion_fn
        
    def solve_malliavin_system(self, x0, t_span, key):
        """
        Resuelve:
        1. Estado: dX_t = b(X)dt + sigma(X)dW_t
        2. Tangente: dY_t = b'(X)Y dt + sigma'(X)Y dW_t
        3. Peso (Integral): dP_t = (sigma^-1(X) Y)^T dW_t
        """
        y0 = jnp.eye(x0.shape[0])
        p0 = jnp.zeros(x0.shape[0]) # Malliavin weight accumulator
        
        def vector_field(t, state, args):
            x, y, p = state
            
            # 1. Drift terminos
            bx = self.drift(t, x)
            db_dx = jax.jacfwd(lambda _x: self.drift(t, _x))(x)
            by = db_dx @ y
            bp = jnp.zeros_like(p) # Integral estocastica no tiene drift en Ito estandar
            
            # 2. Diffusion terminos
            sx = self.diffusion(t, x)
            ds_dx = jax.jacfwd(lambda _x: self.diffusion(t, _x))(x)
            sy = ds_dx @ y
            
            # Termino del peso de Malliavin (Bismut-Elworthy-Li): 
            # dP_t = (sigma^-1(X) Y \nabla b(X))^T dW_t
            # sp = (sigma_inv @ Y @ drift_jacobian).T 
            
            s_inv = self.inv_diffusion(t, x)
            # Correccion Teorica: Incluir Jacobiano del Drift en el integrando
            # db_dx @ y es la deformacion local del flujo determinista
            # Multiplicamos por sigma inversa para convertirlo en ruido
            
            # Nota: La formula exacta puede variar segun si buscamos Delta o Vega.
            # Aqui asumimos la variacion estandar respecto a x0 via flujo tangente Y_t.
            # Para Delta puro: weight ~ int (sigma^-1 Y_t)^T dW_t es la formula estandar simplificada
            # Pero el tratado exige la formulacion completa que acopla drift y difusion.
            
            # sp = (s_inv @ y).T # Anterior (Incompleto)
            sp = (s_inv @ (db_dx @ y)).T # Corregido (Con Drift Sensitivity)
            
            return (bx, by, bp), (sx, sy, sp)

        # Terminos para SDE Solver
        # Malliavin requiere esquema fuerte 1.0 (Milstein) si difusion no es constante.
        # Diffrax no tiene Milstein directo simple para ruido multidimensional general sin conmutatividad.
        # Pero podemos usar un esquema Runge-Kutta estocastico de orden fuerte 1.0 o 1.5.
        
        # Usamos Heun estocastico (Trapezoidal) que converge mas fuerte que Euler
        # O idealmente diffrax.ItoMilstein() si el ruido es escalar o conmutativo.
        # Para maxima precision general: SRK1 (Strong Order 1.0)
        
class CoupledMalliavinTerm(diffrax.AbstractTerm):
    """
    Termino personalizado para Ecuaciones Diferenciales Estocasticas Acopladas (Malliavin).
    Maneja el producto tensorial explicito entre el estado PyTree ((D), (D,D), (D))
    y el ruido browniano vectorial (D).
    """
    def __init__(self, diffusion_fn, brownian_path):
        self.diffusion = diffusion_fn
        self.control = brownian_path
        
    def vf(self, t, y, args):
        return self.diffusion(t, y, args)
        
    def contr(self, t0, t1):
        return self.control.evaluate(t0, t1)
        
    def prod(self, vf, control):
        # Esta es la logica critica que fallaba en ControlTerm estandar.
        # vf es el output de diffusion_fn: (sx, sy, sp)
        # control es el incremento browniano: dW (vector D)
        
        sx, sy, sp = vf
        
        # 1. Estado Primal (X_t): sx @ dW
        dx_diff = jnp.dot(sx, control)
        
        # 2. Estado Tangente (Y_t): Contraction (D,D,D) * (D) -> (D,D)
        # sy_ijk * dW_k
        dy_diff = jnp.einsum('ijk,k->ij', sy, control)
        
        # 3. Peso Malliavin (P_t): Dot product (D) * (D) -> Scalar
        dp_diff = jnp.dot(sp, control)
        
        return (dx_diff, dy_diff, dp_diff)

    def is_in_place(self, *args, **kwargs):
        return False
        
        # --- FIN DE LA CLASE ANIDADA ---
        
        # Retomamos el flujo de solve_malliavin_system CON LA INDENTACION CORRECTA
        # VirtualBrownianTree requiere 'shape' para definir la dimension del ruido W_t
        # Asumimos ruido de misma dimension que el estado (Difusion Cuadrada)
    brownian = diffrax.VirtualBrownianTree(t_span[0], t_span[1], tol=1e-3, shape=x0.shape, key=key)
        
    # Definimos MultiTerm con nuestro termino personalizado
    drift = diffrax.ODETerm(lambda t, s, a: vector_field(t, s, a)[0])
    
    def diffusion_fn_wrapper(t, state, args):
        return vector_field(t, state, args)[1]
       
    diffusion = CoupledMalliavinTerm(diffusion_fn_wrapper, brownian)
    
    terms = diffrax.MultiTerm(drift, diffusion)
        
    # Solver seguro para ruido multidimensional general (Strong Order 0.5)
    # Para Malliavin, Euler es suficiente si el paso es pequeño (dt=0.01)
    solver = diffrax.Euler()
    sol = diffrax.diffeqsolve(terms, solver, t0=t_span[0], t1=t_span[1], 
                              dt0=0.01, y0=(x0, y0, p0))
    
    x_T = sol.ys[0][-1]
    weight_integral = sol.ys[2][-1]
    
    return x_T, weight_integral

    def compute_delta(self, x0, t_span, key, payoff_fn):
        # E[f(X_T) * Weight * (1/T)]
        x_T, integral = self.solve_malliavin_system(x0, t_span, key)
        T = t_span[1] - t_span[0]
        malliavin_weight = integral / T
        
        return payoff_fn(x_T) * malliavin_weight
\end{lstlisting}

\chapter{Módulo 2: Núcleos de Predicción}

\section{Rama A: Procesos de Lévy y Monte Carlo Vectorizado}
Implementación del algoritmo de Chambers-Mallows-Stuck para simulación estable.

\begin{lstlisting}[language=Python]
import jax.numpy as jnp
from jax import random, vmap

def simulate_stable_levy(key, alpha, beta, gamma, delta, n_samples):
    """
    Generador Vectorizado de Variables Alpha-Estables
    Algoritmo: Chambers-Mallows-Stuck (1976)
    """
    k1, k2 = random.split(key)
    
    # Variables auxiliares uniformes y exponenciales
    phi = random.uniform(k1, shape=(n_samples,), minval=-jnp.pi/2, maxval=jnp.pi/2)
    w = random.exponential(k2, shape=(n_samples,))
    
    # Terminos S1, S2 segun parametrizacion (alpha != 1)
    # Ver Predictor_Estocastico_Implementacion.tex Eq (3.4)
    
    s_alpha_beta = (1 + (beta * jnp.tan(jnp.pi * alpha / 2))**2)**(1 / (2 * alpha))
    b_alpha_beta = jnp.arctan(beta * jnp.tan(jnp.pi * alpha / 2)) / alpha
    
    term1 = s_alpha_beta * (jnp.sin(alpha * (phi + b_alpha_beta))) / ((jnp.cos(phi))**(1/alpha))
    term2 = ((jnp.cos(phi - alpha * (phi + b_alpha_beta))) / w)**((1 - alpha) / alpha)
    
    z = term1 * term2
    
    return gamma * z + delta
\end{lstlisting}

\section{Rama B: Solvers DGM-PDE con Equinox}
Uso de Deep Galerkin Method para resolver la ecuación HJB en alta dimensión.

\begin{lstlisting}[language=Python]
import equinox as eqx
import diffrax

class DGM_HJB_Solver(eqx.Module):
    # Red simple para V(t,x)
    mlp: eqx.nn.MLP
    
    def __init__(self, in_size, key):
        self.mlp = eqx.nn.MLP(in_size, 1, width_size=64, depth=4, key=key, activation=jax.nn.tanh)

    def __call__(self, t, x):
        # Concatenar tiempo y espacio
        t = jnp.array([t]) if jnp.ndim(t) == 0 else t
        tx = jnp.concatenate([t, x])
        return self.mlp(tx)[0]

def loss_hjb(model, t_batch, x_batch, hamiltonian_fn, terminal_cond_fn, boundary_cond_fn, T, x_term_batch=None, t_bound_batch=None, x_bound_batch=None):
    """
    Computa la Loss Total DGM: L = L_interior + L_terminal + L_boundary
    Algoritmo 5 (Guia Universal) - Version Vectorizada (vmap)
    """
    
    # 1. Loss Interior (Residual PDE)
    # Definimos el residual para UN solo punto (t, x) para que jax.grad funcione (retorno escalar)
    
    def compute_single_residual(t_val, x_val):
        # t_val: scalar, x_val: vector (dim espacial)
        
        # Derivadas automaticas respecto al tiempo
        v_t = jax.grad(lambda _t: model(_t, x_val))(t_val)
        
        # Derivadas automaticas respecto al espacio
        v_x = jax.grad(lambda _x: model(t_val, _x))(x_val)
        v_xx = jax.hessian(lambda _x: model(t_val, _x))(x_val)
        
        # Residual HJB
        return v_t + hamiltonian_fn(x_val, v_x, v_xx)

    # Vectorizamos sobre el batch de entrenamiento usando vmap
    # t_batch: [Batch], x_batch: [Batch, D]
    residuals = vmap(compute_single_residual)(t_batch, x_batch)
    loss_interior = jnp.mean(residuals**2)
    
    # 2. Loss Terminal (Condicion de Contorno Temporal)
    # V(T, x) = g(x)
    
    x_term = x_batch if x_term_batch is None else x_term_batch
    
    # Vectorizacion simple de la inferencia
    v_terminal_pred = vmap(lambda x: model(T, x))(x_term)
    v_terminal_target = vmap(terminal_cond_fn)(x_term)
    
    loss_terminal = jnp.mean((v_terminal_pred - v_terminal_target)**2)
    
    # 3. Loss Frontera (Condicion de Contorno Espacial)
    # V(t, x_b) = h(t, x_b)
    
    if x_bound_batch is not None and t_bound_batch is not None:
         v_bound_pred = vmap(lambda t, x: model(t, x))(t_bound_batch, x_bound_batch)
         v_bound_target = vmap(boundary_cond_fn)(t_bound_batch, x_bound_batch)
         loss_boundary = jnp.mean((v_bound_pred - v_bound_target)**2)
    else:
         loss_boundary = 0.0
    
    return loss_interior + loss_terminal + loss_boundary

\end{lstlisting}

\chapter{Módulo 3: Orquestador JKO (Jordan-Kinderlehrer-Otto)}

\section{Sinkhorn Estabilizado en Log-Domain con OTT-JAX}
Implementación numéricamente robusta del algoritmo de transporte óptimo entrópico.

\begin{lstlisting}[language=Python]
import jax.numpy as jnp
from ott.geometry import geometry
from ott.problems.linear import linear_problem
from ott.solvers.linear import sinkhorn

class JKO_Discreto:
    def __init__(self, epsilon=1e-2):
        self.epsilon = epsilon # Regularizacion entropica

    def solve_ot_step(self, weights_prev, gradients_energy, tau=0.1):
        """
        Resuelve un paso del esquema JKO:
        rho_{k+1} = argmin_rho { Energy(rho) + (1/2tau)*W2^2(rho, rho_k) }
        
        Usamos la formulacion proximal:
        rho_{k+1} = P #_epsilon (rho_k * exp(-tau * grad_E))
        Donde P es el mapa de transporte entropico.
        """
        
        # 1. Paso explicito (Gradient Descent en espacio de probabilidad)
        # log(rho_target) = log(rho_prev) - tau * grad_E
        log_weights_target = jnp.log(weights_prev + 1e-8) - tau * gradients_energy
        weights_target = jax.nn.softmax(log_weights_target)
        
        # 2. Proyeccion Wasserstein (Sinkhorn)
        # En JKO puro, minimizamos W2^2. Aqui usamos Sinkhorn para encontrar
        # la proyeccion mas cercana en geometria de transporte si hay restricciones.
        # Si no hay restricciones espaciales complejas, el paso softmax es suficiente
        # para la version "Mean Field".
        # Para rigor completo, definimos una geometria entre los "modelos" (nucleos)
        
        # Asumimos que la "distancia" entre modelos es uniforme (todos equidistantes)
        # O definimos una matriz de covarianza entre predictores
        # Costo: penaliza moverse lejos de la diagonal. Costo 0 en diagonal.
        C = 1.0 - jnp.eye(len(weights_prev)) 
        geom = geometry.Geometry(cost_matrix=C, epsilon=self.epsilon)
        
        prob = linear_problem.LinearProblem(geom, a=weights_prev, b=weights_target)
        solver = sinkhorn.Sinkhorn(lse_mode=True)
        out = solver(prob)
        
        # El plan de transporte optimo P (out.matrix) es el acoplamiento pi(x, y).
        # Por definicion de Transporte Optimo (Kantorovich), las marginales de P son 'a' y 'b'.
        # En el esquema JKO, buscamos la proyeccion de la distribucion actual en la direccion del gradiente.
        # La nueva distribucion rho_{k+1} es efectivamente la marginal 'b' (weights_target) ajustada 
        # por la regularizacion de Sinkhorn si no convergio perfectamente, 
        # o mas precisamente, la marginal proyeccion de la masa transportada.
        
        # Correccion Matematica:
        # out.matrix es la matriz de acoplamiento pi_{ij}.
        # La masa total que llega al destino j es la suma sobre i de pi_{ij}.
        # No debemos multiplicar por weights_prev nuevamente, pues pi_{ij} ya contiene la masa.
        
        transported_weights = jnp.sum(out.matrix, axis=0)
        
        # Asegurar normalizacion (por si hay pequenas fugas numericas)
        transported_weights = transported_weights / jnp.sum(transported_weights)
        
        return transported_weights
\end{lstlisting}

\section{Integración con Optax para Aprendizaje de Metaparametros}
Optimización de los hiperparámetros del orquestador (tasas de aprendizaje, regularización).

\begin{lstlisting}[language=Python]
import optax

def make_optimizer(learning_rate):
    # Optimizador AdamW con weight decay para regularizacion
    optimizer = optax.adamw(learning_rate, weight_decay=1e-4)
    return optimizer

def update_metaparameters(params, grads, opt_state, optimizer):
    """
    Actualiza los parametros del orquestador (ej. pesos de atencion, tasas)
    usando gradientes calculados via backprop kroz del tiempo.
    """
    updates, new_opt_state = optimizer.update(grads, opt_state, params)
    new_params = optax.apply_updates(params, updates)
    return new_params, new_opt_state
\end{lstlisting}

\section{Rama C: Esquema IMEX con Solver de Punto Fijo Robusto}
Splitting Implícito-Explícito utilizando \texttt{jaxopt} para garantizar convergencia en la parte rígida.

\begin{lstlisting}[language=Python]
import jaxopt
import jax.numpy as jnp
from jax.scipy.signal import convolve

def compute_jump_fft(u, kernel_fft):
    """
    Evalua la integral de salto (convolucion compensada) usando el Teorema de Convolucion via FFT.
    Operador no-local: L u(x) = int (u(x+y) - u(x)) nu(dy) 
    = (u * nu)(x) - u(x) * lambda
    """
    # 1. Transformada al dominio de la frecuencia
    u_fft = jnp.fft.fft(u)
    
    # 2. Producto punto a punto (convolucion circular)
    # kernel_fft debe ser pre-calculado para eficiencia
    conv_fft = u_fft * kernel_fft
    
    # 3. Transformada inversa (retornar parte real)
    convolution_term = jnp.real(jnp.fft.ifft(conv_fft))
    
    # 4. Compensacion de Levy (Conservacion de Masa)
    # El termino -(lambda * u) es necesario porque la masa salta FUERA de x.
    # lambda (intensidad total) es la suma del kernel = kernel_fft[0] (Componente DC)
    
    lambda_intensity = jnp.real(kernel_fft[0])
    jump_integral = convolution_term - lambda_intensity * u
    
    return jump_integral

def imex_step(x_curr, dt, drift_stiff, jump_kernel_fft, diffusion, key):
    """
    Esquema IMEX de 1er orden para PIDE con Saltos (Levy).
    Parte Implicita: Difusion + Drift Local Stiff
    Parte Explicita: Integral de Saltos (No-Local) via FFT
    """
    noise = random.normal(key, x_curr.shape) * jnp.sqrt(dt)
    
    # 1. Evaluar termino no-local (integral de salto) explicitamente
    # drift_nonstiff (Jumps) = lambda * int (u(y) - u(x)) nu(dy) ~ Convolucion
    jump_term = compute_jump_fft(x_curr, jump_kernel_fft)
    
    # Parte explicita total
    explicit_part = x_curr + dt * jump_term + diffusion(x_curr) * noise
    
    # 2. Solver Implicito para Drift Stiff (Reaccion/Difusion Local)
    # y - dt*f_I(y) = explicit_part
    def fixed_point_op(y, _):
        return explicit_part + dt * drift_stiff(y)
        
    # Solver robusto (Anderson Acceleration converge mas rapido que Picard simple)
    solver = jaxopt.AndersonAcceleration(fixed_point_op, maxiter=10, tol=1e-5)
    
    # Iniciar con x_curr como guess
    x_new, state = solver.run(x_curr, None)
    
    return x_new
\end{lstlisting}

\section{Rama D: Log-Signatures con Signax}
Cálculo de características topológicas de rutas rugosas.

\begin{lstlisting}[language=Python]
import signax # Libreria JAX para signatures

def compute_features(path, depth=3):
    # path: [Batch, Time, Channels]
    # Usamos signax nativo de JAX para calcular log-signatures
    # Esto permite backprop a traves de la signature si fuera necesario
    
    signature = signax.signature(path, depth)
    log_sig = signax.logsignature(path, depth)
    
    return log_sig
\end{lstlisting}

\chapter{Integración y Pipeline}

\section{Clase Maestra PredictionEngine}
Coordinación asíncrona de los módulos.

\begin{lstlisting}[language=Python]
class UniversalPredictor:
    def __init__(self, epsilon=1e-2, tau=0.1, holder_threshold=0.1, 
                 signature_depth=3, signal_buffer_size=128, 
                 cusum_k=0.5, cusum_h=5.0, error_alpha=0.05,
                 besov_c=1.5): # Parametro de influencia de Besov
        self.sia = WTMM_Estimator()
        
        # Guardar parametro Besov para inyectarlo en cada step
        self.besov_c = besov_c
        
        # Buffer circular Estatico (Performance Hack XLA)
        # Usamos JAX arrays estaticos para evitar recompilacion en cada paso
        # Inicializamos con ceros; CWT ignorara el inicio si usamos padding correcto o controlamos el indice.
        self.max_buffer_size = signal_buffer_size
        self.signal_buffer = jnp.zeros(signal_buffer_size) 
        self.buffer_idx = 0
        
        self.min_buffer_size = 32 # Minimo necesario para una wavelet de escala media
        
        # Inyectar profundidad de signatura en Kernel D (Topologico)
        # Asumimos que KernelD acepta 'depth' en su constructor
        self.kernels = [
            KernelA(), 
            KernelB(), 
            KernelC(), 
            KernelD(depth=signature_depth)
        ]
        
        self.orchestrator = JKO_Discreto(epsilon=epsilon)
        self.prev_weights = jnp.ones(4) / 4.0
        self.tau = tau
        self.holder_threshold = holder_threshold
        
        # Estado CUSUM para deteccion de cambio de regimen
        # Incluimos rastreo de varianza (EMA) para estandarizacion dinamica
        self.cusum_state = {
            'g_plus': 0.0, 
            'g_minus': 0.0, 
            'threshold': cusum_h,
            'slack_k': cusum_k, # Parametro de deriva calibrable
            'alpha_var': error_alpha, # Memoria de volatilidad calibrable
            'error_sq_ema': 0.1, # Varianza inicial estimada
            'n_obs': 0
        }

    def fit(self, historical_data):
        """
        Calibracion o Warm-up del modelo online usando datos historicos.
        Procesa la serie temporal para estabilizar pesos JKO y estados internos.
        """
        # 0. Calibrar Nucleos Individuales (Ramas A, B, C, D)
        # Cada kernel ajusta sus parametros internos (ej. redes neuronales DGM, parametros Levy)
        # Esto es critico para que las predicciones base no sean ruido aleatorio.
        for kernel in self.kernels:
             # Asumimos contrato de interfaz: kernel.fit(data)
             if hasattr(kernel, 'fit'):
                 kernel.fit(historical_data)
        
        # Simulamos el paso del tiempo para actualizar pesos y CUSUM
        # Asumimos que historical_data es un array [Time, Features]
        # Y que la target es la propia serie (autoregresivo) o parte de ella
        
        # Reset de estados por seguridad
        self.prev_weights = jnp.ones(4) / 4.0
        self.cusum_state['g_plus'] = 0.0
        self.cusum_state['g_minus'] = 0.0
        
        # Bucle de warm-up (sin guardar predicciones)
        # En JAX puro, esto deberia ser un scan, pero mantenemos loop python 
        # por legibilidad en esta guia, dado que fit() se llama pocas veces.
        
        for t in range(len(historical_data)):
            current_obs = historical_data[t]
            
            # Correction Causal (Time-Shift Bug):
            # En validacion One-Step-Ahead, la observacion que ACABA de llegar (current_obs)
            # es el target real para evaluar la prediccion que hicimos en el paso anterior (t-1).
            # Por tanto, previous_target = current_obs.
            
            # Step actualiza pesos y CUSUM internamente evaluando error = current_obs - last_pred
            _, _ = self.step(current_obs, previous_target=current_obs)

    def predict(self, test_data):
        """
        Generacion de pronosticos secuenciales fuera de muestra.
        """
        predictions = []
        
        for t in range(len(test_data)):
            current_obs = test_data[t]
            
            # Predecir paso t (usando error del paso t-1 evaluado contra current_obs)
            # El argumento previous_target se usa dentro de step() para calcular el error 
            # de la prediccion anterior. Ese target es la observacion actual.
            
            pred, _ = self.step(current_obs, previous_target=current_obs)
            predictions.append(pred)
            
        return jnp.array(predictions)

    def _check_regime_change(self, prediction_error):
        # Implementacion del Algoritmo 3 (CUSUM Secuencial) con Residuos Estandarizados
        # Correccion Dimensionalidad: Reducir error vectorial a escalar (Norma L2)
        # para evitar ValueError en decisiones booleanas.
        
        # Calculamos la magnitud del error (escalar) conservando el signo si es 1D,
        # o usando la norma si es multivariado.
        # Para deteccion general de "falta de ajuste", usamos el error cuadratico medio instantaneo.
        
        error_sq = jnp.sum(prediction_error**2)
        error_norm = jnp.sqrt(error_sq)
        
        # 1. Actualizar estimacion de volatilidad del error (EMA escalar)
        alpha_ema = self.cusum_state['alpha_var'] # Memoria calibrada por Optuna
        current_var = self.cusum_state['error_sq_ema']
        new_var = (1 - alpha_ema) * current_var + alpha_ema * error_sq
        
        # Estandarizacion: s_t ~ (e^2 / sigma^2) - 1 (Chi-squared check)
        # O mas simple para CUSUM de media en magnitud: s_t = (|e| - mu_e) / sigma_e
        # Asumimos que bajo regimen normal, error_norm tiene media correlacionada con sqrt(var).
        
        sigma_t = jnp.sqrt(new_var + 1e-8)
        
        # Score estandarizado: Cuantas desviaciones estandar nos alejamos
        s_standardized = (error_norm / sigma_t) 
        # Restamos el bias esperado (1.0 bajo asuncion normal aprox) para centrar en 0
        s_centered = s_standardized - 1.0
        
        # Guardar estado actualizado
        self.cusum_state['error_sq_ema'] = new_var
        self.cusum_state['n_obs'] += 1

        # 2. Logica CUSUM Unilateral (solo nos importa si el error crece)
        k = self.cusum_state['slack_k'] # Slack calibrado por Optuna
        h = self.cusum_state['threshold']
        
        # Solo monitoreamos g_plus (aumento de error) para detectar ruptura de modelo
        self.cusum_state['g_plus'] = jnp.maximum(0.0, self.cusum_state['g_plus'] + s_centered - k)
        # g_minus no es relevante para deteccion de error (error disminuyendo es bueno)
        self.cusum_state['g_minus'] = 0.0 
        
        alarm = self.cusum_state['g_plus'] > h
        return alarm

    def step(self, new_data, previous_target=None):
        # 0. Actualizacion del Buffer Circular Estatico (Fix XLA Recompilation)
        # Convertimos new_data a escalar representativo
        scalar_obs = new_data[0] if hasattr(new_data, '__len__') and len(new_data) > 0 else new_data
        
        # Desplazamiento ciclico eficiente (Roll)
        # self.signal_buffer = [x_1, x_2, ..., x_N] -> [x_2, ..., x_N, new_x]
        
        # Ojo: jnp.roll devuelve un nuevo array (inmutable). Debemos reemplazar la referencia.
        # Si buffer_idx < max_size, estamos en llenado inicial.
        # Pero para XLA estatico, siempre mantenemos el array full size.
        
        self.signal_buffer = jnp.roll(self.signal_buffer, shift=-1)
        self.signal_buffer = self.signal_buffer.at[-1].set(float(scalar_obs))
        
        # Incremento contador de observaciones validas (hasta saturar)
        new_count = self.buffer_idx + 1
        self.buffer_idx = min(new_count, self.max_buffer_size) # Clamp al maximo int standard de python
        
        # 1. Identificacion (Singularidad Holderiana)
        # Siempre pasamos el buffer COMPLETO de tamano fijo a la funcion JIT.
        # WTMM calculara sobre todo el buffer con el parametro de Besov ajustado.
        
        meta_state_h = self.sia.estimate_holder_exponent(self.signal_buffer, besov_c=self.besov_c)
        
        # Logica condicional fuera de JAX puro (o con where) para el warm-up
        if self.buffer_idx < self.min_buffer_size:
             meta_state_h = jnp.array([0.5]) # Default browniano durante arranque
        
        # 1.1 Deteccion de Cambio de Regimen (CUSUM)
        # Calcular error de la prediccion anterior si existe target
        last_error = 0.0
        
        # Inicializar last_pred si no existe (startup)
        if not hasattr(self, 'last_pred'):
             self.last_pred = jnp.zeros_like(new_data)
             
        if previous_target is not None:
             # Necesitamos haber guardado la prediccion anterior (self.last_pred)
             # last_pred debe tener la misma forma que target
             last_error = previous_target - self.last_pred
        else:
             # Si no hay target previo (burn-in inicial), el error es cero vector
             last_error = jnp.zeros_like(new_data)
        
        # Validacion dimensional: CUSUM internamente reduce a escalar
        # Retorna un booleano unico (True/False)
        regime_changed = self._check_regime_change(last_error)
        
        # 2. Circuit Breaker (Robustez)
        loss_type = 'mse' # Default
        
        if jnp.min(meta_state_h) < self.holder_threshold: # Singularidad detectada (Crash/Salto) con Umbral Dinamico
             # Forzar peso a signatures (Kernel D) con epsilon de seguridad
             epsilon = 1e-8
             weights = jnp.array([epsilon, epsilon, epsilon, 1.0])
             weights = weights / jnp.sum(weights)
             
             loss_type = 'huber' # Activar robustez para el siguiente paso
             
        elif regime_changed:
             # Reinicio Entropico (Softmax Uniforme)
             # El cambio estructural invalida la historia de pesos
             weights = jnp.ones(len(self.kernels)) / len(self.kernels)
             
             # Reset CUSUM
             self.cusum_state['g_plus'] = 0.0
             self.cusum_state['g_minus'] = 0.0
             
        else:
             # Calcular gradientes reales basados en el error anterior
             energy_grads = jnp.zeros(len(self.kernels)) 
             
             if previous_target is not None and hasattr(self, 'last_kernel_preds'):
                 # Recuperar volatilidad reciente del error para escalar la robustez
                 # Esto hace que el parametro delta sea adapativo y universal (scale-invariant)
                 current_volatility = jnp.sqrt(self.cusum_state['error_sq_ema'] + 1e-8)
                 
                 # Definir funcion de perdida local para JAX autograd
                 def loss_objective(w):
                     pred = jnp.dot(w, self.last_kernel_preds)
                     diff = pred - previous_target
                     
                     if self.last_loss_type == 'huber':
                         # Huber Loss robusta: delta depende de la escala de volatilidad
                         # Usamos 1.35 * sigma para eficiencia del 95% en distribucion normal
                         delta = 1.35 * current_volatility
                         
                         abs_diff = jnp.abs(diff)
                         is_small = abs_diff <= delta
                         loss_elements = jnp.where(is_small, 0.5 * diff**2, delta * (abs_diff - 0.5 * delta))
                         return jnp.sum(loss_elements) # Retornar Energia Escalar Total
                     else:
                         return 0.5 * jnp.sum(diff**2) # MSE Escalar Total
                 
                 # Obtener gradiente de la Energia (Loss) respecto a los pesos (rho)
                 energy_grads = jax.grad(loss_objective)(self.prev_weights)
             
             # Resolver flujo JKO con gradientes reales
             # IMPORTANTE: Inyectar el parametro 'tau' optimizado por Optuna
             # De lo contrario, se usaria el default (0.1), ignorando el aprendizaje de metaparametros.
             weights = self.orchestrator.solve_ot_step(self.prev_weights, energy_grads, tau=self.tau)
             
        # 3. Prediccion Ponderada
        # Calcular predicciones individuales para usarlas en el siguiente gradiente
        current_kernel_preds = jnp.array([k.predict(new_data) for k in self.kernels])
        final_pred = jnp.dot(weights, current_kernel_preds)
        
        # Actualizar estado
        self.prev_weights = weights
        self.last_pred = final_pred 
        self.last_kernel_preds = current_kernel_preds # Guardar componentes para autograd
        self.last_loss_type = loss_type # Recordar si estabamos en modo robusto
        
        return final_pred, loss_type
\end{lstlisting}

\chapter{Meta-Optimización: Walk-Forward y Bayesian Tuning}
Implementación de los protocolos de gobernanza para hiperparámetros no diferenciables.

\section{Validación Rolling Walk-Forward}
Implementación vectorizada del esquema de validación causal con ventana deslizante.

\begin{lstlisting}[language=Python]
class WalkForwardValidator:
    def __init__(self, model_factory, metric_fn, window_size, horizon, max_memory=None):
        self.model_factory = model_factory # Funcion: params -> Model
        self.metric_fn = metric_fn
        self.window_size = window_size
        self.horizon = horizon
        self.max_memory = max_memory # W_max para Rolling Window

    def run(self, data, hyperparams):
        """
        Ejecuta el protocolo de validacion sin data leakage.
        data: serie temporal completa [T, Features]
        """
        t = self.window_size
        errors = []
        
        # Ajuste de Horizonte Estructural:
        # Para validar H pasos adelante, necesitamos H+1 datos reales.
        # El dato extra al final es el target real para la ultima prediccion.
        while t + self.horizon + 1 <= len(data):
            # 1. Definir ventanas (Rolling si max_memory esta definido)
            start_idx = 0
            if self.max_memory is not None:
                start_idx = max(0, t - self.max_memory)
                
            train_data = data[start_idx:t]
            
            # Extraemos una ventana de prueba extendida (H+1)
            # test_data incluye: [Obs_t, Obs_t+1, ..., Obs_t+H]
            # Esto nos permite:
            # - Alimentar [Obs_t, ..., Obs_t+H-1] al modelo para generar predicciones
            # - Usar [Obs_t+1, ..., Obs_t+H] como vector de verdad (Ground Truth)
            
            test_window_full = data[t : t + self.horizon + 1]
            input_data = test_window_full[:-1] # Lo que ve el modelo
            target_data = test_window_full[1:] # La realidad futura
            
            # 2. Instanciar y Entrenar (Reset del estado)
            model = self.model_factory(hyperparams)
            
            # Ejecucion del entrenamiento (Warm-up / Fitting)
            model.fit(train_data) 
            
            # 3. Inferencia Fuera de Muestra
            # El modelo recibe N inputs y genera N predicciones one-step-ahead
            preds = model.predict(input_data)
            
            # Correction Data Leakage (Off-by-One) SOLUCIONADA:
            # preds[i] es la prediccion hecha en t+i para t+i+1
            # target_data[i] es el valor real en t+i+1
            # Ahora ambos arrays tienen longitud exacta self.horizon (incluso si H=1)
            
            valid_preds = preds
            valid_targets = target_data
            
            if len(valid_preds) > 0:
                error = self.metric_fn(valid_preds, valid_targets)
                errors.append(error)
            
            # 4. Avanzar
            t += self.horizon
            
        return np.mean(errors)
\end{lstlisting}

\section{Optimización Bayesiana con Optuna}
Uso del estimador TPE (Tree-structured Parzen Estimator) para buscar heurísticas óptimas.

\begin{lstlisting}[language=Python]
import optuna

def objective(trial):
    # Definir espacio de busqueda (AHORA TOTALMENTE AUTO-APRENDIDO)
    hyperparams = {
        # Discretizacion
        'signature_depth': trial.suggest_int('depth', 3, 5),
        
        # Regularizacion
        'sinkhorn_epsilon': trial.suggest_float('epsilon', 1e-3, 1e-1, log=True),
        'jko_tau': trial.suggest_float('tau', 0.01, 1.0),
        
        # Umbrales y Heuristicas Estocasticas (Conectados al Constructor)
        'cusum_h': trial.suggest_float('cusum_h', 2.0, 5.0), # Umbral de disparo
        'cusum_slack': trial.suggest_float('cusum_slack', 0.1, 1.0), # Tolerancia a la deriva
        'error_alpha': trial.suggest_float('error_alpha', 0.01, 0.2, log=True), # Memoria de volatilidad
        'besov_c': trial.suggest_float('besov_c', 1.0, 3.0), # Cono de influencia WTMM
        'holder_threshold': trial.suggest_float('h_min', 0.3, 0.6)
    }
    
    # Validacion Causal
    # Definir factoria: hyperparams -> UniversalPredictor Wrapper
    def model_factory(hp):
        # Inyeccion TOTAL de Hiperparametros Evolutivos hacia el Constructor
        model = UniversalPredictor(
            epsilon=hp['sinkhorn_epsilon'], 
            tau=hp['jko_tau'],
            holder_threshold=hp['holder_threshold'],
            signature_depth=hp['signature_depth'],
            cusum_h=hp['cusum_h'],          # <- Conexion restaurada
            cusum_k=hp['cusum_slack'],      # <- Conexion restaurada (Deriva/Slack)
            error_alpha=hp['error_alpha'],  # <- Conexion restaurada (Memoria Volatilidad)
            besov_c=hp['besov_c']           # <- Conexion restaurada (Cono de Besov)
        )
        return model

    # Definir metrica robusta (MAE/MSE)
    def metric_fn(preds, targets):
        return np.mean(np.abs(preds - targets))

    # Instanciar validador con ventana de 252 dias (trading year) y horizonte 1 dia
    # Usamos la "fabrica" actualizada que inyecta todos los metaparametros
    validator = WalkForwardValidator(
        model_factory=model_factory, 
        metric_fn=metric_fn, 
        window_size=252, 
        horizon=1, 
        max_memory=504
    )
    
    # Ejecutar validacion (data debe ser visible en el scope o pasado como argumento global)
    mean_error = validator.run(historical_data, hyperparams)
    
    return mean_error

def run_meta_optimization(n_trials=50):
    study = optuna.create_study(direction='minimize')
    study.optimize(objective, n_trials=n_trials)
    
    print("Best Personality:", study.best_params)
    return study.best_params
\end{lstlisting}

\end{document}
