\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{geometry}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}

\geometry{a4paper, margin=1in}

\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{pythonstyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2,
    literate={á}{{\'a}}1 {é}{{\'e}}1 {í}{{\'i}}1 {ó}{{\'o}}1 {ú}{{\'u}}1 {ñ}{{\~n}}1 {Á}{{\'A}}1 {É}{{\'E}}1 {Í}{{\'I}}1 {Ó}{{\'O}}1 {Ú}{{\'U}}1
}

\lstset{style=pythonstyle}

\title{Especificación de API Python - Universal Predictor}
\author{Ingeniería de Software}
\date{\today}

\begin{document}

\maketitle

\tableofcontents
\newpage

\section{Introducción}
Este documento detalla la implementación en Python de la interfaz abstracta I/O definida en \textit{Predictor\_Estocastico\_IO}. La API expone la clase \texttt{UniversalPredictor}, diseñada para entornos de alto rendimiento utilizando JAX para la aceleración numérica.

\section{Estructuras de Datos (Tipado)}

Se utilizan \texttt{dataclasses} y \texttt{jaxtyping} para garantizar la inmutabilidad y el tipado dimensional estricto de los tensores.

\subsection{Configuración (\texorpdfstring{$\Lambda$}{Lambda})}
\begin{lstlisting}[language=Python]
from dataclasses import dataclass
from typing import Optional
from jaxtyping import Float, Array, Bool

@dataclass(frozen=True)
class PredictorConfig:
    """Vector de Hiperparámetros Lambda."""
    schema_version: str = "1.0"   # Versionado de snapshots (evita incompatibilidades)
    epsilon: float = 1e-3         # Regularización Entrópica (Sinkhorn)
    learning_rate: float = 0.01   # Tasa de Aprendizaje JKO
    log_sig_depth: int = 3        # Profundidad de Firma (Kernel D)
    wtmm_buffer_size: int = 128   # Memoria WTMM (N_buf)
    besov_cone_c: float = 1.5     # Cono de Influencia de Besov
    holder_threshold: float = 0.4 # Umbral Circuit Breaker (H_min)
    cusum_h: float = 5.0          # Umbral Drift (h)
    cusum_k: float = 0.5          # Slack (k)
    grace_period_steps: int = 20  # Período refractario post-cambio régimen (silencia CUSUM)
    volatility_alpha: float = 0.1 # Decaimiento EWMA de Varianza
    
    # Política de Abandono y Anti-Aliasing
    staleness_ttl_ns: int = 500_000_000         # TTL Latencia (500ms)
    besov_nyquist_interval_ns: int = 100_000_000 # Límite Nyquist (100ms) para estabilidad WTMM
    inference_recovery_hysteresis: float = 0.8  # Factor histéresis para recuperación de modo degradado
\end{lstlisting}

\subsection{Entrada Operativa (\texorpdfstring{$y_t, y_{target}, \tau$}{y\_t, y\_target, tau})}
\begin{lstlisting}[language=Python]
@dataclass(frozen=True)
class MarketObservation:
    price: Float[Array, "1"]      # y_t (Normalizado o Absoluto)
    target: Float[Array, "1"]     # y_target (Generalmente price actual)
    timestamp_ns: int             # Unix Epoch (Nanosegundos)
    
    def validate_domain(self, sigma_bound: float = 20.0, sigma_val: float = 1.0) -> bool:
        """Detección de Outliers Catastróficos (> 20 sigma)."""
        return abs(self.price) <= (sigma_bound * sigma_val)
\end{lstlisting}

\subsection{Salida del Sistema}
\begin{lstlisting}[language=Python]
@dataclass(frozen=True)
class PredictionResult:
    predicted_next: Float[Array, "1"]   # y_{t+1} (Espacio Z-Score)
    
    # Telemetría de Estado (S_risk)
    holder_exponent: Float[Array, "1"]  # H_t
    cusum_drift: Float[Array, "1"]      # G^+
    distance_to_collapse: Float[Array, "1"] # h - G^+
    free_energy: Float[Array, "1"]      # F (Energía JKO)
    
    # Telemetría Avanzada (Nuevas Adiciones)
    kurtosis: Float[Array, "1"]         # κ_t - Curtosis empírica de errores
    dgm_entropy: Float[Array, "1"]      # H_DGM - Entropía del predictor DGM (NaN si inactivo)
    adaptive_threshold: Float[Array, "1"] # h_t - Umbral CUSUM adaptativo
    
    # Estado del Orquestador
    weights: Float[Array, "4"]          # [rho_A, rho_B, rho_C, rho_D] (Simplex)
    
    # Flags de Salud y Control (Explícitos)
    sinkhorn_converged: Bool[Array, "1"] # Convergencia JKO
    degraded_inference_mode: bool       # TTL violation (congelamiento de pesos)
    emergency_mode: bool                # H_t < H_min (singularidad crítica)
    regime_change_detected: bool        # CUSUM alarm (G+ > h_t)
    mode_collapse_warning: bool         # H_DGM < γ·H[g] (colapso DGM)
    
    mode: str                           # "Standard" | "Robust" | "Emergency"
\end{lstlisting}

\section{Arquitectura Multitenencia (Stateless/Functional Pattern)}

Para soportar cientos de activos (Multi-Asset) en un solo servidor, la API soporta un modo puramente funcional. Esto permite gestionar el estado en bases de datos externas de baja latencia (Redis) y compartir el grafo de computación JAX compilado (el \texttt{Predictor}) entre todos los activos.

\subsection{Maximización de Throughput (Batching Vectorizado)}
Esta arquitectura habilita el uso de \texttt{jax.vmap} para procesar lotes de estados de múltiples activos en una sola llamada al hardware, minimizando el impacto del GIL de Python y maximizando la ocupación de la GPU.

\begin{lstlisting}[language=Python]
class FunctionalPredictor:
    """
    Implementación Stateless para JAX Core.
    Permite escalar a miles de predictores compartiendo la misma estructura computacional.
    """
    
    def __init__(self, config: PredictorConfig):
        # Compilación JIT única para todos los activos
        # Habilita vectorización automática (vmap) sobre la dimensión del batch (activos)
        self.config = config
        self._core_step = self._core_update_step
        self._jit_update = jax.jit(self._core_step)
        self._vmap_update = jax.jit(jax.vmap(self._core_step, in_axes=(0, 0, 0, 0)))

    def init_state(self):
        """Genera un estado cero inicial (cold state structure)."""
        return self._initialize_state_structure()

    def step(self, state, obs: MarketObservation) -> tuple[object, PredictionResult]:
        """
        Transición de Estado Pura: (S_t, Obs_t) -> (S_{t+1}, Pred_{t+1})
        """
        # 1. Validaciones (Outlier, Staleness, Nyquist) logic idéntica a UniversalPredictor
        # ... logic for freeze_weights flag calculation ...
        
        # 2. Ejecución Kernel JAX
        # Zero-Copy: La actualización de búferes ocurre dentro de XLA (dynamic_update_slice)
        new_state, raw_result = self._jit_update(
            state,  # Estado inyectado explícitamente desde Redis/Memoria
            obs.price, 
            obs.target, 
            freeze_weights=should_freeze
        )
        
        # 3. Mapeo de Resultados
        result = PredictionResult(
            predicted_next=raw_result.y_next,
            # ... resto de campos ...
        )
        
        return new_state, result
        
    def step_batch(self, states, obs_batch: MarketObservation):
        """
        Procesamiento vectorizado para N activos simultáneos.
        Utiliza vmap para paralelizar la inferencia y actualización.
        """
        # ... logic for batch flags ...
        new_states, results = self._vmap_update(states, obs_batch.price, obs_batch.target, freeze_flags)
        return new_states, results
\end{lstlisting}

\section{Clase Principal: \texttt{UniversalPredictor} (Stateful Wrapper)}

Esta clase envuelve el patrón funcional para casos de uso de un solo activo (Single-Tenant), manteniendo el estado en memoria local (\texttt{self.\_state}).

\subsection{Inicialización}

\begin{lstlisting}[language=Python]
class UniversalPredictor:
    def __init__(self, config: PredictorConfig):
        """
        Inicializa el grafo de cómputo JAX (XLA JIT compilation).
        Asigna memoria estática para los búferes en el dispositivo (VRAM).
        El estado interno (self._state) contiene los `jnp.array` persistentes (rolling buffers)
        que se actualizarán mediante operaciones funcionales (jnp.roll, lax.dynamic_update)
        para eliminar la latencia de transferencia de memoria (Zero-Copy).
        """
        self.config = config
        self._state = self._initialize_state() # Estado interno JAX (resident un GPU)
        self._jit_update = jax.jit(self._core_update_step)
        self._last_timestamp_ns = 0 # Para cálculo de frecuencia
        
    def fit_history(self, history: list[float]) -> bool:
        """
        Bootstrapping inicial (Protocolo de Cold Start).
        Procesa el lote histórico para estabilizar los pesos JKO y llenar los búferes.
        Requiere un mínimo de N_buf muestras.
        
        Returns:
            bool: True si el sistema alcanzó convergencia estable (Sinkhorn + CUSUM).
        Raises:
            ValueError: Si el historial es insuficiente (< wtmm_buffer_size).
            RuntimeError: Si el sistema diverge tras el calentamiento.
        """
        if len(history) < self.config.wtmm_buffer_size:
            raise ValueError(f"Historial insuficiente. Requerido: {self.config.wtmm_buffer_size}")
            
        # Ejecución batch acelerada (jax.lax.scan) para calentar el estado
        # Simula el paso del tiempo para llenar colas y estabilizar gradientes
        self._state, final_metrics = self._jit_scan_history(self._state, jnp.array(history))
        
        # Validación de Convergencia
        is_converged = final_metrics.sinkhorn_converged
        is_stable = final_metrics.cusum_drift < self.config.cusum_h
        
        if not (is_converged and is_stable):
             logger.warning("Cold Start finalizado sin convergencia estable.")
             return False
             
        return True
\end{lstlisting}

\subsection{Método de Ejecución (Paso \texorpdfstring{$t \to t+1$}{t -> t+1})}

\begin{lstlisting}[language=Python]
    def step(self, obs: MarketObservation) -> PredictionResult:
        """
        Ejecuta un ciclo completo de predicción.
        Maneja internamente la validación de dominio y TTL.
        """
        # 1. Validación de Dominio (Outlier Check)
        if not obs.validate_domain():
            logger.error("Outlier Catastrófico detectado. Ignorando tick.")
            return self._last_valid_result # Mantiene inercia
            
        # 2. Check de Abandono (Staleness) y Frecuencia (Anti-Aliasing)
        current_time = time.time_ns()
        latency = current_time - obs.timestamp_ns
        is_stale = latency > self.config.staleness_ttl_ns
        
        # Validación de Frecuencia Nyquist (WTMM Stability)
        dt_arrival = obs.timestamp_ns - self._last_timestamp_ns
        is_sparse = (self._last_timestamp_ns > 0) and (dt_arrival > self.config.besov_nyquist_interval_ns)
        
        if is_sparse:
             logger.warning(f"FrequencyWarning: Event interval {dt_arrival}ns > Nyquist limit. WTMM spectrum might alias.")
        
        self._last_timestamp_ns = obs.timestamp_ns
        
        # 3. Actualización Core (JAX) - Zero-Copy State Management
        # IMPORTANTE: El buffer de señal reside en GPU/TPU (self._state.signal_buffer).
        # La actualización se realiza "in-place" funcionalmente usando jax.lax.dynamic_update_slice
        # o jnp.roll dentro del kernel compilado para evitar transferencias CPU <-> VRAM.
        # Si hay staleness o sparsity excesiva, se congelan pesos para no degradar la geometría.
        should_freeze = is_stale or is_sparse
        
        new_state, result_data = self._jit_update(
            self._state, 
            obs.price, 
            obs.target, 
            freeze_weights=should_freeze,
            # No se pasa history_buffer explícitamente, ya vive en _state
        )
        
        self._state = new_state
        
        # 4. Empaquetado de Resultados
        return PredictionResult(
            predicted_next=result_data.y_next,
            holder_exponent=result_data.H_t,
            sinkhorn_converged=result_data.converged,
            is_stable=not (is_stale or is_sparse),
            # ... mapeo resto de campos
        )
\end{lstlisting}

\section{Prevención de Fragmentación de VRAM (JAX Memory Management)}

\textbf{Problema de Producción:} JAX preasigna el 90\% de la memoria GPU (VRAM) mediante el runtime XLA en el primer acceso, bajo el modelo \textit{single-GPU-device-per-process}. En sistemas de alta disponibilidad con ejecución continua, la fragmentación de memoria puede acumularse tras semanas de operación, causando \textbf{Out Of Memory (OOM)} silencioso o degradación de rendimiento.

\textbf{Escenario:}

\begin{enumerate}
    \item Proceso inicia y JAX asigna $\sim$90\% VRAM (ej. 36/40 GB en una GPU A100).
    \item Durante $N$ horas, se crean/liberan tensores temporales en el algoritmo de Sinkhorn, WTMM, DGM.
    \item El recolector de basura de Python libera memoria CPython, pero XLA mantiene fragmentos aislados.
    \item Tras $\sim$1-4 semanas: OOM silencioso en operación crítica (pérdida de predicción).
\end{enumerate}

\textbf{Solución: Control Granular de Asignación de VRAM}

Configurar dos variables de entorno críticas \textbf{ANTES} de importar JAX:

\begin{lstlisting}[language=Python]
import os

# PASO 1: Limitar asignación inicial de VRAM
# Por defecto JAX asigna 90% → reservar solo 70% para dejar margen
os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '0.7'

# PASO 2: Usar allocador "platform" para liberar dinámicamente si Python GC lo exige
# Opciones:
#   'platform' (recomendado): Libera memoria al solicitar el SO
#   'bfc'     (default): Caché de bloques fija (menos flexible)
os.environ['XLA_PYTHON_CLIENT_ALLOCATOR'] = 'platform'

# PASO 3: Habilitar protección contra fragmentación
os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # Permite crecimiento incremental

# Ahora importar JAX (después de fijar variables de entorno)
import jax
import jax.numpy as jnp

print(f"VRAM allocation: {jax.devices()}")
print(f"XLA allocator: platform (dynamic)")
\end{lstlisting}

\textbf{Implicaciones de Configuración:}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|l|}
\hline
\textbf{Variable} & \textbf{Default} & \textbf{Recomendado} & \textbf{Efecto} \\
\hline
\texttt{XLA\_PYTHON\_CLIENT\_MEM\_FRACTION} & 0.9 & 0.7 & Deja 30\% libre para I/O, SO, buffer \\
\texttt{XLA\_PYTHON\_CLIENT\_ALLOCATOR} & bfc & platform & Libera dinamicamente al GC \\
\texttt{TF\_FORCE\_GPU\_ALLOW\_GROWTH} & false & true & Crecimiento incremental (no prealloc) \\
\hline
\end{tabular}
\end{table}

\textbf{Análisis de VRAM Disponible:}

Asumiendo GPU A100 (40 GB):

\begin{itemize}
    \item \textbf{Sin configuración}: JAX asigna 36 GB → SO + threads + buffers tienen 4 GB
    \item \textbf{Con configuración}: JAX asigna 28 GB → margen de 12 GB para overhead
    \item Sistema más estable: mejor para operaciones fragmentadas (Sinkhorn iterativo, WTMM multiscala)
\end{itemize}

\textbf{Mitigación de Fragmentación: Estrategia de Pooling}

Además de las variables de entorno, implementar \textit{pool} de tensores pre-asignados para operaciones críticas:

\begin{lstlisting}[language=Python]
class VRAM_PooledAllocator:
    def __init__(self, device_memory_budget_gb: float = 28.0, pool_size: int = 100):
        """
        Crea un pool de tensores pre-asignados para reducir fragmentación.
        """
        self.device_budget_bytes = device_memory_budget_gb * 1e9
        self.pool = []
        self.available = []
        
        # Pre-asignar tensores comunes (ej. buffers de Sinkhorn)
        for i in range(pool_size):
            tensor = jnp.zeros((1024, 1024), dtype=jnp.float32)  # ~4MB
            self.pool.append(tensor)
            self.available.append(True)
    
    def acquire_tensor(self, shape, dtype=jnp.float32):
        """Obtiene tensor del pool sin fragmentar VRAM."""
        for idx, available in enumerate(self.available):
            if available:
                self.available[idx] = False
                return self.pool[idx]
        
        # Si no hay disponible, crear temporalmente
        return jax.device_put(jnp.zeros(shape, dtype=dtype))
    
    def release_tensor(self, idx):
        """Devuelve tensor al pool."""
        if idx < len(self.available):
            self.available[idx] = True
    
    def memory_utilization_percent(self):
        """Reporta fragmentación."""
        used = sum(1 for av in self.available if not av)
        return 100.0 * used / len(self.available)
\end{lstlisting}

\textbf{Monitoreo de Fragmentación:}

\begin{lstlisting}[language=Python]
import psutil
import subprocess

def monitor_vram_fragmentation(interval_seconds=60):
    """
    Thread de monitoreo que reporta fragmentación de VRAM.
    """
    import time
    import threading
    
    def _monitor():
        while True:
            try:
                # Consultar nvidia-smi para obtener uso real
                result = subprocess.run(
                    ['nvidia-smi', '--query-gpu=memory.used,memory.total',
                     '--format=csv,nounits,noheader'],
                    capture_output=True, text=True, timeout=5
                )
                
                if result.returncode == 0:
                    used, total = map(float, result.stdout.strip().split(','))
                    utilization = 100.0 * used / total
                    
                    if utilization > 0.95:
                        print(f"[WARNING] VRAM near saturation: {utilization:.1f}%")
                    elif utilization > 0.85:
                        print(f"[INFO] VRAM utilization: {utilization:.1f}% (elevated)")
                
                time.sleep(interval_seconds)
            except Exception as e:
                print(f"[ERROR] VRAM monitoring failed: {e}")
                break
    
    thread = threading.Thread(target=_monitor, daemon=True)
    thread.start()
\end{lstlisting}

\textbf{Configuración de Despliegue Recomendada:}

\begin{lstlisting}[language=bash]
#!/bin/bash
# deployment/run_predictor.sh

# Variables de entorno CRÍTICAS para producción
export XLA_PYTHON_CLIENT_MEM_FRACTION=0.7
export XLA_PYTHON_CLIENT_ALLOCATOR=platform
export TF_FORCE_GPU_ALLOW_GROWTH=true

# Logs de configuración
echo "[INFO] XLA VRAM Fraction: 0.7 (28/40 GB en A100)"
echo "[INFO] Allocator: platform (dynamic)"
echo "[INFO] GPU growth: enabled"

# Ejecutar predictor
python3 -u predictor_service.py \
    --config config.yaml \
    --device gpu \
    --pool-size 100 \
    --monitor-interval 300
\end{lstlisting}

\textbf{Garantías de Confiabilidad:}

\begin{itemize}
    \item \textbf{Sin OOM Silencioso}: Margen de 30\% previene asignaciones inesperadas.
    \item \textbf{Fragmentación Reducida}: Allocador \texttt{platform} libera agresivamente.
    \item \textbf{Uptime Sostenido}: Pool predefinido evita picos de asignación.
    \item \textbf{Degradación Gradual}: Monitoreo detecta saturación tempranamente.
\end{itemize}

\section{Persistencia (Atomic Snapshotting)}

El sistema implementa persistencia binaria protegida por checksum.

\begin{lstlisting}[language=Python]
import hashlib
import msgpack

    def save_snapshot(self, filepath: str):
        """
        Exporta el estado interno Sigma_t a formato binario (MessagePack).
        Incluye Checksum SHA-256 al final del archivo.
        """
        # Serialización de tensores JAX a bytes
        state_dict = self._serialize_jax_state(self._state)
        
        # Segmentación Modular (K-Blocks)
        # IMPORTANTE: Incluir versionado de schema para evitar errores al cargar
        # snapshots generados con versiones antiguas (cambios en profundidad de firma, etc.)
        payload = {
            "schema_version": self.config.schema_version,  # Versionado seguro
            "timestamp": time.time_ns(),
            "config": asdict(self.config),
            "global": state_dict["global"], # rho, G+, ema
            "telemetry": {
                "kurtosis": float(self._state.kurtosis),
                "dgm_entropy": float(self._state.dgm_entropy),
                "adaptive_threshold": float(self._state.h_adaptive)
            },
            "flags": {
                "degraded_inference": bool(self._state.degraded_mode),
                "emergency": bool(self._state.emergency_mode),
                "regime_change": bool(self._state.regime_changed),
                "mode_collapse": bool(self._state.mode_collapse_warning)
            },
            "kernels": {
                "A": state_dict["kernel_a"],
                "B": state_dict["kernel_b"],
                "C": state_dict["kernel_c"],
                "D": state_dict["kernel_d"]
            }
        }
        
        data_bytes = msgpack.packb(payload)
        checksum = hashlib.sha256(data_bytes).hexdigest()
        
        with open(filepath, "wb") as f:
            f.write(data_bytes)
            f.write(checksum.encode('utf-8')) # Append hash
            
    def load_snapshot(self, filepath: str):
        """
        Carga estado. Valida SHA-256 y schema_version antes de deserializar.
        Lanza ValueError si falla la validación o schema incompatible.
        """
        with open(filepath, "rb") as f:
            content = f.read()
            
        data_bytes = content[:-64] # Todo menos los últimos 64 bytes (SHA256 hex)
        stored_checksum = content[-64:].decode('utf-8')
        
        computed = hashlib.sha256(data_bytes).hexdigest()
        if computed != stored_checksum:
            raise ValueError("Snapshot corrupto: Checksum mismatch.")
        
        payload = msgpack.unpackb(data_bytes)
        
        # Validar schema_version para detectar incompatibilidades
        loaded_schema = payload.get('schema_version', 'unknown')
        if loaded_schema != self.config.schema_version:
            raise ValueError(
                f"Schema version mismatch: snapshot={loaded_schema}, "
                f"current={self.config.schema_version}. "
                f"Cannot load snapshot generated with incompatible kernel depths or signature features."
            )
        
        self._state = self._deserialize_jax_state(payload)
\end{lstlisting}

\section{I/O Asíncrono para Snapshots (Non-Blocking)}

\textbf{Problema de Latencia:} La función \texttt{save\_snapshot()} invoca operaciones síncronas de I/O:

\begin{enumerate}
    \item Serialización MessagePack del estado (microsegundos)
    \item \textbf{Escritura a disco} (milisegundos: 1--100 ms según velocidad de almacenamiento)
    \item \textbf{Cálculo SHA-256} en los datos (milisegundos: 2--50 ms para estados de 1--100 MB)
\end{enumerate}

Si estas operaciones se ejecutan en el hilo principal del predictor, contaminan el \textit{jitter} de latencia en la predicción:

\begin{itemize}
    \item El reloj de predicción (ingesta de datos $\rightarrow$ forward pass de 4 ramas $\rightarrow$ actualización orquestador) se bloquea.
    \item En mercados H.F., una desviación de 50 ms es catastrófica (oportunidades perdidas).
    \item El SLA (Service Level Agreement) de latencia P99 se degrada irremediablemente.
\end{itemize}

\textbf{Solución: Delegación Asíncrona a ThreadPoolExecutor}

El cálculo de checksum y la escritura a disco se delegan a un \textit{thread pool} dedicado, permitiendo que el hilo principal continúe sin obstáculos:

\begin{lstlisting}[language=Python]
import concurrent.futures
import hashlib
import msgpack
import threading
import time

class UniversalPredictor_AsyncIO:
    def __init__(self, n_worker_threads=2):
        # Pool de threads dedicados a I/O (no interfieren con inferencia)
        self.io_executor = concurrent.futures.ThreadPoolExecutor(
            max_workers=n_worker_threads,
            thread_name_prefix="snapshot_io_"
        )
        
        # Futuro del snapshot en vuelo para monitoreo (opcional)
        self.pending_snapshot_future = None
        self.snapshot_lock = threading.Lock()
    
    def _compute_and_save_async(self, filepath: str, data_bytes: bytes):
        """
        Ejecuta en thread pool: calcula checksum y escribe a disco.
        No bloquea el hilo principal.
        """
        checksum = hashlib.sha256(data_bytes).hexdigest()
        
        # Escritura atómica (write + rename) para evitar estado intermedio
        temp_filepath = filepath + ".tmp"
        
        try:
            with open(temp_filepath, "wb") as f:
                f.write(data_bytes)
                f.write(checksum.encode('utf-8'))
            
            # Rename atómico (POSIX-compliant)
            import os
            os.replace(temp_filepath, filepath)
            
            return {
                'status': 'success',
                'filepath': filepath,
                'filesize_bytes': len(data_bytes),
                'checksum': checksum,
                'timestamp': time.time()
            }
        except Exception as e:
            return {
                'status': 'error',
                'filepath': filepath,
                'error': str(e),
                'timestamp': time.time()
            }
    
    def save_snapshot_nonblocking(self, filepath: str) -> concurrent.futures.Future:
        """
        Exporta estado a snapshot sin bloquear el hilo de inferencia.
        
        Retorna un Future<dict>. El llamante puede:
        - Ignorarlo (fire-and-forget): permitir que escriba en background
        - Esperar con .result(timeout=N): bloquear solo si es necesario (monitoreo)
        
        Arquitectura:
        1. Main thread: Serialización MessagePack (rápido: microsegundos)
        2. Main thread: Retorna control inmediatamente
        3. Worker thread: Cálculo SHA-256 + escritura a disco (en background)
        """
        
        # Paso 1: Serialización (en el hilo principal, muy rápido)
        state_dict = self._serialize_jax_state(self._state)
        
        payload = {
            "schema_version": self.config.schema_version,
            "timestamp": time.time_ns(),
            "config": asdict(self.config),
            "global": state_dict["global"],
            "telemetry": {
                "kurtosis": float(self._state.kurtosis),
                "dgm_entropy": float(self._state.dgm_entropy),
                "adaptive_threshold": float(self._state.h_adaptive)
            },
            "flags": {
                "degraded_inference": bool(self._state.degraded_mode),
                "emergency": bool(self._state.emergency_mode),
                "regime_change": bool(self._state.regime_changed),
                "mode_collapse": bool(self._state.mode_collapse_warning)
            },
            "kernels": {
                "A": state_dict["kernel_a"],
                "B": state_dict["kernel_b"],
                "C": state_dict["kernel_c"],
                "D": state_dict["kernel_d"]
            }
        }
        
        data_bytes = msgpack.packb(payload)
        
        # Paso 2: Delegar I/O a thread pool (no-bloqueante)
        future = self.io_executor.submit(
            self._compute_and_save_async,
            filepath,
            data_bytes
        )
        
        # Mantener referencia al Future para debugging (opcional)
        with self.snapshot_lock:
            self.pending_snapshot_future = future
        
        return future
    
    def predict_step_with_async_checkpoint(self, x_t: jnp.ndarray) -> Tuple[jnp.ndarray, Optional[concurrent.futures.Future]]:
        """
        Paso de predicción con snapshot asíncrono periódico.
        
        El snapshot se dispara cada N pasos pero NO interfiere con latencia de inferencia.
        """
        # Predicción principal (hot path)
        prediction = self._predict_step_core(x_t)
        
        # Checkpoint asíncrono si es el momento
        snapshot_future = None
        if self.step_counter % self.checkpoint_interval == 0:
            checkpoint_path = f"{self.checkpoint_dir}/snapshot_step_{self.step_counter}.msgpack"
            snapshot_future = self.save_snapshot_nonblocking(checkpoint_path)
            # El hilo retorna SIN esperar a que el snapshot se escriba a disco
        
        self.step_counter += 1
        return prediction, snapshot_future
    
    def monitor_snapshot_queue(self):
        """
        Thread de monitoreo (opcional) que reporta el estado de snapshots en vuelo.
        Ejecutado en otro thread para no interferir.
        """
        while not self.shutdown_event.wait(timeout=5.0):
            with self.snapshot_lock:
                if self.pending_snapshot_future is not None:
                    if self.pending_snapshot_future.done():
                        try:
                            result = self.pending_snapshot_future.result()
                            if result['status'] == 'success':
                                print(f"[INFO] Snapshot guardado: {result['filepath']} "
                                      f"({result['filesize_bytes']} bytes)")
                            else:
                                print(f"[WARNING] Snapshot falló: {result['error']}")
                        except Exception as e:
                            print(f"[ERROR] Future exception: {e}")
    
    def graceful_shutdown(self, timeout_seconds=10):
        """
        Aguarda a que todos los snapshots pendientes se completen antes de cerrar.
        """
        print("[INFO] Aguardando snapshots pendientes...")
        
        # Esperar a que se completen (con timeout)
        concurrent.futures.wait(
            [self.pending_snapshot_future] if self.pending_snapshot_future else [],
            timeout=timeout_seconds
        )
        
        # Cerrar pool
        self.io_executor.shutdown(wait=True)
        print("[INFO] ThreadPoolExecutor cerrado gracefully")
\end{lstlisting}

\textbf{Implicaciones de Performance:}

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|}
\hline
\textbf{Operación} & \textbf{Latencia (ms)} & \textbf{Hilo} \\
\hline
Serialización MessagePack & 0.1--0.5 & Principal (hot path) \\
SHA-256 en 10 MB & 5--15 & Worker (background) \\
Escritura a disco & 2--50 & Worker (background) \\
\hline
\textbf{Latencia observed por predictor} & \textbf{0.1--0.5} & \textbf{Principal} \\
\hline
\end{tabular}
\end{table}

Sin I/O asíncrono: latencia observada $\sim$ 7--65 ms  
Con I/O asíncrono: latencia observada $\sim$ 0.1--0.5 ms  
\textbf{Factor de mejora: 14--130x}

\textbf{Garantías Operacionales:}

\begin{itemize}
    \item \textbf{Fire-and-Forget}: Ignorar el Future retornado permite que el snapshot se escriba en background sin interferencia.
    
    \item \textbf{Integridad Atómica}: Escritura a archivo temporal seguida de rename POSIX garantiza que no hay snapshots corruptos parciales.
    
    \item \textbf{Monitoreo Opcional}: El thread \texttt{monitor\_snapshot\_queue()} reporta estado sin afectar predicción (ejecutado en thread separado).
    
    \item \textbf{Graceful Shutdown}: \texttt{graceful\_shutdown()} aguarda a snapshots pendientes antes de terminar proceso.
    
    \item \textbf{SLA Garantizado}: Arquitectura no-bloqueante asegura que \textbf{P99 latencia} se mantiene $\leq$ 1 ms incluso durante I/O intensivo.
\end{itemize}

\textbf{Configuración Recomendada:}

\begin{lstlisting}[language=Python]
predictor = UniversalPredictor_AsyncIO(
    n_worker_threads=2,  # Típicamente 1-2 threads suficientes
    checkpoint_interval=1000  # Cada 1000 pasos (~1 segundo en latencia 1ms)
)

# En el loop de trading/predicción:
for x_t in market_stream:
    prediction, snapshot_future = predictor.predict_step_with_async_checkpoint(x_t)
    
    # USA prediction inmediatamente
    # El snapshot se escribirá en background
    if snapshot_future is not None:
        # Opcional: esperar solo en situaciones críticas (ej. antes de shutdown)
        snapshot_result = snapshot_future.result(timeout=30)
\end{lstlisting}

\section{Ajuste Adaptativo del Umbral CUSUM}

El sistema implementa el \textbf{Lema de Umbral Adaptativo} basado en curtosis, permitiendo que el detector CUSUM se ajuste automáticamente a regímenes con colas pesadas.

\subsection{Fórmula de Ajuste}

El umbral de detección de cambio de régimen se calcula dinámicamente:

\[
h_t = k \cdot \sigma_t \cdot \left(1 + \ln\left(\frac{\kappa_t}{3}\right)\right)
\]

donde:
\begin{itemize}
    \item $k$: Slack calibrado (\texttt{cusum\_k} en configuración)
    \item $\sigma_t$: Volatilidad EMA del error de predicción
    \item $\kappa_t$: Curtosis empírica móvil (ventana de 252 pasos)
    \item $3$: Curtosis de referencia Gaussiana
\end{itemize}

\subsection{Interpretación de Curtosis}

\begin{table}[h]
\centering
\begin{tabular}{|c|l|}
\hline
\textbf{Rango $\kappa_t$} & \textbf{Régimen de Mercado} \\
\hline
$\kappa_t \approx 3$ & Gaussiano (mercado normal) \\
$\kappa_t \in [5,10]$ & Volatilidad financiera estándar \\
$\kappa_t \in [10,15]$ & Alta volatilidad (eventos outlier) \\
$\kappa_t > 15$ & Régimen de crisis (colas pesadas) \\
$\kappa_t > 20$ & Falla en modelo de residuos (alerta crítica) \\
\hline
\end{tabular}
\caption{Interpretación de curtosis empírica}
\end{table}

\textbf{Nota:} El ajuste logarítmico permite que el umbral se expanda automáticamente cuando $\kappa_t > 3$, evitando falsos positivos en regímenes de alta curtosis mientras mantiene sensibilidad a cambios estructurales genuinos.

\section{Periodo de Gracia (Ventana Refractaria) Post-Cambio de Régimen}

\subsection{Motivación}

Cuando CUSUM detecta un cambio de régimen ($G^+ > h_t$), el orquestador reinicia los pesos a distribución uniforme y reseta los acumuladores CUSUM. Sin embargo, en los pasos inmediatos posteriores:

\begin{itemize}
    \item \textbf{Volatilidad inflada:} El error de predicción $e_t$ se vuelve temporalmente grande porque los nuevos pesos uniformes aún no se han optimizado.
    \item \textbf{Curtosis elevada:} El buffer de errores refuerza momentáneamente momentos de alto orden.
    \item \textbf{Cascada de falsas alarmas:} CUSUM podría detectar "otro cambio" basándose en ruido de recalibración, no en genuina ruptura estructural.
\end{itemize}

Esto puede causar oscilación patológica donde el sistema alterna entre reinicio uniforme y redetección espuria.

\subsection{Solución: Grace Period (Refractario)}

Se introduce un parámetro \texttt{grace\_period\_steps} en \texttt{PredictorConfig} (por defecto 20-50 pasos):

\[
\text{CUSUM\_silenciado} = (\text{pasos\_desde\_último\_cambio} < \text{grace\_period\_steps})
\]

\textbf{Durante el período de gracia:}
\begin{enumerate}
    \item El detector CUSUM calcula su estadística $G^+$ internamente (para diagnóstico)
    \item \textbf{Pero no emite alarma} ($\text{regime\_change\_detected} = \text{False}$) aunque $G^+ > h_t$
    \item El acumulador $G^+$ se mantiene en reset ($G^+ = 0$ al inicio del glance)
    \item Permiten que los pesos converjan bajo el algoritmo JKO sin interrupciones
\end{enumerate}

\textbf{Transcurrido el período:}
\begin{itemize}
    \item CUSUM vuelve a estado operacional normal
    \item Próxima detección de cambio (si ocurre) desencadena nuevo período de gracia
\end{itemize}

\subsection{Algoritmo de Implementación}

\begin{lstlisting}[language=Python]
class CUSUMState:
    def __init__(self, grace_period_steps=20):
        self.g_plus = 0.0
        self.g_minus = 0.0
        self.error_sq_ema = 0.0
        self.steps_since_regime_change = 0
        self.grace_period = grace_period_steps
    
    def step(self, error, sigma_t, kurtosis):
        """Avanza el estado CUSUM con silenciamiento refractario."""
        # Incrementar contador desde último cambio
        self.steps_since_regime_change += 1
        
        # Calcular estadística (siempre)
        k = self.config.cusum_k
        h_adaptive = k * sigma_t * (1 + np.log(max(kurtosis, 1.0) / 3.0))
        
        s_standardized = np.abs(error) / sigma_t
        s_centered = s_standardized - 1.0
        
        self.g_plus = max(0.0, self.g_plus + s_centered - k)
        
        # Lógica de alarma CON GRACIA
        is_in_grace_period = (
            self.steps_since_regime_change < self.grace_period
        )
        
        if is_in_grace_period:
            # Silenciar: no emitir alarma
            alarm = False
        else:
            # Normal: comparar con umbral
            alarm = (self.g_plus > h_adaptive)
        
        return alarm, self.g_plus, h_adaptive
    
    def reset_on_regime_change(self):
        """Al detectar cambio, iniciar período de gracia."""
        self.g_plus = 0.0
        self.steps_since_regime_change = 0  # Reiniciar reloj
\end{lstlisting}

\subsection{Parámetros Sugeridos}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|l|}
\hline
\textbf{grace\_period\_steps} & \textbf{Escenario} & \textbf{Justificación} \\
\hline
10-15 & Mercados estables, baja latencia & Recalibración rápida \\
20-30 & Mercados con volatilidad media & Balance entre estabilidad y reactividad \\
40-50 & Mercados de alta turbulencia & Mayor tiempo para convergencia JKO \\
60+ & Instrumentos ilíquidos o con gaps & Minimizar oscilaciones patológicas \\
\hline
\end{tabular}
\caption{Recomendaciones para grace\_period\_steps según régimen}
\end{table}

\subsection{Diagnóstico y Telemetría}

Se recomienda registrar (sin decidir) durante el período de gracia:
\begin{itemize}
    \item $G^+$ observable (si hubiera alarma)
    \item $\sigma_t$ y $\kappa_t$ instantáneos
    \item Convergencia del JKO (distancia Wasserstein a cada paso)
\end{itemize}

Esto permite post-hoc análisis de si el período fue suficiente o excesivo.

\section{Flags de Operación y Recuperación}

El sistema mantiene cuatro flags booleanos explícitos que señalizan estados críticos al ejecutor:

\subsection{DegradedInferenceMode}

\textbf{Condición de activación:}
\[
\text{TTL}(y_{\text{target}}) = t_{\text{current}} - t_{\text{signal}} > \Delta_{\text{max}}
\]

\textbf{Implicaciones operacionales:}
\begin{enumerate}
    \item Suspende actualización del transporte JKO inmediatamente
    \item Congela pesos $\rho$ en último valor válido (modo inercial)
    \item Predicciones continúan generándose pero con confianza degradada
    \item Riesgo NO está siendo optimizado geométricamente
\end{enumerate}

\textbf{Recuperación con histéresis:}
\[
\text{TTL}(y_{\text{target}}) < h_{\text{hyst}} \cdot \Delta_{\text{max}}
\]

donde $h_{\text{hyst}} = \texttt{inference\_recovery\_hysteresis}$ (por defecto 0.8) parametrizable en PredictorConfig.

Se emite \texttt{NormalOperationRestoredEvent} al recuperar.

\subsection{EmergencyMode}

\textbf{Condición:} $H_t < H_{\text{min}}$ (singularidad crítica detectada)

\textbf{Acción:} Fuerza $w_D \to 1.0$ (Kernel D de signatures) y cambia a métrica de Huber robusta.

\subsection{RegimeChangeDetected}

\textbf{Condición:} $G^+ > h_t$ (CUSUM detecta cambio de régimen)

\textbf{Acción:} Reinicio de entropía a distribución uniforme y reset de acumuladores.

\subsection{ModeCollapseWarning}

\textbf{Condición:} $H_{\text{DGM}} < \gamma \cdot H[g]$ durante $> 10$ pasos consecutivos (solo relevante si $\rho_B > 0.05$)

\textbf{Acción correctiva:} Reducir $\rho_B \to 0$ hasta re-entrenar red DGM.

\subsection{Período de Gracia (Refractario) Post-Cambio de Régimen}

\textbf{Motivación:} Cuando CUSUM detecta un cambio de régimen y resetea los pesos a distribución uniforme, la curtosis y varianza residual se vuelven \textbf{transitoriamente infladas} mientras los filtros (SIA, WTMM, EMA) se recalibran. Sin protección, esto provoca \textbf{cascadas de falsos positivos} inmediatos: el sistema detecta el mismo cambio repetidamente en los siguientes 5-10 pasos.

\textbf{Solución:} Introducir un contador refractario que \textbf{silencia CUSUM temporalmente} tras la detección de cambio.

\subsubsection{Implementación}

Dentro del estado interno del predictor, se mantiene un contador:

\begin{lstlisting}[language=Python]
@dataclass
class PredictorState:
    # ... otros campos ...
    grace_period_counter: int = 0  # Contador refractario (decrementado cada paso)
    regime_change_locked: bool = False  # Flag de bloqueo durante gracia
\end{lstlisting}

La lógica en el núcleo de actualización (dentro de \texttt{\_core\_update\_step}) es:

\begin{lstlisting}[language=Python]
def _core_update_step(state, price, target, freeze_weights=False):
    # ... paso de identificación (SIA, WTMM) ...
    
    # Calcular CUSUM normalmente
    raw_alarm = self._check_regime_change_with_kurtosis(error)
    
    # Aplicar período de gracia: silenciar falsa alarma si dentro de gracia
    if state.grace_period_counter > 0:
        raw_alarm = False  # Suprimir detección durante refractario
        state.grace_period_counter -= 1
        state.regime_change_locked = True
    else:
        state.regime_change_locked = False
    
    # Si se detecta cambio FUERA del período de gracia, resetear contador
    if raw_alarm and not state.regime_change_locked:
        state.grace_period_counter = self.config.grace_period_steps
        # Reiniciar pesos a uniforme, resetear acumuladores
        weights = jnp.ones(4) / 4.0
        cusum_state['g_plus'] = 0.0
    
    # ... resto de la lógica ...
    return new_state, result
\end{lstlisting}

\subsubsection{Dinámica Temporal}

\textbf{Ejemplo}: Con \texttt{grace\_period\_steps=20}:

\begin{table}[h]
\centering
\begin{tabular}{|l|c|c|c|}
\hline
\textbf{Paso} & \textbf{CUSUM Crudo} & \textbf{Contador Gracia} & \textbf{Alarma Emitida} \\
\hline
$t=0$ & \texttt{False} & 0 & \texttt{False} \\
$t=1$ & \texttt{True} & 0 & \texttt{True} $\Rightarrow$ Cambio detectado \\
$t=2$ & \texttt{True} & 19 & \texttt{False} (silenciado) \\
$t=3$ & \texttt{True} & 18 & \texttt{False} (silenciado) \\
\vdots & \vdots & \vdots & \vdots \\
$t=20$ & \texttt{True} & 1 & \texttt{False} (silenciado) \\
$t=21$ & \texttt{True} & 0 & \texttt{True} $\Rightarrow$ Nueva alarma (fin gracia) \\
\hline
\end{tabular}
\caption{Evolución del contador de gracia con detecciones repetidas}
\end{table}

\textbf{Interpretación:}
\begin{enumerate}
    \item En $t=1$: Cambio genuino detectado. Se resetean pesos, inicia contador \texttt{grace\_period\_counter=20}.
    \item En $t \in [2, 20]$: Aunque CUSUM crudo sigue alto (inflación transitoria), la alarma es \textbf{suprimida}. El sistema se recalibra en silencio.
    \item En $t=21$ (fin del período): Si la volatilidad persiste (e.g., un verdadero régimen de crisis), la alarma se re-emite. Si fue transitorio, CUSUM se normaliza.
\end{enumerate}

\subsubsection{Parámetros Recomendados}

\begin{itemize}
    \item \textbf{grace\_period\_steps}: Típicamente $10-50$ pasos.
    \begin{itemize}
        \item \textbf{10-15 pasos}: Para mercados de alta frecuencia (> 1 kHz). Recalibración rápida.
        \item \textbf{20-30 pasos}: Para operaciones intraday (1-100 Hz). Balance entre rechazo de ruido y reacción.
        \item \textbf{40-50 pasos}: Para datos de baja frecuencia (< 1 Hz). Permite amortiguamiento completo de transiente.
    \end{itemize}
    Entre mercados: Calibrar via \texttt{optuna.optimize()} sobre ventanas de validación histórica, minimizando tasa de falsas alarmas dentro de 30 minutos post-cambio.
\end{itemize}

\subsubsection{Ventajas}

\begin{itemize}
    \item \textbf{Evita Cascadas:} Una sola alarma genuina no dispara falsos positivos en cadena.
    \item \textbf{Permite Recalibración:} Los filtros (SIA, curtosis, varianza) tienen tiempo para estabilizarse sin distorsiones retroactivas.
    \item \textbf{Preserva Reactividad:} Tras el período de gracia, el sistema es tan reactivo como antes.
    \item \textbf{Parametrizable:} Fácil sintonización per-activo o per-mercado.
\end{itemize}

\section{Manejo de Errores y Excepciones}

\subsection{Excepciones Estándar}

\begin{itemize}
    \item \texttt{DomainError}: Se lanza (o se loguea crítico) si $y_t$ excede los límites (Outlier Catastrófico $> 20\sigma$).
    \item \texttt{StalenessWarning}: Emitido mediante el sistema de logging estándar de Python cuando se activa la protección TTL.
    \item \texttt{FrequencyWarning}: Alerta si la tasa de arribo de eventos cae por debajo del límite de Nyquist para el análisis de Besov.
    \item \texttt{IntegrityError}: Fallo crítico en la carga de snapshot. El sistema debe abortar y solicitar reinicio en frío.
\end{itemize}

\subsection{Alertas Específicas Avanzadas}

\begin{itemize}
    \item \texttt{ModeDegradationAlert}: Se emite cuando $H_{\text{DGM}}$ viola umbral durante $> 10$ pasos consecutivos. Indica colapso de modo en el predictor neuronal DGM (Rama B).
    
    \item \texttt{KurtosisOutlierWarning}: Se emite si $\kappa_t > 20$ de forma persistente ($> 5$ pasos consecutivos). Señala falla potencial en el modelo de residuos y sugiere revisión de arquitectura.
    
    \item \texttt{NormalOperationRestoredEvent}: Se emite al recuperar de \texttt{DegradedInferenceMode} (cuando TTL vuelve bajo el umbral con histéresis). Señaliza al ejecutor que puede retomar operación normal.
\end{itemize}

\subsection{Ejemplo de Logging en Producción}

\begin{lstlisting}[language=Python]
import logging
import os
from datetime import datetime

def save_emergency_dump(predictor, result, asset_id: str):
    """
    Guarda un "Dump de Depuración" completo cuando se activa EmergencyMode.
    Incluye: estado de pesos, buffer de señales, historial de telemetría.
    """
    dump_dir = os.path.expanduser("~/.predictor_emergency_dumps")
    os.makedirs(dump_dir, exist_ok=True)
    
    timestamp = datetime.now().isoformat()
    dump_file = f"{dump_dir}/{asset_id}_emergency_{timestamp}.msgpack"
    
    debug_payload = {
        "emergency_timestamp": timestamp,
        "asset_id": asset_id,
        "holder_exponent": float(result.holder_exponent),
        "weights": [float(w) for w in result.weights],
        "signal_buffer": predictor._state.signal_circular_buffer.tolist(),
        "regime_history": predictor._state.cusum_history.tolist(),
        "telemetry_snapshot": {
            "kurtosis": float(result.kurtosis),
            "dgm_entropy": float(result.dgm_entropy),
            "adaptive_threshold": float(result.adaptive_threshold),
            "distance_to_collapse": float(result.distance_to_collapse)
        },
        "flags_at_emergency": {
            "degraded_inference": bool(result.degraded_inference_mode),
            "regime_change": bool(result.regime_change_detected),
            "mode_collapse": bool(result.mode_collapse_warning)
        }
    }
    
    with open(dump_file, "wb") as f:
        msgpack.packb(debug_payload, file=f)
    
    logging.critical(f"Emergency dump saved to {dump_file} for forensius analysis")

def process_prediction(predictor, obs):
    result = predictor.step(obs)
    asset_id = obs.asset_id if hasattr(obs, 'asset_id') else "unknown"
    
    # Flags críticos
    if result.degraded_inference_mode:
        logging.warning(
            "DEGRADED MODE: TTL exceeded. Weights frozen. "
            "Consider reducing position size."
        )
    
    if result.emergency_mode:
        logging.critical(
            f"EMERGENCY: Singularity detected (H={result.holder_exponent:.3f}). "
            "Forcing Kernel D with Huber loss."
        )
        # Guardar dump automáticamente para análisis post-mortem
        save_emergency_dump(predictor, result, asset_id)
    
    if result.mode_collapse_warning:
        logging.error(
            f"MODE COLLAPSE: DGM entropy below threshold. "
            f"H_DGM = {result.dgm_entropy:.3f}. "
            "Reducing rho_B -> 0."
        )
    
    if result.kurtosis > 20.0:
        logging.warning(
            f"KURTOSIS OUTLIER: kappa = {result.kurtosis:.2f} > 20. "
            "Residual model may be invalid."
        )
    
    return result
\end{lstlisting}

\section{Detección de Mode Collapse en DGM}

El sistema monitoriza la entropía diferencial del predictor neuronal (Rama B) para detectar colapso a soluciones triviales.

\subsection{Criterio de Detección}

La entropía diferencial de la solución DGM $V_\theta(x,t)$ se calcula como:

\[
H_{\text{DGM}} = -\int p_V(v) \log p_V(v) \, dv
\]

se compara contra la entropía de la condición terminal $H[g]$:

\[
H_{\text{DGM}} \geq \gamma \cdot H[g], \quad \gamma \in [0.5, 1.0]
\]

Si la violación persiste durante $> 10$ pasos consecutivos, se activa \texttt{mode\_collapse\_warning}.

\subsection{Acción Correctiva}

El orquestador JKO debe reducir el peso de la Rama B:

\[
\rho_B \to 0
\]

hasta que se re-entrene la red neuronal DGM con hiperparámetros ajustados (tasa de aprendizaje, arquitectura, inicialización).

\textbf{Nota Teórica:} Una solución colapsada tiene $H[V_\theta] \to -\infty$ (distribución delta), correspondiendo a una política de control degenerada que no responde a variaciones del estado.

\section{Determinismo de Punto Flotante (Bit-Exact Reproducibility)}

\textbf{Problema:} Para validar la consistencia del sistema en \textbf{tests de portabilidad} (ejecución en CPU vs GPU vs FPGA, descritos en \textit{Pruebas.tex}), los cálculos de punto flotante deben ser estrictamente deterministas. Sin embargo, JAX compila a código XLA que puede reordenar operaciones de reducción (ej. \texttt{jax.numpy.sum}, llamadas en el algoritmo de Sinkhorn) dependiendo del backend.

\textbf{Impacto:}
\begin{itemize}
    \item En CPU: suma secuencial $\to$ error de redondeo $\epsilon_{\text{CPU}}$
    \item En GPU: suma paralela con diferentes agrupaciones $\to$ error $\epsilon_{\text{GPU}} \neq \epsilon_{\text{CPU}}$
    \item En FPGA: precisión de punto flotante custom $\to$ error $\epsilon_{\text{FPGA}}$
\end{itemize}

Aunque todos los valores sean matemáticamente correctos (dentro de tolerancia numérica), el \textit{bit-exact} resultado difiere, rompiendo tests determinísticos de regresión.

\textbf{Solución: Configuración Determinista de XLA y PRNG Fijo}

Fijar las variables de entorno antes de importar JAX:

\begin{lstlisting}[language=Python]
import os
import jax
import jax.numpy as jnp

# PASO 1: Configurar variables de entorno ANTES de cualquier operación JAX
os.environ['XLA_FLAGS'] = '--xla_cpu_use_cross_replica_callbacks=false'
os.environ['JAX_DETERMINISTIC_REDUCTIONS'] = '1'  # Force deterministic reductions
os.environ['JAX_TRACEBACK_FILTERING'] = 'off'     # Completo traceback para debugging

# Alternativas según backend:
# Para GPU (CUDA):
# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
# os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'  # Fijo cuBLAS workspace

# Para forzar CPU (deshabilitar GPU):
# os.environ['JAX_PLATFORMS'] = 'cpu'

# PASO 2: Fijar semillas globales de PRNG
import numpy as np

RANDOM_SEED = 42  # Determinista en todos los backends

# Semilla NumPy
np.random.seed(RANDOM_SEED)

# Semilla JAX (RNG de clave)
from jax import random
jax.config.update('jax_default_prng_impl', 'threefry2x32')  # Determinista entre backends
key = random.PRNGKey(RANDOM_SEED)

# PASO 3: Importar y configurar JAX después de las variables de entorno
jax.config.update('jax_enable_x64', True)  # float64 para mayor precisión

# PASO 4: Verificar que se forzó determinismo
print(f"XLA Backend: {jax.devices()}")
print(f"JAX Deterministic Mode: {os.environ.get('JAX_DETERMINISTIC_REDUCTIONS', 'not set')}")
\end{lstlisting}

\textbf{Implicaciones Matemáticas:}

Consideramos una operación de reducción típica en Sinkhorn (divergencia Kullback-Leibler):

\[
D_{\text{KL}}(p \| q) = \sum_{i=1}^n p_i \log\left(\frac{p_i}{q_i}\right)
\]

En punto flotante, el orden de suma influye en el error acumulado:

\[
\text{Secuencial}: \quad ((s_1 + s_2) + s_3) + \cdots \quad \rightarrow \quad \epsilon_{\text{seq}} = O(n \, \delta)
\]

\[
\text{Árbol paralelo (GPU)}: \quad ((s_1 + s_2) + (s_3 + s_4)) + \cdots \quad \rightarrow \quad \epsilon_{\text{tree}} \approx O(\log n \, \delta)
\]

donde $\delta$ es la máquina epsilon de punto flotante. Aunque ambas sumas son correctas en valor, el bit-exact resultado difiere ligeramente.

\textbf{Estrategia de Testing: 3-Capas}

\begin{enumerate}
    \item \textbf{CPU Baseline} (Referencia):
        \begin{lstlisting}[language=Python]
os.environ['JAX_PLATFORMS'] = 'cpu'
result_cpu = predictor.predict_step(x_t, key)
        \end{lstlisting}
        Ejecutar con determinismo forzado en CPU. Este resultado se considera \textit{ground truth}.
    
    \item \textbf{GPU Determinista}:
        \begin{lstlisting}[language=Python]
os.environ['JAX_PLATFORMS'] = 'gpu'
os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':16:8'
# Con las mismas semillas y configuración XLA
result_gpu = predictor.predict_step(x_t, key)

assert jnp.allclose(result_cpu, result_gpu, atol=1e-7, rtol=1e-6)
        \end{lstlisting}
        Ejecutar en GPU con callbacks bloqueantes. La tolerancia se relaja ligeramente ($10^{-7}$) debido a diferencias en el orden de operaciones.
    
    \item \textbf{FPGA Simulada} (Si aplicable):
        \begin{lstlisting}[language=Python]
# Simulación: forzar operaciones en float32 (FPGA typical) vs float64 (CPU)
jax.config.update('jax_enable_x64', False)
result_fpga = predictor.predict_step(x_t, key)
jax.config.update('jax_enable_x64', True)

# Tolerancia relavada para float32
assert jnp.allclose(result_cpu, result_fpga, atol=1e-4, rtol=1e-3)
        \end{lstlisting}
\end{enumerate}

\textbf{Procedimiento de Validación en CI/CD:}

\begin{lstlisting}[language=bash]
#!/bin/bash
# File: tests/determinism_test.sh

set -e

echo "[CPU] Running determinism test..."
export JAX_DETERMINISTIC_REDUCTIONS=1
export JAX_PLATFORMS=cpu
python tests/test_cpu_baseline.py

echo "[GPU] Running determinism test on GPU..."
export JAX_PLATFORMS=gpu
export CUDA_LAUNCH_BLOCKING=1
export CUBLAS_WORKSPACE_CONFIG=:16:8
python tests/test_gpu_consistency.py

echo "[FPGA Sim] Running determinism test with float32..."
python tests/test_fpga_sim.py

echo "✓ All determinism tests passed"
\end{lstlisting}

\textbf{Notas de Configuración por Backend:}

\begin{table}[h]
\centering
\begin{tabular}{|l|l|l|}
\hline
\textbf{Backend} & \textbf{Variable de Entorno} & \textbf{Efecto} \\
\hline
CPU & \texttt{XLA\_FLAGS=--xla\_cpu\_use\_cross\_replica\_callbacks=false} & Deshabilita callbacks paralelos \\
GPU (CUDA) & \texttt{CUDA\_LAUNCH\_BLOCKING=1} & Ejecuta kernels secuencialmente \\
GPU (CUDA) & \texttt{CUBLAS\_WORKSPACE\_CONFIG=:16:8} & Fijo workspace cuBLAS \\
Todos & \texttt{JAX\_DETERMINISTIC\_REDUCTIONS=1} & Fuerza orden de reducciones \\
Todos & \texttt{JAX\_DEFAULT\_PRNG\_IMPL=threefry2x32} & PRNG portátil entre backends \\
\hline
\end{tabular}
\end{table}

\textbf{Garantías Post-Configuración:}

\begin{itemize}
    \item \textbf{Bit-Exactitud en CPU}: Garantizada si se ejecutan las mismas operaciones en el mismo orden.
    \item \textbf{Tolerancia GPU}: $10^{-7}$ (atol) / $10^{-6}$ (rtol) debido a paralelismo.
    \item \textbf{Tolerancia FPGA}: $10^{-4}$ (atol) / $10^{-3}$ (rtol) si usa float32.
    \item \textbf{PRNG}: Mismo \texttt{seed} produce igual secuencia en todos backends.
\end{itemize}

\textbf{Conclusión:}

El determinismo en tests de portabilidad es crítico para \textit{Pruebas.tex} (CPU vs GPU vs FPGA). Las variables de entorno XLA y la configuración de PRNG son \textbf{obligatorias} para CI/CD que valide consistencia entre plataformas.

\section{Load Shedding Dinámico (Poda Topológica en Cisne Negro)}

\textbf{Problema Crítico:} Durante eventos de cisne negro (ej. crash de mercado masivo en marzo 2024), la volatilidad $\sigma_t$ puede explotar en múltiplos de $5-20\times$ respecto al valor nominal. Esto desencadena dos patologías simultáneas:

\begin{enumerate}
    \item \textbf{Saturación de Datos de Entrada}: La frecuencia de inyección de ticks sube de 1-10 Hz a 50-200 Hz (sistemas H.F.)
    \item \textbf{Complejidad Factorial de Rama D}: La profundidad $M=5$ de log-signatures requiere $\mathcal{O}(d^M)$ operaciones tensoriales, donde $d$ es la dimensión del path
\end{enumerate}

\textbf{Consecuencia sin Mitigación:}

\[
\text{Latencia de Inferencia} = T_{\text{kernel\_A+B+C}} + \underbrace{T_{\text{signature}}(M=5)}_{\text{Dominante: 80-120ms}} > \text{Tick-Rate de Entrada} = 5-20\text{ms}
\]

Resultado: \textbf{Backlog infinito}, el sistema nunca se recupera, y las predicciones son obsoletas (stale) cuando finalmente se producen.

\textbf{Solución: Load Shedding Adaptativo en Orquestador}

Incorporar lógica de \textbf{Deslastre de Carga Topológica} que monitoree la latencia de inferencia en tiempo real. Si la latencia media móvil (EWMA) supera el tick-rate de entrada, el sistema degrada dinámicamente:

\[
M_{\text{efectivo}} = \begin{cases}
    5 & \text{si } \text{EWMA}(\text{latencia}) < 0.7 \times \text{tick-rate} \\
    3 & \text{si } 0.7 \times \text{tick-rate} \leq \text{EWMA}(\text{latencia}) < \text{tick-rate} \\
    2 & \text{si } \text{EWMA}(\text{latencia}) \geq \text{tick-rate}
\end{cases}
\]

donde el umbral $0.7$ introduce margen de seguridad (histéresis) para evitar oscilaciones.

\textbf{Implementación: Dual JIT Graph Switching}

Precompile múltiples grafos JIT con diferentes profundidades $M \in \{2, 3, 5\}$:

\begin{lstlisting}[language=Python]
import jax
import jax.numpy as jnp
from collections import deque
from typing import Dict, Callable

class AdaptiveSignatureOrchestrator:
    """
    Orquestrador con Load Shedding para Rama D.
    Mantiene múltiples grafos JIT precompilados y selecciona dinámicamente.
    """
    def __init__(self, config: PredictorConfig):
        self.config = config
        self.tick_rate_ns = config.besov_nyquist_interval_ns  # Mínimo tick esperado
        
        # Precompilar grafos JIT para cada profundidad
        self.signature_graphs: Dict[int, Callable] = {
            2: jax.jit(lambda path: compute_signature(path, depth=2)),
            3: jax.jit(lambda path: compute_signature(path, depth=3)),
            5: jax.jit(lambda path: compute_signature(path, depth=5)),
        }
        
        # Monitoreo de latencia (EWMA)
        self.latency_history = deque(maxlen=20)  # Últimos 20 ticks
        self.ewma_alpha = 0.3  # Factor de decaimiento
        self.current_depth = 5   # Empezar en máxima resolución
        self.ewma_latency_ns = 0.0
        
        # Histéresis (evita flapping)
        self.degradation_threshold = 0.7  # Degradar si latencia > 70% del tick-rate
        self.recovery_threshold = 0.5     # Recuperar solo si latencia < 50% del tick-rate
        
    def update_latency(self, inference_time_ns: int):
        """Actualiza EWMA de latencia y decide si degradar/recuperar."""
        self.latency_history.append(inference_time_ns)
        
        # EWMA: L_t = alpha * L_actual + (1-alpha) * L_{t-1}
        if self.ewma_latency_ns == 0.0:
            self.ewma_latency_ns = float(inference_time_ns)
        else:
            self.ewma_latency_ns = (
                self.ewma_alpha * inference_time_ns + 
                (1 - self.ewma_alpha) * self.ewma_latency_ns
            )
        
        # Decisión de degradación/recuperación
        latency_ratio = self.ewma_latency_ns / self.tick_rate_ns
        
        if latency_ratio >= 1.0:  # Crítico: Ya sobrepasamos el tick-rate
            self.current_depth = 2
        elif latency_ratio >= self.degradation_threshold:  # Advertencia
            self.current_depth = min(self.current_depth, 3)  # Degradar pero no al mínimo
        elif latency_ratio < self.recovery_threshold and self.current_depth < 5:
            # Recuperación gradual (histéresis)
            self.current_depth = min(5, self.current_depth + 1)
        
    def compute_adaptive_signature(self, path: jnp.ndarray) -> jnp.ndarray:
        """
        Calcula log-signature con profundidad adaptativa.
        """
        # Seleccionar grafo JIT según profundidad actual
        signature_fn = self.signature_graphs[self.current_depth]
        
        import time
        t_start = time.perf_counter_ns()
        result = signature_fn(path)
        t_end = time.perf_counter_ns()
        
        # Actualizar estadísticas
        self.update_latency(t_end - t_start)
        
        return result
    
    def get_telemetry(self) -> Dict:
        """Devuelve métricas de monitoreo."""
        return {
            "current_depth": self.current_depth,
            "ewma_latency_ms": self.ewma_latency_ns / 1e6,
            "tick_rate_ms": self.tick_rate_ns / 1e6,
            "latency_ratio": self.ewma_latency_ns / self.tick_rate_ns,
            "status": (
                "DEGRADED" if self.current_depth < 5 else "NOMINAL"
            )
        }
\end{lstlisting}

\textbf{Análisis de Performance (Profundidad vs Latencia):}

\begin{table}[h]
\centering
\begin{tabular}{|c|c|c|c|}
\hline
\textbf{Profundidad M} & \textbf{Latencia Típica} & \textbf{Throughput (ticks/s)} & \textbf{Resolución Topológica} \\
\hline
$M=5$ & 80-120ms & 8-12 Hz & \textbf{Máxima} (captura todas interacciones) \\
$M=3$ & 20-35ms  & 28-50 Hz & \textbf{Media} (interacciones principales) \\
$M=2$ & 5-12ms   & 83-200 Hz & \textbf{Mínima} (solo correlaciones simples) \\
\hline
\end{tabular}
\end{table}

\textbf{Trade-off:}
\begin{itemize}
    \item \textbf{M=5}: Captura interacciones de orden 5 (ej. $dx_1 \cdot dx_2 \cdot dx_3 \cdot dx_4 \cdot dx_5$) → Información topológica máxima pero $\mathcal{O}(d^5)$ costo
    \item \textbf{M=3}: Captura hasta orden 3 (ej. $dx_1 \cdot dx_2 \cdot dx_3$) → 3-4x más rápido
    \item \textbf{M=2}: Solo correlaciones pairwise → 10-15x más rápido, pero pierde estructura no-lineal profunda
\end{itemize}

\textbf{Integración en UniversalPredictor:}

\begin{lstlisting}[language=Python]
class UniversalPredictor:
    def __init__(self, config: PredictorConfig):
        self.config = config
        self.orchestrator = AdaptiveSignatureOrchestrator(config)
        # ...resto de inicialización...
    
    def predict_next(self, observation: MarketObservation) -> PredictionResult:
        """
        Predicción con Load Shedding automático.
        """
        # 1. Validar entrada
        if not observation.validate_domain():
            return self._fallback_prediction(observation)
        
        # 2. Construir path incremental
        path = self._build_path(observation)
        
        # 3. Compute signature con profundidad adaptativa
        signature = self.orchestrator.compute_adaptive_signature(path)
        
        # 4. Resto de kernels (A, B, C)
        # ...
        
        # 5. Retornar con telemetría
        telemetry = self.orchestrator.get_telemetry()
        return PredictionResult(
            predicted_next=predicted_value,
            confidence=confidence_score,
            metadata={
                "signature_depth": telemetry["current_depth"],
                "latency_ms": telemetry["ewma_latency_ms"],
                "system_status": telemetry["status"]
            }
        )
\end{lstlisting}

\textbf{Validación en Cisne Negro (Simulación):}

\begin{lstlisting}[language=Python]
def test_black_swan_load_shedding():
    """
    Simula evento de cisne negro con tick-rate explosivo.
    """
    config = PredictorConfig(
        log_sig_depth=5,  # Profundidad nominal
        besov_nyquist_interval_ns=100_000_000  # 100ms nominal
    )
    predictor = UniversalPredictor(config)
    
    # Simular 1000 ticks con aceleración progresiva
    tick_intervals = []
    for i in range(1000):
        if i < 100:  # Primeros 100 ticks: normal (100ms)
            tick_intervals.append(100_000_000)
        elif i < 500:  # Siguientes 400 ticks: aceleración (20ms)
            tick_intervals.append(20_000_000)  # 50 Hz
        else:  # Últimos 500 ticks: crisis (5ms)
            tick_intervals.append(5_000_000)   # 200 Hz
    
    depths_observed = []
    latencies_observed = []
    
    for interval_ns in tick_intervals:
        observation = MarketObservation(
            price=jnp.array([random.normal()]),
            target=jnp.array([0.0]),
            timestamp_ns=time.time_ns()
        )
        
        result = predictor.predict_next(observation)
        depths_observed.append(result.metadata["signature_depth"])
        latencies_observed.append(result.metadata["latency_ms"])
        
        time.sleep(interval_ns / 1e9)  # Simular tick-rate
    
    # Assertions
    assert depths_observed[50] == 5, "Debe estar en M=5 durante régimen normal"
    assert depths_observed[300] == 3, "Debe degradar a M=3 durante aceleración"
    assert depths_observed[700] == 2, "Debe degradar a M=2 durante crisis"
    
    # Verificar que latencia nunca causa backlog infinito
    max_backlog_ratio = max(
        latencies_observed[i] / (tick_intervals[i] / 1e6) 
        for i in range(len(tick_intervals))
    )
    assert max_backlog_ratio < 1.2, f"Backlog ratio demasiado alto: {max_backlog_ratio}"
    
    print("[✓] Load Shedding test PASSED")
    print(f"    Profundidad nominal: M=5")
    print(f"    Profundidad mínima observada: M={min(depths_observed)}")
    print(f"    Latencia máxima: {max(latencies_observed):.2f}ms")
    print(f"    Max backlog ratio: {max_backlog_ratio:.2f}x")
\end{lstlisting}

\textbf{Beneficios en Producción:}

\begin{itemize}
    \item \textbf{Prevención de Backlog Infinito}: Sistema siempre se adapta al tick-rate, nunca colapsa
    \item \textbf{Graceful Degradation}: Reduce resolución topológica pero mantiene predicciones (vs fallo total)
    \item \textbf{Recuperación Automática}: Cuando volatilidad baja, sistema escala de vuelta a $M=5$
    \item \textbf{Overhead Mínimo}: Decisión de switching toma $<0.1$ms (simple comparación EWMA)
    \item \textbf{Visibilidad}: Telemetría expone profundidad actual en cada predicción
\end{itemize}

\textbf{Consideraciones Operacionales:}

\begin{enumerate}
    \item \textbf{Alertas de Degradación}: Si sistema permanece en $M<5$ por más de 60 segundos, emitir alerta de alta volatilidad
    \item \textbf{Persistencia de Estado}: El \texttt{AdaptiveSignatureOrchestrator} debe incluirse en snapshots para preservar EWMA tras restart
    \item \textbf{Configuración de Umbrales}: Los thresholds $0.7$ y $0.5$ deben ser ajustables vía \texttt{PredictorConfig}
    \item \textbf{Métricas de Monitoreo}: Exponer \texttt{current\_depth}, \texttt{ewma\_latency\_ms}, \texttt{latency\_ratio} a Prometheus/Grafana
\end{enumerate}

\textbf{Alternativa Avanzada: Poda Selectiva de Kernels}

En lugar de solo degradar Rama D, se puede escalar a deshabilitar temporalmente kernels completos:

\begin{lstlisting}[language=Python]
# Modo ultra-degradado (solo Kernel A + Rama D superficial)
if latency_ratio > 2.0:
    result = kernel_a_only_prediction(observation)  # Rama A sin Signatures
elif latency_ratio > 1.0:
    result = kernels_a_b_only(observation)  # Rama A + B (sin Neural ODE Rama C)
else:
    result = full_prediction(observation)  # Todas las Ramas
\end{lstlisting}

Esto permite \textbf{mantener throughput} incluso en crisis extremas (ej. flash crash de mayo 2010).

\textbf{Conclusión:}

El Load Shedding Dinámico es \textbf{esencial} para sistemas H.F. que operan en mercados volátiles. Sin esta lógica, eventos de cisne negro producirían backlog infinito y obsolescencia de predicciones. La degradación topológica $(M=5 \to 3 \to 2)$ sacrifica resolución no-lineal profunda pero garantiza que el sistema \textbf{nunca se sature}, priorizando latencia sobre precisión extrema cuando es necesario.

\end{document}
