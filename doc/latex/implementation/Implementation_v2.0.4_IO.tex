\documentclass[11pt, a4paper]{report}

% --- PREAMBLE ---
\usepackage[a4paper, top=2.5cm, bottom=2.5cm, left=2cm, right=2cm]{geometry}
\usepackage{fontspec}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{xcolor}
\usepackage[hidelinks]{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{array}

\usepackage[english]{babel}

% Code highlighting
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.95,0.95,0.92}

\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\ttfamily\footnotesize,
    breakatwhitespace=false,
    breaklines=true,
    captionpos=b,
    keepspaces=true,
    numbers=left,
    numbersep=5pt,
    showspaces=false,
    showstringspaces=false,
    showtabs=false,
    tabsize=2,
    frame=single
}

\lstset{style=mystyle}

\title{\textbf{Universal Stochastic Predictor \\ Phase 4: IO Layer Initiation}}
\author{Implementation Team}
\date{February 19, 2026}

\begin{document}

\maketitle

\tableofcontents

\chapter{Phase 4: IO Layer Initiation Overview}

Phase 4 introduces the asynchronous I/O layer for snapshots, streaming, and telemetry export. The primary design goal is to preserve JAX/XLA throughput by decoupling compute from disk or network latency.

\section{Scope}

Phase 4 covers:
\begin{itemize}
    \item \textbf{Telemetry Buffering}: Non-blocking emission of telemetry snapshots
    \item \textbf{Deterministic Logging}: Hash-based parity checks for CPU/GPU validation
    \item \textbf{Snapshot Strategy}: Atomic persistence of predictor state
    \item \textbf{Ingestion and Validation}: Input filtering, staleness policy, frozen signal detection
    \item \textbf{Security Enforcement}: Credential injection and secret exclusion
    \item \textbf{IO Modules}: validators, loaders, telemetry, snapshots, credentials
\end{itemize}

\section{Design Principles}

\begin{itemize}
    \item \textbf{No Compute Stalls}: JAX compute threads never block on I/O
    \item \textbf{Determinism}: Logs capture reproducible hashes instead of raw state dumps
    \item \textbf{Security}: No raw signals or secrets in logs
    \item \textbf{Configurability}: Logging intervals and destinations injected via config
    \item \textbf{Integrity}: Snapshots and parity logs are hash-verified
\end{itemize}

\chapter{Ingestion and Validation}

\section{Implementation Modules}

Phase 4 IO introduces the following modules:

\begin{itemize}
    \item \texttt{io/validators.py}: Outlier, frozen signal, and staleness checks
    \item \texttt{io/loaders.py}: Ingestion gate and decision flags
    \item \texttt{io/telemetry.py}: Non-blocking telemetry buffer and parity hashes
    \item \texttt{io/snapshots.py}: Binary snapshots, hash verification, atomic writes
    \item \texttt{io/credentials.py}: Environment-based credential injection helpers
\end{itemize}

\section{Catastrophic Outlier Filter}

Input validation must reject catastrophic outliers when $|y_t| > 20\sigma$ relative to historical normalization. In this case, the system must preserve inertial state and emit a critical alert without advancing the transport update.

\begin{itemize}
    \item Reject observation and keep current state unchanged.
    \item Emit a critical alert for audit visibility.
    \item Do not update JKO/Sinkhorn weights for the rejected step.
\end{itemize}

\subsection{Implementation Notes}

Outlier detection is implemented as a pure function with configuration-driven thresholds. The ingestion gate returns a decision object that preserves inertial state when an outlier is detected.

\section{Frozen Signal Alarm}

If the exact same value is observed for $N_{freeze} \geq 5$ consecutive steps, emit a \texttt{FrozenSignalAlarmEvent}. This invalidates the multifractal spectrum and requires:

\begin{itemize}
    \item Freeze the topological branch (Kernel D).
    \item Switch to degraded inference mode.
    \item Continue monitoring until signal variation resumes.
\end{itemize}

\subsection{Recovery Criteria (V-MAJ-6: Frozen Signal Recovery Ratio)}

The frozen signal lock is released when variance recovers above a configurable ratio of historical variance for a configurable number of consecutive steps.

\subsubsection{Algorithm}

\begin{equation}
\text{recovered} = \text{detect\_frozen\_recovery}(\text{variance\_history}, \text{historical\_var}, \rho, n_c)
\end{equation}

where:
\begin{itemize}
    \item $\text{variance\_history}$: Recent residual variances
    \item $\text{historical\_var}$: Baseline variance reference
    \item $\rho = \texttt{config.frozen\_signal\_recovery\_ratio}$ (default: 0.1): Recovery threshold multiplier
    \item $n_c = \texttt{config.frozen\_signal\_recovery\_steps}$ (default: 2): Confirmation window
\end{itemize}

Recovery is confirmed when:
\begin{equation}
\text{variance}_t > \rho \cdot \text{historical\_var} \quad \text{for} \quad n_c \text{ consecutive steps}
\end{equation}

\subsubsection{Implementation}

\begin{lstlisting}[language=Python]
# In evaluate_ingestion():
if frozen:
    residual_variance = np.var(state.residual_buffer)
    in_recovery = detect_frozen_recovery(
        variance_history=[residual_variance],
        historical_variance=referenc_variance,
        ratio_threshold=config.frozen_signal_recovery_ratio,  # V-MAJ-6: Use parameter
        consecutive_steps=config.frozen_signal_recovery_steps
    )
    if in_recovery:
        frozen = False  # Lift the frozen signal flag
\end{lstlisting}

\subsubsection{Configuration Parameters}

From \texttt{PredictorConfig}:

\begin{table}[h!]
\centering
\begin{tabular}{|l|l|p{6cm}|}
\hline
\textbf{Parameter} & \textbf{Default} & \textbf{Purpose} \\
\hline
\texttt{frozen\_signal\_min\_steps} & 5 & Consecutive equal values to trigger alarm \\
\texttt{frozen\_signal\_recovery\_ratio} & 0.1 & Variance ratio threshold for recovery (10\% of baseline) \\
\texttt{frozen\_signal\_recovery\_steps} & 2 & Confirmation window for recovery \\
\hline
\end{tabular}
\caption{V-MAJ-6 Frozen Signal Recovery Configuration}
\end{table}

\subsubsection{Benefits}

\begin{itemize}
    \item \textbf{Automatic Recovery}: No manual intervention needed when signal variance improves
    \item \textbf{Hysteresis}: Recovery threshold ($\rho=0.1$) is more lenient than typical alarm threshold, preventing oscillation
    \item \textbf{Configuration-Driven}: All parameters injected from config.toml (zero-heuristics policy)
    \item \textbf{State Preservation}: Maintains frozen flag during low-variance periods, automatically lifts when variance returns
    \item \textbf{Signal Quality Supervision}: Enables secondary observability on signal quality degradation patterns
\end{itemize}

\section{Staleness Policy (TTL)}

Every observation must carry a timestamp for TTL evaluation. If the target delay exceeds $\Delta_{max}$, the JKO update must be suspended immediately.

\begin{itemize}
    \item Compute staleness as $\Delta_t = t_{now} - t_{obs}$.
    \item If $\Delta_t > \Delta_{max}$, skip the transport update.
    \item Preserve state and record a staleness warning event.
\end{itemize}

\subsection{Implementation Notes}

Staleness is computed as the difference between current time and observation timestamp. The ingestion decision flags a suspended JKO update when the TTL is exceeded.

\chapter{Telemetry Abstraction}

\section{TelemetryBuffer Emission}

The JKO orchestrator should emit a \texttt{TelemetryBuffer} at the end of each step. This buffer is consumed by a dedicated process outside the JAX execution thread.

\begin{itemize}
    \item The buffer contains summary metrics (CUSUM, entropy, regime flags, OT cost).
    \item The compute path only enqueues the buffer and continues.
    \item The consumer is responsible for serialization and persistence.
\end{itemize}

\subsection{Implementation Notes}

The telemetry buffer is a bounded, thread-safe queue. Buffer capacity is explicitly injected from \texttt{PredictorConfig.telemetry\_buffer\_capacity} to eliminate implicit defaults (zero-heuristics policy). Parity hashes are emitted on a configurable interval and derived from canonical float64 serialization.

\begin{lstlisting}[language=Python]
# Instantiation pattern (capacity injected from config)
buffer = TelemetryBuffer(capacity=config.telemetry_buffer_capacity)
\end{lstlisting}

\section{No Compute Stalls}

JAX compute threads must never block on I/O. Telemetry buffers must be non-blocking and consumed by a separate process or thread outside the JAX execution path.

\chapter{Deterministic Logging}

\section{Hash-Based Parity Checks}

For hardware parity audits, the logger records SHA-256 hashes of the weight vector $\rho$ and the OT cost at configurable intervals. This permits CPU/GPU parity validation without dumping VRAM data.

\begin{itemize}
    \item Hash interval configured per deployment.
    \item Hashes derived from canonical float64 serialization.
    \item Logs are append-only and immutable.
\end{itemize}

\section{Audit Hashes}

Parity audits must log SHA-256 hashes of $\rho$ and OT cost at configured intervals. Hash input must be derived from canonical float64 serialization to ensure reproducibility across CPU and GPU.

\chapter{Snapshot Strategy}

\section{Atomic Persistence}

Snapshots must be persisted atomically to prevent partial writes. The IO layer is responsible for:
\begin{itemize}
    \item Writing to temporary files and renaming atomically.
    \item Optional compression configured by policy.
    \item Coordinating snapshot cadence with telemetry output.
\end{itemize}

\section{Binary Serialization}

Text formats (JSON, XML) are prohibited for critical snapshots due to latency and ambiguity. Use dense binary formats such as Protocol Buffers or MessagePack.

\begin{itemize}
    \item Encode all fields deterministically.
    \item Preserve float64 for numerical fidelity.
\end{itemize}

\subsection{Implementation Notes}

The snapshot serializer uses MessagePack as the default binary format. Hash verification is performed before state injection.

\section{Integrity Verification}

Each snapshot $\Sigma_t$ must include a hash footer (SHA-256 or CRC32c). The load routine must verify the hash before injecting state into memory.

\begin{itemize}
    \item Fail closed if hash verification fails.
    \item Log integrity failures at critical severity.
\end{itemize}

\section{Atomic Write Protocol}

To avoid partial writes, persist snapshots to a temporary file and then atomically rename to the target path. The rename step must be the only visible operation to consumers.

\begin{itemize}
    \item Use a unique temporary filename per snapshot.
    \item Ensure the target file is replaced atomically.
\end{itemize}

\subsection{Implementation Notes}

Snapshots are written to a unique temporary file and moved into place using atomic rename. Optional fsync ensures persistence across power loss.

\chapter{Security Policies}

\section{Credential Injection}

Tokens and API keys must not appear in source code. Credentials must be injected at runtime via environment variables or .env files.

\subsection{Implementation Notes}

Credential helpers read from environment variables or .env files and raise explicit errors on missing values.

\section{Version Control Exclusion}

The repository must exclude .env files and credential directories via .gitignore. Secrets must never be committed.

\chapter{Orchestrator Integration}

\section{Ingestion Gate in orchestrate\_step()}

The core orchestration pipeline now integrates ingestion validation as a pre-kernel gate. The \texttt{orchestrate\_step()} function signature is extended to accept observation metadata:

\begin{lstlisting}[language=Python]
def orchestrate_step(
    signal: Float[Array, "n"],
    timestamp_ns: int,
    state: InternalState,
    config: PredictorConfig,
    observation: ProcessState,
    now_ns: int,
) -> OrchestrationResult:
    """Run a single orchestration step with IO ingestion validation."""
\end{lstlisting}

\subsection{Execution Flow}

The ingestion gate operates as follows:

\begin{enumerate}
    \item \textbf{Input Validation}: Standard signal length and dtype checks.
    \item \textbf{Ingestion Decision}: Call \texttt{evaluate\_ingestion()} with current state, observation, and configuration.
    \item \textbf{Rejection Logic}: If \texttt{accept\_observation == False}, reject the entire observation without state update (emergency mode).
    \item \textbf{Degradation Flags}: Apply \texttt{suspend\_jko\_update} and \texttt{freeze\_kernel\_d} flags to control fusion behavior.
    \item \textbf{Kernel Execution}: Run kernels A-D; if \texttt{freeze\_kernel\_d == True}, mark kernel D output as frozen.
    \item \textbf{Fusion Selection}: Skip JKO/Sinkhorn if degraded mode or \texttt{suspend\_jko\_update} is set.
    \item \textbf{State Update}: Only update InternalState if observation is accepted.
\end{enumerate}

\subsection{Flag Semantics}

The \texttt{IngestionDecision} object carries the following flags:

\begin{itemize}
    \item \textbf{accept\_observation}: If False, reject and preserve inertial state.
    \item \textbf{suspend\_jko\_update}: If True, freeze weights and skip Sinkhorn.
    \item \textbf{degraded\_mode}: If True, emit degraded inference mode prediction.
    \item \textbf{freeze\_kernel\_d}: If True, mark kernel D output as frozen (no weight update).
    \item \textbf{staleness\_ns}: Staleness in nanoseconds for audit logging.
    \item \textbf{events}: Emitted validation events (outliers, frozen signals, staleness alarms).
\end{itemize}

\subsection{Early Return on Rejection}

If an observation is rejected (catastrophic outlier), the orchestrator returns a degraded result without advancing the state:

\begin{lstlisting}[language=Python]
# If observation is rejected, skip state update entirely
if reject_observation:
    updated_state = state
else:
    updated_state = atomic_state_update(...)
\end{lstlisting}

\section{PRNG Constant}

To eliminate magic numbers in PRNG splitting, we introduce a module-level constant in \texttt{api/prng.py}:

\begin{lstlisting}[language=Python]
# api/prng.py: GLOBAL PRNG CONFIGURATION
RNG_SPLIT_COUNT = 2  # For kernel execution subkeys
\end{lstlisting}

This constant is now imported by \texttt{core/orchestrator.py} to maintain layer isolation and clarity. All PRNG-related constants reside in the API layer.

\section{64-bit Precision Enforcement}

To ensure Malliavin calculus and Signature computation stability, 64-bit precision must be activated at module import time, before any XLA tracing:

\begin{lstlisting}[language=Python]
# api/config.py: JAX CONFIGURATION (at module level)
import jax
jax.config.update("jax_enable_x64", True)
\end{lstlisting}

This enforces bit-exact reproducibility across CPU/GPU/FPGA backends and must execute before \texttt{ConfigManager} initialization.

\chapter{Telemetry Buffer Integration (P2.3)}

\section{Motivation}

Phase 2 implementations (P2.1 WTMM, P2.2 SDE stiffness, V-MAJ violations) generate rich diagnostic data during orchestration. To enable post-mortem analysis, compliance audits, and debugging without stalling inference, P2.3 integrates a \textbf{non-blocking telemetry buffer} into the orchestration pipeline.

Key requirements:
\begin{itemize}
    \item \textbf{Non-Blocking}: Logging never blocks compute threads (async enqueue only)
    \item \textbf{Thread-Safe}: Multiple consumers can safely drain buffer
    \item \textbf{Audit Trail}: Records capture complete prediction state snapshot
    \item \textbf{Integrity}: Parity hashes verify weights and free energy
    \item \textbf{Config-Driven}: Emission interval and buffer capacity injected from config
\end{itemize}

\section{Data Model}

Each telemetry record captures:

\begin{lstlisting}[language=Python]
@dataclass(frozen=True)
class TelemetryRecord:
    step: int                     # Monotonic counter
    payload: dict                 # Rich diagnostic data


# Payload structure (P2.3):
payload = {
    "step": 42,
    "timestamp_ns": 1708308000000000000,  # Nanosecond precision
    "prediction": 1.234,                  # Fused kernel prediction
    "weights": [0.25, 0.25, 0.25, 0.25], # Kernel ensemble weights (rho)
    "kurtosis": 3.5,
    "holder_exponent": 0.65,              # Signal regularity
    "dgm_entropy": 0.45,
    "mode_collapse_warning": false,       # V-MAJ-5 flag
    "degraded_mode": false,               # V-MAJ-7 hysteresis
    "emergency_mode": false,              # Circuit breaker
    "parity_hashes": {
        "rho_sha256": "abc123...",        # Hash of weight vector
        "ot_cost_sha256": "def456..."     # Hash of Sinkhorn free energy
    }
}
\end{lstlisting}

\section{Integration into orchestrate\_step()}

The orchestrator now accepts optional \texttt{telemetry\_buffer} and \texttt{step\_counter} parameters:

\begin{lstlisting}[language=Python]
def orchestrate_step(
    signal: Float[Array, "n"],
    timestamp_ns: int,
    state: InternalState,
    config: PredictorConfig,
    observation: ProcessState,
    now_ns: int,
    telemetry_buffer: Optional[TelemetryBuffer] = None,  # P2.3
    step_counter: int = 0,  # P2.3
) -> OrchestrationResult:
    """
    Run a single orchestration step with telemetry buffering.
    
    If telemetry_buffer is None, skips telemetry (backward compatible).
    If provided, enqueues record when hash_interval triggers.
    """
    # ... existing orchestration logic ...
    
    # P2.3: Telemetry Buffer Integration (before return)
    if telemetry_buffer is not None:
        parity_record = parity_hashes(
            rho=final_rho,
            ot_cost=float(free_energy) if fusion is not None else 0.0
        )
        
        telemetry_payload = {
            "step": step_counter,
            "timestamp_ns": timestamp_ns,
            "prediction": float(fused_prediction),
            "weights": [float(w) for w in final_rho],
            "kurtosis": float(updated_state.kurtosis),
            "holder_exponent": float(updated_state.holder_exponent),
            "dgm_entropy": float(updated_state.dgm_entropy),
            "mode_collapse_warning": mode_collapse_warning,
            "degraded_mode": degraded_mode,
            "emergency_mode": emergency_mode,
            "parity_hashes": parity_record,
        }
        
        # Emit only when hash_interval triggers (config-driven)
        if should_emit_hash(step_counter, config.telemetry_hash_interval_steps):
            telemetry_record = TelemetryRecord(step=step_counter, payload=telemetry_payload)
            telemetry_buffer.enqueue(telemetry_record)
    
    return OrchestrationResult(...)
\end{lstlisting}

\section{Configuration Parameters}

\begin{table}[h!]
\centering
\begin{tabular}{|l|c|p{6cm}|}
\hline
\textbf{Parameter} & \textbf{Default} & \textbf{Purpose} \\
\hline
\texttt{telemetry\_buffer\_capacity} & 1024 & Maximum records in ring buffer \\
\hline
\texttt{telemetry\_hash\_interval\_steps} & 1 & Emit telemetry every N steps \\
\hline
\end{tabular}
\caption{P2.3 Telemetry Configuration}
\end{table}

\subsection{Configuration Injection Example}

\begin{lstlisting}[language=bash]
# config.toml
[io]
# Telemetry
telemetry_hash_interval_steps = 1          # Emit every step (or 10 for sparser logging)
telemetry_buffer_capacity = 1024           # Ring buffer size (zero-heuristics injection)
\end{lstlisting}

\section{Thread-Safety Model}

\texttt{TelemetryBuffer} uses \texttt{threading.Lock} for atomic operations:

\begin{itemize}
    \item \textbf{enqueue()}: Acquires lock, appends record, releases (O(1) amortized)
    \item \textbf{drain()}: Acquires lock, extracts all records, clears buffer, releases
    \item \textbf{size()}: Acquires lock, returns current count, releases
\end{itemize}

This prevents race conditions when orchestrator (compute thread) enqueues while consumer thread drains.

\section{Backward Compatibility}

P2.3 is fully backward compatible:
\begin{itemize}
    \item If \texttt{telemetry\_buffer=None}, no telemetry is emitted (default)
    \item Existing calls to \texttt{orchestrate\_step()} without telemetry params continue working
    \item No changes to compute path (telemetry entirely outside @jax.jit scope)
\end{itemize}

\section{Usage Example}

\begin{lstlisting}[language=Python]
from stochastic_predictor.io.telemetry import TelemetryBuffer
from stochastic_predictor.api.config import PredictorConfigInjector

# Initialize
config = PredictorConfigInjector().create_config()
telemetry_buffer = TelemetryBuffer(capacity=config.telemetry_buffer_capacity)

# In prediction loop:
for step in range(num_steps):
    result = orchestrate_step(
        signal=current_signal,
        timestamp_ns=now_ns(),
        state=state,
        config=config,
        observation=obs,
        now_ns=now_ns(),
        telemetry_buffer=telemetry_buffer,     # P2.3: Pass buffer
        step_counter=step,                     # P2.3: Pass step
    )
    
    # Optional: Drain telemetry in background thread
    if step\% 100 == 0:
        records = telemetry_buffer.drain()
        # Write to file/database (non-blocking, doesn't stall orchestrator)
        write_telemetry_async(records)
\end{lstlisting}

\section{Benefits}

\begin{itemize}
    \item \textbf{Non-Blocking}: Telemetry enqueue is O(1), never stalls inference
    \item \textbf{Audit Trail}: Complete state snapshots for compliance and debugging
    \item \textbf{Integrity}: Parity hashes enable CPU/GPU parity validation
    \item \textbf{Configurable}: Emission interval and buffer size injected from config
    \item \textbf{Thread-Safe}: Lock-based synchronization for multi-threaded consumers
    \item \textbf{Backward Compatible}: Fully optional, no impact on existing code paths
\end{itemize}

\chapter{Compliance Checklist}

\begin{itemize}
    \item \textbf{No Compute Stalls}: All logging is asynchronous
    \item \textbf{Binary Format}: Protocol Buffers or MessagePack for snapshots
    \item \textbf{Atomic Snapshots}: Write-then-rename protocol
    \item \textbf{Deterministic Hashing}: SHA-256 on $\rho$ and OT cost
    \item \textbf{Security}: No raw signals, VRAM dumps, or secrets
    \item \textbf{Integrity}: Snapshot hashes verified before load
    \item \textbf{Config-Driven}: Intervals and destinations are injected
    \item \textbf{Module Coverage}: IO helpers implemented for validation, telemetry, snapshots, and credentials
    \item \textbf{Orchestrator Integration}: IO ingestion gate integrated into \texttt{orchestrate\_step()}
    \item \textbf{PRNG Constants}: Named constants (RNG\_SPLIT\_COUNT) reside in \texttt{api/prng.py}
    \item \textbf{Buffer Capacity Injection}: TelemetryBuffer capacity injected from config (zero-heuristics policy)
    \item \textbf{64-bit Precision}: Enforced at module load time (\texttt{api/config.py}) before XLA tracing
    \item \textbf{Layer Isolation}: PRNG constants in API layer, not Core layer
\end{itemize}

\chapter{Phase 4 Summary}

Phase 4 introduces a non-blocking I/O architecture that preserves deterministic compute while enabling telemetry, logging, and atomic snapshot persistence.

\end{document}
